{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the HYDRAFloods Documentation The Hydrologic Remote Sensing Analysis for Floods (or HYDRAFloods) is an open source Python application for downloading, processing, and delivering surface water maps derived from remote sensing data. The bases behind the tool is to provide sensor agnostic approaches to produce surface water maps. Furthermore, there are workflows that leverage multiple remote sensing dataset in conjunction to provide daily surface water maps for flood application. The HYDRAFloods application is built using Google Earth Engine and Google Cloud Platform to leverage cloud computing for large-scale computations and handling high data volume outputs. The goal of the package is to allow users access to high-quality, cloud-based surface water mapping algorithms with minimal effort. To achieve this goal, hydrafloods provides a high-level API on top of the Earth Engine Python API to reduce code duplication, such as filtering or carrying metadata for image processing, and provide complex surface water algorithms in a simple API. Furthermore, the package provides some GCP functionality to read and transfer data to be used within Earth Engine. Quick Start To highlight a quick example of the hydrafloods API and simplicity to produce high-quality surface water maps we provide a quick example of mapping surface water using Sentinel-1 over the confluence of the Mekong and Tonle Sap rivers in Cambodia, which experiences frequent flooding. # content of example.py Python file # import the hydrafloods and ee package import hydrafloods as hf import ee ee . Initialize () # specify start and end time as well as geographic region to process start_time = \"2019-10-05\" end_time = \"2019-10-06\" region = ee . Geometry . Rectangle ([ 104 , 11.5 , 106 , 12.5 ]) # get the Sentinel-1 collection # the hf.dataset classes performs the spatial-temporal filtering for you s1 = hf . datasets . Sentinel1 ( region , start_time , end_time ) # apply a water mapping function to the S1 dataset # this applies the \"Edge Otsu\" algorithm from https://doi.org/10.3390/rs12152469 water_imgs = s1 . apply_func ( hf . thresholding . edge_otsu , initial_threshold =- 14 , edge_buffer = 300 ) # take the mode from multiple images # since this is just imagery from one day, it will simply mosaic the images water_map = ee . Image ( water_imgs . collection . mode ()) # export the water map hf . geeutils . export_image ( water_map , region , \"users/<YOUR_USERNAME>/water_map_example\" , scale = 30 , ) (This script is complete, it should run \"as is\") At the end of the script execution, there will be an Earth Engine export task running the process on the EE servers for use later in the EE platform. The resulting surface water image should look like the following figure. It should be noted that hydrafloods can scale quickly and easily by simply changing the start or end time and region to process, allowing for processing of surface water maps with minimal effort in terms of coding. Figure 1. Sentinel-1 backscatter image (left) and resulting surface water map (right) from 2019-10-05 for a region in Cambodia as in the example. Learn more about how to use the package for processing see Getting Start in the docs. Get in touch Report bugs, suggest features or view the source code on GitHub . Contact us through a Technical Assistance Request and mention \"hydrafloods\" Contribute Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. Please see the Contributing Guidelines for details on where to contribute and how to get started. License hydrafloods is available under the open source GNU General Public License v3.0 .","title":"Overview"},{"location":"#welcome-to-the-hydrafloods-documentation","text":"The Hydrologic Remote Sensing Analysis for Floods (or HYDRAFloods) is an open source Python application for downloading, processing, and delivering surface water maps derived from remote sensing data. The bases behind the tool is to provide sensor agnostic approaches to produce surface water maps. Furthermore, there are workflows that leverage multiple remote sensing dataset in conjunction to provide daily surface water maps for flood application. The HYDRAFloods application is built using Google Earth Engine and Google Cloud Platform to leverage cloud computing for large-scale computations and handling high data volume outputs. The goal of the package is to allow users access to high-quality, cloud-based surface water mapping algorithms with minimal effort. To achieve this goal, hydrafloods provides a high-level API on top of the Earth Engine Python API to reduce code duplication, such as filtering or carrying metadata for image processing, and provide complex surface water algorithms in a simple API. Furthermore, the package provides some GCP functionality to read and transfer data to be used within Earth Engine.","title":"Welcome to the HYDRAFloods Documentation"},{"location":"#quick-start","text":"To highlight a quick example of the hydrafloods API and simplicity to produce high-quality surface water maps we provide a quick example of mapping surface water using Sentinel-1 over the confluence of the Mekong and Tonle Sap rivers in Cambodia, which experiences frequent flooding. # content of example.py Python file # import the hydrafloods and ee package import hydrafloods as hf import ee ee . Initialize () # specify start and end time as well as geographic region to process start_time = \"2019-10-05\" end_time = \"2019-10-06\" region = ee . Geometry . Rectangle ([ 104 , 11.5 , 106 , 12.5 ]) # get the Sentinel-1 collection # the hf.dataset classes performs the spatial-temporal filtering for you s1 = hf . datasets . Sentinel1 ( region , start_time , end_time ) # apply a water mapping function to the S1 dataset # this applies the \"Edge Otsu\" algorithm from https://doi.org/10.3390/rs12152469 water_imgs = s1 . apply_func ( hf . thresholding . edge_otsu , initial_threshold =- 14 , edge_buffer = 300 ) # take the mode from multiple images # since this is just imagery from one day, it will simply mosaic the images water_map = ee . Image ( water_imgs . collection . mode ()) # export the water map hf . geeutils . export_image ( water_map , region , \"users/<YOUR_USERNAME>/water_map_example\" , scale = 30 , ) (This script is complete, it should run \"as is\") At the end of the script execution, there will be an Earth Engine export task running the process on the EE servers for use later in the EE platform. The resulting surface water image should look like the following figure. It should be noted that hydrafloods can scale quickly and easily by simply changing the start or end time and region to process, allowing for processing of surface water maps with minimal effort in terms of coding. Figure 1. Sentinel-1 backscatter image (left) and resulting surface water map (right) from 2019-10-05 for a region in Cambodia as in the example. Learn more about how to use the package for processing see Getting Start in the docs.","title":"Quick Start"},{"location":"#get-in-touch","text":"Report bugs, suggest features or view the source code on GitHub . Contact us through a Technical Assistance Request and mention \"hydrafloods\"","title":"Get in touch"},{"location":"#contribute","text":"Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. Please see the Contributing Guidelines for details on where to contribute and how to get started.","title":"Contribute"},{"location":"#license","text":"hydrafloods is available under the open source GNU General Public License v3.0 .","title":"License"},{"location":"algorithms/","text":"Here are a more in depth examples of specific algorithms for surface water mapping workflows that are implemented within hydrafloods that users can call. It is expected that the code is run in an interactive python session such as IPython or in a Jupyter Notebook as later code blocks will use variables from previous ones. import ee ee . Initialize () import hydrafloods as hf SAR Speckle Filtering Algorithms SAR imagery is affected by artifacts called Speckle. Speckle looks like granular noise in synthetic aperture radar (SAR) data and is due to the interference of radar waves reflected from many elementary scatterers on the ground. Speckle in SAR imagery typically reduces the accuracy of image segmentation and classification so applying speckle filters is a common preprocessing step ( Lee et al., 2009 ). Multiple algorithms have been developed by the scientific community to alleviate the effects of Speckle in subsequent SAR image processing. hydrafloods has implemented a few of these Speckle filter algorithms in the package to help effectively use SAR imagery for image processing, in this case for surface water mapping. Here is a list of Speckle filter algorithms available: Lee Sigma: hydrafloods.lee_sigma ( Lee et al., 2008 ) Gamma Map: hydrafloods.gamma_map ( Beauchemin et al., 1995 ) Refined Lee: hydrafloods.refined_lee ( Lee, 1981 ) Here is a brief example of how one might apply these algorithms to SAR data using hydrafloods : # define a geographic region region = hf . country_bbox ( \"Cambodia\" ) # define start and end times start_time = \"2019-09-15\" end_time = \"2019-09-20\" # get the Sentinel 1 collection as a Dataset s1 = hf . Sentinel1 ( region , start_time , end_time ) After we have our SAR collection, we can apply the functions on the image using the apply_func() method. Since these algorithms take an image as input and ouput and image we can easily apply on all imagery. Watch out though...some of these algorithms (specfically refined_lee() ) are extremely memory intensive and you will likely get a \"User memory limit exceeded\" error when applying over many (25+) images. In this case, it will work since we are only applying over a few images. lee_sigma_filtered = ( s1 . apply_func ( hf . lee_sigma ) . collection . first () ) gamma_map_filtered = ( s1 . apply_func ( hf . gamma_map ) . collection . first () ) refined_lee_filtered = ( s1 . apply_func ( hf . refined_lee ) . collection . first () ) original = s1 . collection . first () zoom_region = [ 104.60 , 15.10 , 104.95 , 15.35 ] viz_params = { \"min\" : - 25 , \"max\" : 0 , \"bands\" : \"VV\" , \"region\" : zoom_region , \"dimensions\" : 2000 , \"crs\" : \"epsg:4326\" } print ( original . getThumbURL ( viz_params )) print ( lee_sigma_filtered . getThumbURL ( viz_params )) print ( gamma_map_filtered . getThumbURL ( viz_params )) print ( refined_lee_filtered . getThumbURL ( viz_params )) Try opening the examples in a new tab to zoom in and really see the differences Original Lee Sigma filter Gamma Map filter Refined Lee filter For more information on the filtering algorithms and the specific arguments, please see the filtering module API reference Correction Algorithms Another common workflow when working with satelitte imagery is to correct for atmospheric and terrain effects. Most of the data collection on Earth Engine have atmospherically corrected data so hydrafloods has focused on correction algorithms for terrain (both SAR and optical) correction and a bidirectional reflectance distribution function (BRDF) correction for optical imagery. \ud83d\udea7 Under construction \ud83d\udea7 Generic Water Mapping Algorithms The goal of hydrafloods is to provide efficient, easily accessible surface water maps. To that end, there are a few generic surface water mapping algorithms available that can be used with virtually any dataset (given some customization of parameters). Here is a list of the water mapping algorithms available: Edge Otsu: hydrafloods.edge_otsu ( Donchyts et al., 2016 ; Markert et al., 2020 ) Bmax Otsu: hydrafloods.bmax_otsu ( Cao et al.,2019 ; Markert et al., 2020 ) KMeans Extent: hydrafloods.kmeans_extent ( Chang et al., 2020 ) To begin, we will access optical and SAR data for a coincident time period following the example from Using Datasets : # area where overlap is known region = ee . Geometry . Rectangle ([ 103.6334 , 12.4368 , 104.8419 , 13.2615 ]) # month where we know coincident data start_time = \"2019-02-01\" end_time = \"2019-03-01\" # get Landsat 8 dataset lc8 = hf . Landsat8 ( region , start_time , end_time ) # add the mndwi water index to the lc8 dataset lc8 = lc8 . apply_func ( hf . add_indices , indices = [ \"mndwi\" ]) # get Sentinel 1 dataset s1 = hf . Sentinel1 ( region , start_time , end_time ) # apply gamma map speckle filter s1 = s1 . apply_func ( hf . gamma_map ) # join the two datasets joined = lc8 . join ( s1 ) # create a composite image for the region composite = joined . collection . median () # define some visualization parameters to use water_viz = { \"min\" : 0 , \"max\" : 1 , \"palette\" : \"silver,navy\" , \"region\" : region , \"dimensions\" : 2000 } optical_viz = { \"min\" : 50 , \"max\" : 5500 , \"bands\" : \"swir2,nir,green\" , \"gamma\" : 1.5 , \"region\" : region , \"dimensions\" : 2000 } sar_viz = { \"min\" : - 25 , \"max\" : 0 , \"bands\" : \"VV\" , \"region\" : region , \"dimensions\" : 2000 } Now that we have our data here we will highlight how to use some generic surface water mapping algorithms, specifically the edge_otsu() algorithm: # apply the edge otsu algorithm on the MNDWI optical index optical_water = hf . edge_otsu ( composite , region = region , band = \"mndwi\" , initial_threshold = 0 , edge_buffer = 300 , invert = True ) # apply edge otsu algorithm on the VV SAR band sar_water = hf . edge_otsu ( composite , region = region , band = \"VV\" , initial_threshold =- 16 , edge_buffer = 300 ) # get thumb urls of results print ( composite . getThumbURL ( optical_viz )) print ( composite . getThumbURL ( sar_viz )) print ( optical_water . getThumbURL ( water_viz )) print ( sar_water . getThumbURL ( water_viz )) Landsat 8 Image SAR Image Landsat 8 Water Map SAR Water Map This is just one example of surface water mapping and there are additional water mapping algorithms as mentioned above. More documentation regarding the water mapping functions and the input arguments can be found at the thresholding module If there are other algorithms you would like to see in the hydrafloods package, please file an issue with specifics (and hopefully a link to the paper) on our GitHub repo.","title":"Algorithms"},{"location":"algorithms/#sar-speckle-filtering-algorithms","text":"SAR imagery is affected by artifacts called Speckle. Speckle looks like granular noise in synthetic aperture radar (SAR) data and is due to the interference of radar waves reflected from many elementary scatterers on the ground. Speckle in SAR imagery typically reduces the accuracy of image segmentation and classification so applying speckle filters is a common preprocessing step ( Lee et al., 2009 ). Multiple algorithms have been developed by the scientific community to alleviate the effects of Speckle in subsequent SAR image processing. hydrafloods has implemented a few of these Speckle filter algorithms in the package to help effectively use SAR imagery for image processing, in this case for surface water mapping. Here is a list of Speckle filter algorithms available: Lee Sigma: hydrafloods.lee_sigma ( Lee et al., 2008 ) Gamma Map: hydrafloods.gamma_map ( Beauchemin et al., 1995 ) Refined Lee: hydrafloods.refined_lee ( Lee, 1981 ) Here is a brief example of how one might apply these algorithms to SAR data using hydrafloods : # define a geographic region region = hf . country_bbox ( \"Cambodia\" ) # define start and end times start_time = \"2019-09-15\" end_time = \"2019-09-20\" # get the Sentinel 1 collection as a Dataset s1 = hf . Sentinel1 ( region , start_time , end_time ) After we have our SAR collection, we can apply the functions on the image using the apply_func() method. Since these algorithms take an image as input and ouput and image we can easily apply on all imagery. Watch out though...some of these algorithms (specfically refined_lee() ) are extremely memory intensive and you will likely get a \"User memory limit exceeded\" error when applying over many (25+) images. In this case, it will work since we are only applying over a few images. lee_sigma_filtered = ( s1 . apply_func ( hf . lee_sigma ) . collection . first () ) gamma_map_filtered = ( s1 . apply_func ( hf . gamma_map ) . collection . first () ) refined_lee_filtered = ( s1 . apply_func ( hf . refined_lee ) . collection . first () ) original = s1 . collection . first () zoom_region = [ 104.60 , 15.10 , 104.95 , 15.35 ] viz_params = { \"min\" : - 25 , \"max\" : 0 , \"bands\" : \"VV\" , \"region\" : zoom_region , \"dimensions\" : 2000 , \"crs\" : \"epsg:4326\" } print ( original . getThumbURL ( viz_params )) print ( lee_sigma_filtered . getThumbURL ( viz_params )) print ( gamma_map_filtered . getThumbURL ( viz_params )) print ( refined_lee_filtered . getThumbURL ( viz_params )) Try opening the examples in a new tab to zoom in and really see the differences Original Lee Sigma filter Gamma Map filter Refined Lee filter For more information on the filtering algorithms and the specific arguments, please see the filtering module API reference","title":"SAR Speckle Filtering Algorithms"},{"location":"algorithms/#correction-algorithms","text":"Another common workflow when working with satelitte imagery is to correct for atmospheric and terrain effects. Most of the data collection on Earth Engine have atmospherically corrected data so hydrafloods has focused on correction algorithms for terrain (both SAR and optical) correction and a bidirectional reflectance distribution function (BRDF) correction for optical imagery. \ud83d\udea7 Under construction \ud83d\udea7","title":"Correction Algorithms"},{"location":"algorithms/#generic-water-mapping-algorithms","text":"The goal of hydrafloods is to provide efficient, easily accessible surface water maps. To that end, there are a few generic surface water mapping algorithms available that can be used with virtually any dataset (given some customization of parameters). Here is a list of the water mapping algorithms available: Edge Otsu: hydrafloods.edge_otsu ( Donchyts et al., 2016 ; Markert et al., 2020 ) Bmax Otsu: hydrafloods.bmax_otsu ( Cao et al.,2019 ; Markert et al., 2020 ) KMeans Extent: hydrafloods.kmeans_extent ( Chang et al., 2020 ) To begin, we will access optical and SAR data for a coincident time period following the example from Using Datasets : # area where overlap is known region = ee . Geometry . Rectangle ([ 103.6334 , 12.4368 , 104.8419 , 13.2615 ]) # month where we know coincident data start_time = \"2019-02-01\" end_time = \"2019-03-01\" # get Landsat 8 dataset lc8 = hf . Landsat8 ( region , start_time , end_time ) # add the mndwi water index to the lc8 dataset lc8 = lc8 . apply_func ( hf . add_indices , indices = [ \"mndwi\" ]) # get Sentinel 1 dataset s1 = hf . Sentinel1 ( region , start_time , end_time ) # apply gamma map speckle filter s1 = s1 . apply_func ( hf . gamma_map ) # join the two datasets joined = lc8 . join ( s1 ) # create a composite image for the region composite = joined . collection . median () # define some visualization parameters to use water_viz = { \"min\" : 0 , \"max\" : 1 , \"palette\" : \"silver,navy\" , \"region\" : region , \"dimensions\" : 2000 } optical_viz = { \"min\" : 50 , \"max\" : 5500 , \"bands\" : \"swir2,nir,green\" , \"gamma\" : 1.5 , \"region\" : region , \"dimensions\" : 2000 } sar_viz = { \"min\" : - 25 , \"max\" : 0 , \"bands\" : \"VV\" , \"region\" : region , \"dimensions\" : 2000 } Now that we have our data here we will highlight how to use some generic surface water mapping algorithms, specifically the edge_otsu() algorithm: # apply the edge otsu algorithm on the MNDWI optical index optical_water = hf . edge_otsu ( composite , region = region , band = \"mndwi\" , initial_threshold = 0 , edge_buffer = 300 , invert = True ) # apply edge otsu algorithm on the VV SAR band sar_water = hf . edge_otsu ( composite , region = region , band = \"VV\" , initial_threshold =- 16 , edge_buffer = 300 ) # get thumb urls of results print ( composite . getThumbURL ( optical_viz )) print ( composite . getThumbURL ( sar_viz )) print ( optical_water . getThumbURL ( water_viz )) print ( sar_water . getThumbURL ( water_viz )) Landsat 8 Image SAR Image Landsat 8 Water Map SAR Water Map This is just one example of surface water mapping and there are additional water mapping algorithms as mentioned above. More documentation regarding the water mapping functions and the input arguments can be found at the thresholding module If there are other algorithms you would like to see in the hydrafloods package, please file an issue with specifics (and hopefully a link to the paper) on our GitHub repo.","title":"Generic Water Mapping Algorithms"},{"location":"cli/","text":"\ud83d\udea7 Under construction \ud83d\udea7","title":"Command Line Interface"},{"location":"datasets/","text":"hydrafloods.datasets.Dataset Base dataset class used to define an EE image collection by datetime and geographic region A dataset wraps an ee.ImageCollection by applying the spatial and temporal filtering upon init. Provides utility functionality to make working with and managing image collections less verbose Examples: Create a dataset object for Sentinel-1 data over Alabama for 2019 >>> ds = Dataset ( ... region = ee . Geometry . Rectangle ([ - 88.473227 , 30.223334 , - 84.88908 , 35.008028 ]), ... start_time = \"2019-01-01\" , ... end_time = \"2020-01-01\" , ... asset_id = \"COPERNICUS/S1_GRD\" ... ) >>> ds HYDRAFloods Dataset : { 'asset_id' : 'COPERNICUS/S1_GRD' , 'end_time' : '2020-01-01' , 'name' : 'Dataset' , 'region' : [[[ ... ], [ ... ], [ ... ], [ ... ], [ ... ]]], 'start_time' : '2019-01-01' } collection property writable image collection object property wrapped by dataset dates property readonly Dates of imagery contained in the image collection n_images property readonly Number of images contained in the dataset __init__ ( self , region , start_time , end_time , asset_id , use_qa = False ) special Initialize Dataset class Parameters: Name Type Description Default region ee.Geometry earth engine geometry object to filter image collection by required start_time str | datetime.datetime start time used to filter image collection required end_time str | datetime.datetime end time used to filter image collection required asset_id str asset id of earth engine collection required use_qa bool boolean to determine to use an internal function qa(). Used for definining custom dataset objects False Exceptions: Type Description AttributeError if qa() method is not defined and use_qa is True Source code in hydrafloods/datasets.py def __init__ ( self , region , start_time , end_time , asset_id , use_qa = False ): \"\"\"Initialize Dataset class args: region (ee.Geometry): earth engine geometry object to filter image collection by start_time (str | datetime.datetime): start time used to filter image collection end_time (str | datetime.datetime): end time used to filter image collection asset_id (str): asset id of earth engine collection use_qa (bool, optional): boolean to determine to use an internal function qa(). Used for definining custom dataset objects raises: AttributeError: if qa() method is not defined and use_qa is True \"\"\" # TODO: add exceptions to check datatypes self . region = region # dtype = ee.Geometry self . start_time = start_time self . end_time = end_time self . asset_id = asset_id self . use_qa = use_qa # dictionary mapping of band names used to harmonized optical datasets to same names self . BANDREMAP = ee . Dictionary ( { \"landsat7\" : ee . List ([ \"B1\" , \"B2\" , \"B3\" , \"B4\" , \"B5\" , \"B7\" ]), \"landsat8\" : ee . List ([ \"B2\" , \"B3\" , \"B4\" , \"B5\" , \"B6\" , \"B7\" ]), \"viirs\" : ee . List ([ \"M2\" , \"M4\" , \"I1\" , \"I2\" , \"I3\" , \"M11\" ]), \"sen2\" : ee . List ([ \"B2\" , \"B3\" , \"B4\" , \"B8\" , \"B11\" , \"B12\" ]), \"modis\" : ee . List ( [ \"sur_refl_b03\" , \"sur_refl_b04\" , \"sur_refl_b01\" , \"sur_refl_b02\" , \"sur_refl_b06\" , \"sur_refl_b07\" , ] ), \"new\" : ee . List ([ \"blue\" , \"green\" , \"red\" , \"nir\" , \"swir1\" , \"swir2\" ]), } ) # get the image collection and filter by geographic region and date time imgcollection = ( ee . ImageCollection ( self . asset_id ) . filterBounds ( self . region ) . filterDate ( self . start_time , self . end_time ) ) # check if to apply arbitrary qa process on collection # qa function can be defined in custom objects extending dataset if self . use_qa : try : imgcollection = imgcollection . map ( self . qa ) except AttributeError : raise AttributeError ( \"qa() method is not defined...please define one or set `use_qa` to False\" ) self . collection = imgcollection aggregate_time ( self , dates = None , period = 1 , reducer = 'mean' , clip_to_area = False , inplace = False ) Aggregates multiple images into one based on time periods and a user defined reducer. Useful for mosaicing images from same date or time period. Expects the images in this dataset to be homogenous (same band names and types) Parameters: Name Type Description Default dates list[str] list of dates defined as beginning time period of aggregatation. default = None, all available uniques dates in collection will be used None period int number of days to advance from dates for aggregation. default = 1 1 reducer str | ee.Reducer reducer to apply to images for aggregation, accepts string reducer name or ee.Reducer opbject, default = \"mean\" 'mean' clip_to_area bool switch to clip imagery that has been merged to the overlaping region of imagery, default=False False inplace bool define whether to return another dataset object or update inplace. default = False False Returns: Type Description Dataset | None returns dataset.collection with aggregated imagery or none depending on inplace Source code in hydrafloods/datasets.py def aggregate_time ( self , dates = None , period = 1 , reducer = \"mean\" , clip_to_area = False , inplace = False ): \"\"\"Aggregates multiple images into one based on time periods and a user defined reducer. Useful for mosaicing images from same date or time period. Expects the images in this dataset to be homogenous (same band names and types) args: dates (list[str], optional): list of dates defined as beginning time period of aggregatation. default = None, all available uniques dates in collection will be used period (int, optional): number of days to advance from dates for aggregation. default = 1 reducer (str | ee.Reducer, optional): reducer to apply to images for aggregation, accepts string reducer name or ee.Reducer opbject, default = \"mean\" clip_to_area (bool): switch to clip imagery that has been merged to the overlaping region of imagery, default=False inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset.collection with aggregated imagery or none depending on inplace \"\"\" def _aggregation ( d ): \"\"\"Closure function to map through days and reduce data within a given time period \"\"\" t1 = ee . Date ( d ) t2 = t1 . advance ( period , \"day\" ) img = ( self . collection . filterDate ( t1 , t2 ) . reduce ( reducer ) . rename ( band_names ) . set ( \"system:time_start\" , t1 . millis ()) ) geom = ( ee . FeatureCollection ( self . collection . filterDate ( t1 , t2 ) . map ( geeutils . get_geoms ) ) . union ( 100 ) . geometry ( 100 ) ) outimg = ee . Algorithms . If ( clip_to_area , img . clip ( geom ), img ) return outimg if dates is None : dates = ( self . collection . aggregate_array ( \"system:time_start\" ) . map ( lambda x : ee . Date ( x ) . format ( \"YYYY-MM-dd\" )) . distinct () ) else : dates = ee . List ( dates ) band_names = ee . Image ( self . collection . first ()) . bandNames () out_coll = ee . ImageCollection . fromImages ( dates . map ( _aggregation )) if inplace : self . collection = out_coll return else : outCls = self . copy () outCls . collection = out_coll return outCls apply_func ( self , func , inplace = False , * args , ** kwargs ) Wrapper method to apply a function to all of the image in the dataset. Makes a copy of the collection and reassigns the image collection propety. Function must accept an ee.ImageCollection and return an ee.ImageCollection Parameters: Name Type Description Default func object Function to map across image collection. Function must accept ee.Image as first argument required inplace bool define whether to return another dataset object or update inplace. default = False False **kwargs arbitrary keyword to pass to func {} Returns: Type Description Dataset | None copy of class with results from func as image within collection property Source code in hydrafloods/datasets.py def apply_func ( self , func , inplace = False , * args , ** kwargs ): \"\"\"Wrapper method to apply a function to all of the image in the dataset. Makes a copy of the collection and reassigns the image collection propety. Function must accept an ee.ImageCollection and return an ee.ImageCollection Args: func (object): Function to map across image collection. Function must accept ee.Image as first argument inplace (bool, optional): define whether to return another dataset object or update inplace. default = False **kwargs: arbitrary keyword to pass to `func` Returns: Dataset | None: copy of class with results from `func` as image within collection property \"\"\" # get a partial function to map over imagery with the keywords applied # expects that the first positional arg is an func = partial ( func , ** kwargs ) if inplace : self . collection = self . collection . map ( func ) return else : outCls = self . copy () outCls . collection = self . collection . map ( func ) return outCls band_pass_adjustment ( self , img ) Method to apply linear band transformation to dataset image collection. Expects that dataset has properties self.gain and self.bias set Parameters: Name Type Description Default img ee.Image image to apply regression on required Source code in hydrafloods/datasets.py @decorators . carry_metadata def band_pass_adjustment ( self , img ): \"\"\"Method to apply linear band transformation to dataset image collection. Expects that dataset has properties `self.gain` and `self.bias` set args: img (ee.Image): image to apply regression on \"\"\" # linear regression coefficients for adjustment return ( img . multiply ( self . gain ) . add ( self . bias ) . set ( \"system:time_start\" , img . get ( \"system:time_start\" )) ) clip_to_region ( self , inplace = False ) Clips all of the images to the geographic extent defined by region. Useful for setting geometries on unbounded imagery in collection (e.g. MODIS or VIIRS imagery) Parameters: Name Type Description Default inplace bool define whether to return another dataset object or update inplace. default = False False Returns: Type Description Dataset | None returns dataset with imagery clipped to self.region or none depending on inplace Source code in hydrafloods/datasets.py def clip_to_region ( self , inplace = False ): \"\"\"Clips all of the images to the geographic extent defined by region. Useful for setting geometries on unbounded imagery in collection (e.g. MODIS or VIIRS imagery) args: inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset with imagery clipped to self.region or none depending on inplace \"\"\" @decorators . carry_metadata def clip ( img ): \"\"\"Closure function to perform the clipping while carrying metadata \"\"\" return ee . Image ( img . clip ( self . region )) if inplace : self . collection = self . collection . map ( clip ) return else : outCls = self . copy () outCls . collection = self . collection . map ( clip ) return outCls copy ( self ) Returns a deep copy of the hydrafloods dataset class Source code in hydrafloods/datasets.py def copy ( self ): \"\"\"Returns a deep copy of the hydrafloods dataset class \"\"\" return copy . deepcopy ( self ) join ( self , dataset , inplace = False ) Performs spatiotemporal join between self.collection and dataset.collection. Result will be a dataset where the collection is colocated imagery in space and time Parameters: Name Type Description Default dataset Dataset dataset object to apply join with. Used as right in join operations required inplace bool define whether to return another dataset object or update inplace. default = False False Returns: Type Description Dataset | None returns dataset where collection with joined imagery or none depending on inplace Source code in hydrafloods/datasets.py def join ( self , dataset , inplace = False ): \"\"\"Performs spatiotemporal join between self.collection and dataset.collection. Result will be a dataset where the collection is colocated imagery in space and time args: dataset (Dataset): dataset object to apply join with. Used as right in join operations inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset where collection with joined imagery or none depending on inplace \"\"\" def _merge ( img ): \"\"\"Closure func to take results from the join and combine into one image with overlaping region \"\"\" join_coll = ee . ImageCollection . fromImages ( img . get ( key )) img_geom = img . geometry ( 100 ) join_geom = join_coll . map ( geeutils . get_geoms ) . union ( 100 ) . geometry ( 100 ) overlap = img_geom . intersection ( join_geom , 100 ) join_data = join_coll . mosaic () return img . addBands ( join_data ) . clip ( overlap ) key = str ( dataset . __class__ . __name__ ) # get a time and space filter filter = ee . Filter . And ( ee . Filter . maxDifference ( ** { \"difference\" : 1000 * 60 * 60 * 24 , # One day in milliseconds \"leftField\" : \"system:time_start\" , \"rightField\" : \"system:time_start\" , } ), ee . Filter . intersects ( ** { \"leftField\" : \".geo\" , \"rightField\" : \".geo\" , \"maxError\" : 100 } ), ) # apply join on collections and save all results joined = ee . ImageCollection ( ee . Join . saveAll ( key ) . apply ( primary = self . collection , secondary = dataset . collection , condition = filter ) ) # map over all filtered imagery, mosaic joined matches, and add bands to imagery joined = joined . map ( _merge ) if inplace : self . collection = joined return else : outCls = self . copy () outCls . collection = joined return outCls merge ( self , dataset , inplace = False ) Merge the collection of two datasets into one where self.collection will contain imagery from self and dataset arg. Results will be sorted by time Parameters: Name Type Description Default dataset Dataset dataset object to merge required inplace bool define whether to return another dataset object or update inplace. default = False False Returns: Type Description Dataset | None returns dataset where collection is merged imagery or none depending on inplace Source code in hydrafloods/datasets.py def merge ( self , dataset , inplace = False ): \"\"\"Merge the collection of two datasets into one where self.collection will contain imagery from self and dataset arg. Results will be sorted by time args: dataset (Dataset): dataset object to merge inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset where collection is merged imagery or none depending on inplace \"\"\" merged = self . collection . merge ( dataset . collection ) . sort ( \"system:time_start\" ) if inplace : self . collection = merged return else : outCls = self . copy () outCls . collection = merged return outCls hydrafloods.datasets.Sentinel1 Class extending dataset for the Sentinel 1 collection __init__ ( self , * args , * , asset_id = 'COPERNICUS/S1_GRD' , use_qa = True , ** kwargs ) special Initialize Sentinel1 Dataset class Parameters: Name Type Description Default *args positional arguments to pass to Dataset (i.e. region , start_time , end_time ) () asset_id str asset id of the Sentinel 1 earth engine collection. default=\"COPERNICUS/S1_GRD\" 'COPERNICUS/S1_GRD' use_qa bool boolean to determine to use a private self.qa() function. default=True True **kwargs optional addtional arbitrary keywords to pass to Dataset {} Source code in hydrafloods/datasets.py def __init__ ( self , * args , asset_id = \"COPERNICUS/S1_GRD\" , use_qa = True , ** kwargs ): \"\"\"Initialize Sentinel1 Dataset class args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the Sentinel 1 earth engine collection. default=\"COPERNICUS/S1_GRD\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Sentinel1 , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) self . collection = self . collection . filter ( ee . Filter . listContains ( \"transmitterReceiverPolarisation\" , \"VH\" ) ) return add_fusion_features ( self , inplace = False ) Method to add additional features to SAR imagery for data fusion. Will calculate Normalized Difference Polorization Index (VV-VH)/(VV+VH), VV/VH ratio, and categorical orbit bands Returns: Type Description Dataset | None returns dataset.collection where imagery has the added bands Source code in hydrafloods/datasets.py def add_fusion_features ( self , inplace = False ): \"\"\"Method to add additional features to SAR imagery for data fusion. Will calculate Normalized Difference Polorization Index (VV-VH)/(VV+VH), VV/VH ratio, and categorical orbit bands returns: Dataset | None: returns dataset.collection where imagery has the added bands \"\"\" def _add_fusion_features ( img ): \"\"\"Closure function to add features as bands to the images \"\"\" bounds = img . geometry ( 100 ) orbit = ee . String ( img . get ( \"orbitProperties_pass\" )) orbit_band = ee . Algorithms . If ( orbit . compareTo ( \"DESCENDING\" ), ee . Image ( 1 ), ee . Image ( 0 ) ) vv = img . select ( \"VV\" ) vh = img . select ( \"VH\" ) ratio = vv . divide ( vh ) . rename ( \"ratio\" ) ndpi = vv . subtract ( vh ) . divide ( vv . add ( vh )) . rename ( \"ndpi\" ) extraFeatures = ee . Image . cat ( [ ee . Image ( orbit_band ) . rename ( \"orbit\" ), ratio , ndpi ] ) return img . addBands ( extraFeatures . clip ( bounds )) return self . apply_func ( _add_fusion_features , inplace = inplace ) qa ( self , img ) Custom QA masking method for Sentinel2 surface reflectance dataset Source code in hydrafloods/datasets.py @decorators . carry_metadata def qa ( self , img ): \"\"\"Custom QA masking method for Sentinel2 surface reflectance dataset \"\"\" angles = img . select ( \"angle\" ) return img . updateMask ( angles . lt ( 45 ) . And ( angles . gt ( 30 ))) hydrafloods.datasets.Sentinel2 __init__ ( self , * args , * , asset_id = 'COPERNICUS/S2_SR' , apply_band_adjustment = False , use_qa = True , ** kwargs ) special Initialize Sentinel2 Dataset class Parameters: Name Type Description Default *args positional arguments to pass to Dataset (i.e. region , start_time , end_time ) () asset_id str asset id of the Sentinel2 earth engine collection. default=\"COPERNICUS/S2_SR\" 'COPERNICUS/S2_SR' apply_band_adjustment bool boolean switch to apply linear band pass equation to convert values to Landsat8. default=False False use_qa bool boolean to determine to use a private self.qa() function. default=True True **kwargs optional addtional arbitrary keywords to pass to Dataset {} Source code in hydrafloods/datasets.py def __init__ ( self , * args , asset_id = \"COPERNICUS/S2_SR\" , apply_band_adjustment = False , use_qa = True , ** kwargs , ): \"\"\"Initialize Sentinel2 Dataset class args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the Sentinel2 earth engine collection. default=\"COPERNICUS/S2_SR\" apply_band_adjustment (bool, optional): boolean switch to apply linear band pass equation to convert values to Landsat8. default=False use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Sentinel2 , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) coll = self . collection . select ( self . BANDREMAP . get ( \"sen2\" ), self . BANDREMAP . get ( \"new\" ) ) if apply_band_adjustment : # band bass adjustment coefficients taken HLS project https://hls.gsfc.nasa.gov/algorithms/bandpass-adjustment/ # slope coefficients self . gain = ee . Image . constant ( [ 0.9778 , 1.0053 , 0.9765 , 0.9983 , 0.9987 , 1.003 ] ) # y-intercept coefficients self . bias = ee . Image . constant ( [ - 0.00411 , - 0.00093 , 0.00094 , - 0.0001 , - 0.0015 , - 0.0012 ] ) . multiply ( 10000 ) coll = coll . map ( self . band_pass_adjustment ) self . collection = coll return qa ( self , img ) Custom QA masking method for Sentinel2 surface reflectance dataset Source code in hydrafloods/datasets.py @decorators . carry_metadata def qa ( self , img ): \"\"\"Custom QA masking method for Sentinel2 surface reflectance dataset \"\"\" sclImg = img . select ( \"SCL\" ) # Scene Classification Map mask = sclImg . gte ( 4 ) . And ( sclImg . lte ( 6 )) return img . updateMask ( mask ) hydrafloods.datasets.Landsat8 __init__ ( self , * args , * , asset_id = 'LANDSAT/LC08/C01/T1_SR' , use_qa = True , ** kwargs ) special Initialize Landsat8 Dataset class Can theoretically be useds with any Landsat surface reflectance collection (e.g. LANDSAT/LT05/C01/T1_SR) Parameters: Name Type Description Default *args positional arguments to pass to Dataset (i.e. region , start_time , end_time ) () asset_id str asset id of the Landsat earth engine collection. default=\"LANDSAT/LC08/C01/T1_SR\" 'LANDSAT/LC08/C01/T1_SR' use_qa bool boolean to determine to use a private self.qa() function. default=True True **kwargs optional addtional arbitrary keywords to pass to Dataset {} Source code in hydrafloods/datasets.py def __init__ ( self , * args , asset_id = \"LANDSAT/LC08/C01/T1_SR\" , use_qa = True , ** kwargs ): \"\"\"Initialize Landsat8 Dataset class Can theoretically be useds with any Landsat surface reflectance collection (e.g. LANDSAT/LT05/C01/T1_SR) args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the Landsat earth engine collection. default=\"LANDSAT/LC08/C01/T1_SR\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Landsat8 , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) self . collection = self . collection . select ( self . BANDREMAP . get ( \"landsat8\" ), self . BANDREMAP . get ( \"new\" ) ) return qa ( self , img ) Custom QA masking method for Landsat8 surface reflectance dataset Source code in hydrafloods/datasets.py @decorators . carry_metadata def qa ( self , img ): \"\"\"Custom QA masking method for Landsat8 surface reflectance dataset \"\"\" qa_band = img . select ( \"pixel_qa\" ) qaCloud = geeutils . extract_bits ( qa_band , start = 5 , new_name = \"cloud_mask\" ) . eq ( 0 ) qaShadow = geeutils . extract_bits ( qa_band , start = 3 , new_name = \"shadow_mask\" ) . eq ( 0 ) qaSnow = geeutils . extract_bits ( qa_band , start = 4 , new_name = \"snow_mask\" ) . eq ( 0 ) mask = qaCloud . And ( qaShadow ) . And ( qaSnow ) return img . updateMask ( mask ) hydrafloods.datasets.Landsat7 __init__ ( self , * args , * , asset_id = 'LANDSAT/LE07/C01/T1_SR' , apply_band_adjustment = False , use_qa = True , ** kwargs ) special Initialize Landsat7 Dataset class Can theoretically be useds with any Landsat surface reflectance collection (e.g. LANDSAT/LT05/C01/T1_SR) Parameters: Name Type Description Default *args positional arguments to pass to Dataset (i.e. region , start_time , end_time ) () asset_id str asset id of the Landsat7 earth engine collection. default=\"LANDSAT/LE07/C01/T1_SR\" 'LANDSAT/LE07/C01/T1_SR' apply_band_adjustment bool boolean switch to apply linear band pass equation to convert values to Landsat8. default=False False use_qa bool boolean to determine to use a private self.qa() function. default=True True **kwargs optional addtional arbitrary keywords to pass to Dataset {} Source code in hydrafloods/datasets.py def __init__ ( self , * args , asset_id = \"LANDSAT/LE07/C01/T1_SR\" , apply_band_adjustment = False , use_qa = True , ** kwargs , ): \"\"\"Initialize Landsat7 Dataset class Can theoretically be useds with any Landsat surface reflectance collection (e.g. LANDSAT/LT05/C01/T1_SR) args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the Landsat7 earth engine collection. default=\"LANDSAT/LE07/C01/T1_SR\" apply_band_adjustment (bool, optional): boolean switch to apply linear band pass equation to convert values to Landsat8. default=False use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Landsat7 , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) coll = self . collection . select ( self . BANDREMAP . get ( \"landsat7\" ), self . BANDREMAP . get ( \"new\" ) ) if apply_band_adjustment : # band bass adjustment coefficients taken from Roy et al., 2016 http://dx.doi.org/10.1016/j.rse.2015.12.024 # slope coefficients self . gain = ee . Image . constant ( [ 0.8474 , 0.8483 , 0.9047 , 0.8462 , 0.8937 , 0.9071 ] ) # y-intercept coefficients self . bias = ee . Image . constant ( [ 0.0003 , 0.0088 , 0.0061 , 0.0412 , 0.0254 , 0.0172 ] ) . multiply ( 10000 ) coll = coll . map ( self . band_pass_adjustment ) self . collection = coll return qa ( self , img ) Custom QA masking method for Landsat7 surface reflectance dataset Source code in hydrafloods/datasets.py @decorators . carry_metadata def qa ( self , img ): \"\"\"Custom QA masking method for Landsat7 surface reflectance dataset \"\"\" qa_band = img . select ( \"pixel_qa\" ) qaCloud = geeutils . extract_bits ( qa_band , start = 5 , new_name = \"cloud_mask\" ) . eq ( 0 ) qaShadow = geeutils . extract_bits ( qa_band , start = 3 , new_name = \"shadow_mask\" ) . eq ( 0 ) qaSnow = geeutils . extract_bits ( qa_band , start = 4 , new_name = \"snow_mask\" ) . eq ( 0 ) mask = qaCloud . And ( qaShadow ) # .And(qaSnow) return img . updateMask ( mask ) hydrafloods.datasets.Viirs __init__ ( self , * args , * , asset_id = 'NOAA/VIIRS/001/VNP09GA' , apply_band_adjustment = False , use_qa = True , ** kwargs ) special Initialize VIIRS Dataset class Parameters: Name Type Description Default *args positional arguments to pass to Dataset (i.e. region , start_time , end_time ) () asset_id str asset id of the VIIRS earth engine collection. default=\"NOAA/VIIRS/001/VNP09GA\" 'NOAA/VIIRS/001/VNP09GA' apply_band_adjustment bool boolean switch to apply linear band pass equation to convert values to Landsat8. default=False False use_qa bool boolean to determine to use a private self.qa() function. default=True True **kwargs optional addtional arbitrary keywords to pass to Dataset {} Source code in hydrafloods/datasets.py def __init__ ( self , * args , asset_id = \"NOAA/VIIRS/001/VNP09GA\" , apply_band_adjustment = False , use_qa = True , ** kwargs , ): \"\"\"Initialize VIIRS Dataset class args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the VIIRS earth engine collection. default=\"NOAA/VIIRS/001/VNP09GA\" apply_band_adjustment (bool, optional): boolean switch to apply linear band pass equation to convert values to Landsat8. default=False use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Viirs , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) # get the bands and rename to common optical names coll = self . collection . select ( self . BANDREMAP . get ( \"viirs\" ), self . BANDREMAP . get ( \"new\" ) ) if apply_band_adjustment : # band bass adjustment coefficients taken calculated from https://code.earthengine.google.com/876f53861690e483fb3e3439a3571f27 # slope coefficients self . gain = ee . Image . constant ( [ 0.68328 , 0.66604 , 0.78901 , 0.95324 , 0.98593 , 0.88941 ] ) # y-intercept coefficients self . bias = ee . Image . constant ( [ 0.016728 , 0.030814 , 0.023199 , 0.036571 , 0.026923 , 0.021615 ] ) . multiply ( 10000 ) coll = coll . map ( self . band_pass_adjustment ) self . collection = coll return qa ( self , img ) Custom QA masking method for VIIRS VNP09GA dataset Source code in hydrafloods/datasets.py @decorators . carry_metadata def qa ( self , img ): \"\"\"Custom QA masking method for VIIRS VNP09GA dataset \"\"\" cloudMask = geeutils . extract_bits ( img . select ( \"QF1\" ), 2 , end = 3 , new_name = \"cloud_qa\" ) . lt ( 1 ) shadowMask = geeutils . extract_bits ( img . select ( \"QF2\" ), 3 , new_name = \"shadow_qa\" ) . Not () snowMask = geeutils . extract_bits ( img . select ( \"QF2\" ), 5 , new_name = \"snow_qa\" ) . Not () sensorZenith = img . select ( \"SensorZenith\" ) . abs () . lt ( 6000 ) mask = cloudMask . And ( shadowMask ) . And ( sensorZenith ) return img . updateMask ( mask ) hydrafloods.datasets.Modis __init__ ( self , * args , * , asset_id = 'MODIS/006/MOD09GA' , use_qa = True , ** kwargs ) special Initialize MODIS Dataset class Can be used with MOD09GA and MYD09GA Parameters: Name Type Description Default *args positional arguments to pass to Dataset (i.e. region , start_time , end_time ) () asset_id str asset id of the MODIS earth engine collection. default=\"MODIS/006/MOD09GA\" 'MODIS/006/MOD09GA' use_qa bool boolean to determine to use a private self.qa() function. default=True True **kwargs optional addtional arbitrary keywords to pass to Dataset {} Source code in hydrafloods/datasets.py def __init__ ( self , * args , asset_id = \"MODIS/006/MOD09GA\" , use_qa = True , ** kwargs ): \"\"\"Initialize MODIS Dataset class Can be used with MOD09GA and MYD09GA args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the MODIS earth engine collection. default=\"MODIS/006/MOD09GA\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Modis , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) self . collection = self . collection . select ( self . BANDREMAP . get ( \"modis\" ), self . BANDREMAP . get ( \"new\" ) ) self . clip_to_region ( inplace = True ) return qa ( self , img ) Custom QA masking method for MODIS MXD09GA dataset Source code in hydrafloods/datasets.py @decorators . carry_metadata def qa ( self , img ): \"\"\"Custom QA masking method for MODIS MXD09GA dataset \"\"\" qa = img . select ( \"state_1km\" ) cloudMask = geeutils . extract_bits ( qa , 10 , end = 11 , new_name = \"cloud_qa\" ) . lt ( 1 ) shadowMask = geeutils . extract_bits ( qa , 2 , new_name = \"shadow_qa\" ) . Not () snowMask = geeutils . extract_bits ( qa , 12 , new_name = \"snow_qa\" ) . Not () sensorZenith = img . select ( \"SensorZenith\" ) . abs () . lt ( 6000 ) mask = cloudMask . And ( shadowMask ) . And ( snowMask ) . And ( sensorZenith ) return img . updateMask ( mask )","title":"datasets module"},{"location":"datasets/#hydrafloods.datasets.Dataset","text":"Base dataset class used to define an EE image collection by datetime and geographic region A dataset wraps an ee.ImageCollection by applying the spatial and temporal filtering upon init. Provides utility functionality to make working with and managing image collections less verbose Examples: Create a dataset object for Sentinel-1 data over Alabama for 2019 >>> ds = Dataset ( ... region = ee . Geometry . Rectangle ([ - 88.473227 , 30.223334 , - 84.88908 , 35.008028 ]), ... start_time = \"2019-01-01\" , ... end_time = \"2020-01-01\" , ... asset_id = \"COPERNICUS/S1_GRD\" ... ) >>> ds HYDRAFloods Dataset : { 'asset_id' : 'COPERNICUS/S1_GRD' , 'end_time' : '2020-01-01' , 'name' : 'Dataset' , 'region' : [[[ ... ], [ ... ], [ ... ], [ ... ], [ ... ]]], 'start_time' : '2019-01-01' }","title":"Dataset"},{"location":"datasets/#hydrafloods.datasets.Dataset.collection","text":"image collection object property wrapped by dataset","title":"collection"},{"location":"datasets/#hydrafloods.datasets.Dataset.dates","text":"Dates of imagery contained in the image collection","title":"dates"},{"location":"datasets/#hydrafloods.datasets.Dataset.n_images","text":"Number of images contained in the dataset","title":"n_images"},{"location":"datasets/#hydrafloods.datasets.Dataset.__init__","text":"Initialize Dataset class Parameters: Name Type Description Default region ee.Geometry earth engine geometry object to filter image collection by required start_time str | datetime.datetime start time used to filter image collection required end_time str | datetime.datetime end time used to filter image collection required asset_id str asset id of earth engine collection required use_qa bool boolean to determine to use an internal function qa(). Used for definining custom dataset objects False Exceptions: Type Description AttributeError if qa() method is not defined and use_qa is True Source code in hydrafloods/datasets.py def __init__ ( self , region , start_time , end_time , asset_id , use_qa = False ): \"\"\"Initialize Dataset class args: region (ee.Geometry): earth engine geometry object to filter image collection by start_time (str | datetime.datetime): start time used to filter image collection end_time (str | datetime.datetime): end time used to filter image collection asset_id (str): asset id of earth engine collection use_qa (bool, optional): boolean to determine to use an internal function qa(). Used for definining custom dataset objects raises: AttributeError: if qa() method is not defined and use_qa is True \"\"\" # TODO: add exceptions to check datatypes self . region = region # dtype = ee.Geometry self . start_time = start_time self . end_time = end_time self . asset_id = asset_id self . use_qa = use_qa # dictionary mapping of band names used to harmonized optical datasets to same names self . BANDREMAP = ee . Dictionary ( { \"landsat7\" : ee . List ([ \"B1\" , \"B2\" , \"B3\" , \"B4\" , \"B5\" , \"B7\" ]), \"landsat8\" : ee . List ([ \"B2\" , \"B3\" , \"B4\" , \"B5\" , \"B6\" , \"B7\" ]), \"viirs\" : ee . List ([ \"M2\" , \"M4\" , \"I1\" , \"I2\" , \"I3\" , \"M11\" ]), \"sen2\" : ee . List ([ \"B2\" , \"B3\" , \"B4\" , \"B8\" , \"B11\" , \"B12\" ]), \"modis\" : ee . List ( [ \"sur_refl_b03\" , \"sur_refl_b04\" , \"sur_refl_b01\" , \"sur_refl_b02\" , \"sur_refl_b06\" , \"sur_refl_b07\" , ] ), \"new\" : ee . List ([ \"blue\" , \"green\" , \"red\" , \"nir\" , \"swir1\" , \"swir2\" ]), } ) # get the image collection and filter by geographic region and date time imgcollection = ( ee . ImageCollection ( self . asset_id ) . filterBounds ( self . region ) . filterDate ( self . start_time , self . end_time ) ) # check if to apply arbitrary qa process on collection # qa function can be defined in custom objects extending dataset if self . use_qa : try : imgcollection = imgcollection . map ( self . qa ) except AttributeError : raise AttributeError ( \"qa() method is not defined...please define one or set `use_qa` to False\" ) self . collection = imgcollection","title":"__init__()"},{"location":"datasets/#hydrafloods.datasets.Dataset.aggregate_time","text":"Aggregates multiple images into one based on time periods and a user defined reducer. Useful for mosaicing images from same date or time period. Expects the images in this dataset to be homogenous (same band names and types) Parameters: Name Type Description Default dates list[str] list of dates defined as beginning time period of aggregatation. default = None, all available uniques dates in collection will be used None period int number of days to advance from dates for aggregation. default = 1 1 reducer str | ee.Reducer reducer to apply to images for aggregation, accepts string reducer name or ee.Reducer opbject, default = \"mean\" 'mean' clip_to_area bool switch to clip imagery that has been merged to the overlaping region of imagery, default=False False inplace bool define whether to return another dataset object or update inplace. default = False False Returns: Type Description Dataset | None returns dataset.collection with aggregated imagery or none depending on inplace Source code in hydrafloods/datasets.py def aggregate_time ( self , dates = None , period = 1 , reducer = \"mean\" , clip_to_area = False , inplace = False ): \"\"\"Aggregates multiple images into one based on time periods and a user defined reducer. Useful for mosaicing images from same date or time period. Expects the images in this dataset to be homogenous (same band names and types) args: dates (list[str], optional): list of dates defined as beginning time period of aggregatation. default = None, all available uniques dates in collection will be used period (int, optional): number of days to advance from dates for aggregation. default = 1 reducer (str | ee.Reducer, optional): reducer to apply to images for aggregation, accepts string reducer name or ee.Reducer opbject, default = \"mean\" clip_to_area (bool): switch to clip imagery that has been merged to the overlaping region of imagery, default=False inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset.collection with aggregated imagery or none depending on inplace \"\"\" def _aggregation ( d ): \"\"\"Closure function to map through days and reduce data within a given time period \"\"\" t1 = ee . Date ( d ) t2 = t1 . advance ( period , \"day\" ) img = ( self . collection . filterDate ( t1 , t2 ) . reduce ( reducer ) . rename ( band_names ) . set ( \"system:time_start\" , t1 . millis ()) ) geom = ( ee . FeatureCollection ( self . collection . filterDate ( t1 , t2 ) . map ( geeutils . get_geoms ) ) . union ( 100 ) . geometry ( 100 ) ) outimg = ee . Algorithms . If ( clip_to_area , img . clip ( geom ), img ) return outimg if dates is None : dates = ( self . collection . aggregate_array ( \"system:time_start\" ) . map ( lambda x : ee . Date ( x ) . format ( \"YYYY-MM-dd\" )) . distinct () ) else : dates = ee . List ( dates ) band_names = ee . Image ( self . collection . first ()) . bandNames () out_coll = ee . ImageCollection . fromImages ( dates . map ( _aggregation )) if inplace : self . collection = out_coll return else : outCls = self . copy () outCls . collection = out_coll return outCls","title":"aggregate_time()"},{"location":"datasets/#hydrafloods.datasets.Dataset.apply_func","text":"Wrapper method to apply a function to all of the image in the dataset. Makes a copy of the collection and reassigns the image collection propety. Function must accept an ee.ImageCollection and return an ee.ImageCollection Parameters: Name Type Description Default func object Function to map across image collection. Function must accept ee.Image as first argument required inplace bool define whether to return another dataset object or update inplace. default = False False **kwargs arbitrary keyword to pass to func {} Returns: Type Description Dataset | None copy of class with results from func as image within collection property Source code in hydrafloods/datasets.py def apply_func ( self , func , inplace = False , * args , ** kwargs ): \"\"\"Wrapper method to apply a function to all of the image in the dataset. Makes a copy of the collection and reassigns the image collection propety. Function must accept an ee.ImageCollection and return an ee.ImageCollection Args: func (object): Function to map across image collection. Function must accept ee.Image as first argument inplace (bool, optional): define whether to return another dataset object or update inplace. default = False **kwargs: arbitrary keyword to pass to `func` Returns: Dataset | None: copy of class with results from `func` as image within collection property \"\"\" # get a partial function to map over imagery with the keywords applied # expects that the first positional arg is an func = partial ( func , ** kwargs ) if inplace : self . collection = self . collection . map ( func ) return else : outCls = self . copy () outCls . collection = self . collection . map ( func ) return outCls","title":"apply_func()"},{"location":"datasets/#hydrafloods.datasets.Dataset.band_pass_adjustment","text":"Method to apply linear band transformation to dataset image collection. Expects that dataset has properties self.gain and self.bias set Parameters: Name Type Description Default img ee.Image image to apply regression on required Source code in hydrafloods/datasets.py @decorators . carry_metadata def band_pass_adjustment ( self , img ): \"\"\"Method to apply linear band transformation to dataset image collection. Expects that dataset has properties `self.gain` and `self.bias` set args: img (ee.Image): image to apply regression on \"\"\" # linear regression coefficients for adjustment return ( img . multiply ( self . gain ) . add ( self . bias ) . set ( \"system:time_start\" , img . get ( \"system:time_start\" )) )","title":"band_pass_adjustment()"},{"location":"datasets/#hydrafloods.datasets.Dataset.clip_to_region","text":"Clips all of the images to the geographic extent defined by region. Useful for setting geometries on unbounded imagery in collection (e.g. MODIS or VIIRS imagery) Parameters: Name Type Description Default inplace bool define whether to return another dataset object or update inplace. default = False False Returns: Type Description Dataset | None returns dataset with imagery clipped to self.region or none depending on inplace Source code in hydrafloods/datasets.py def clip_to_region ( self , inplace = False ): \"\"\"Clips all of the images to the geographic extent defined by region. Useful for setting geometries on unbounded imagery in collection (e.g. MODIS or VIIRS imagery) args: inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset with imagery clipped to self.region or none depending on inplace \"\"\" @decorators . carry_metadata def clip ( img ): \"\"\"Closure function to perform the clipping while carrying metadata \"\"\" return ee . Image ( img . clip ( self . region )) if inplace : self . collection = self . collection . map ( clip ) return else : outCls = self . copy () outCls . collection = self . collection . map ( clip ) return outCls","title":"clip_to_region()"},{"location":"datasets/#hydrafloods.datasets.Dataset.copy","text":"Returns a deep copy of the hydrafloods dataset class Source code in hydrafloods/datasets.py def copy ( self ): \"\"\"Returns a deep copy of the hydrafloods dataset class \"\"\" return copy . deepcopy ( self )","title":"copy()"},{"location":"datasets/#hydrafloods.datasets.Dataset.join","text":"Performs spatiotemporal join between self.collection and dataset.collection. Result will be a dataset where the collection is colocated imagery in space and time Parameters: Name Type Description Default dataset Dataset dataset object to apply join with. Used as right in join operations required inplace bool define whether to return another dataset object or update inplace. default = False False Returns: Type Description Dataset | None returns dataset where collection with joined imagery or none depending on inplace Source code in hydrafloods/datasets.py def join ( self , dataset , inplace = False ): \"\"\"Performs spatiotemporal join between self.collection and dataset.collection. Result will be a dataset where the collection is colocated imagery in space and time args: dataset (Dataset): dataset object to apply join with. Used as right in join operations inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset where collection with joined imagery or none depending on inplace \"\"\" def _merge ( img ): \"\"\"Closure func to take results from the join and combine into one image with overlaping region \"\"\" join_coll = ee . ImageCollection . fromImages ( img . get ( key )) img_geom = img . geometry ( 100 ) join_geom = join_coll . map ( geeutils . get_geoms ) . union ( 100 ) . geometry ( 100 ) overlap = img_geom . intersection ( join_geom , 100 ) join_data = join_coll . mosaic () return img . addBands ( join_data ) . clip ( overlap ) key = str ( dataset . __class__ . __name__ ) # get a time and space filter filter = ee . Filter . And ( ee . Filter . maxDifference ( ** { \"difference\" : 1000 * 60 * 60 * 24 , # One day in milliseconds \"leftField\" : \"system:time_start\" , \"rightField\" : \"system:time_start\" , } ), ee . Filter . intersects ( ** { \"leftField\" : \".geo\" , \"rightField\" : \".geo\" , \"maxError\" : 100 } ), ) # apply join on collections and save all results joined = ee . ImageCollection ( ee . Join . saveAll ( key ) . apply ( primary = self . collection , secondary = dataset . collection , condition = filter ) ) # map over all filtered imagery, mosaic joined matches, and add bands to imagery joined = joined . map ( _merge ) if inplace : self . collection = joined return else : outCls = self . copy () outCls . collection = joined return outCls","title":"join()"},{"location":"datasets/#hydrafloods.datasets.Dataset.merge","text":"Merge the collection of two datasets into one where self.collection will contain imagery from self and dataset arg. Results will be sorted by time Parameters: Name Type Description Default dataset Dataset dataset object to merge required inplace bool define whether to return another dataset object or update inplace. default = False False Returns: Type Description Dataset | None returns dataset where collection is merged imagery or none depending on inplace Source code in hydrafloods/datasets.py def merge ( self , dataset , inplace = False ): \"\"\"Merge the collection of two datasets into one where self.collection will contain imagery from self and dataset arg. Results will be sorted by time args: dataset (Dataset): dataset object to merge inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset where collection is merged imagery or none depending on inplace \"\"\" merged = self . collection . merge ( dataset . collection ) . sort ( \"system:time_start\" ) if inplace : self . collection = merged return else : outCls = self . copy () outCls . collection = merged return outCls","title":"merge()"},{"location":"datasets/#hydrafloods.datasets.Sentinel1","text":"Class extending dataset for the Sentinel 1 collection","title":"Sentinel1"},{"location":"datasets/#hydrafloods.datasets.Sentinel1.__init__","text":"Initialize Sentinel1 Dataset class Parameters: Name Type Description Default *args positional arguments to pass to Dataset (i.e. region , start_time , end_time ) () asset_id str asset id of the Sentinel 1 earth engine collection. default=\"COPERNICUS/S1_GRD\" 'COPERNICUS/S1_GRD' use_qa bool boolean to determine to use a private self.qa() function. default=True True **kwargs optional addtional arbitrary keywords to pass to Dataset {} Source code in hydrafloods/datasets.py def __init__ ( self , * args , asset_id = \"COPERNICUS/S1_GRD\" , use_qa = True , ** kwargs ): \"\"\"Initialize Sentinel1 Dataset class args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the Sentinel 1 earth engine collection. default=\"COPERNICUS/S1_GRD\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Sentinel1 , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) self . collection = self . collection . filter ( ee . Filter . listContains ( \"transmitterReceiverPolarisation\" , \"VH\" ) ) return","title":"__init__()"},{"location":"datasets/#hydrafloods.datasets.Sentinel1.add_fusion_features","text":"Method to add additional features to SAR imagery for data fusion. Will calculate Normalized Difference Polorization Index (VV-VH)/(VV+VH), VV/VH ratio, and categorical orbit bands Returns: Type Description Dataset | None returns dataset.collection where imagery has the added bands Source code in hydrafloods/datasets.py def add_fusion_features ( self , inplace = False ): \"\"\"Method to add additional features to SAR imagery for data fusion. Will calculate Normalized Difference Polorization Index (VV-VH)/(VV+VH), VV/VH ratio, and categorical orbit bands returns: Dataset | None: returns dataset.collection where imagery has the added bands \"\"\" def _add_fusion_features ( img ): \"\"\"Closure function to add features as bands to the images \"\"\" bounds = img . geometry ( 100 ) orbit = ee . String ( img . get ( \"orbitProperties_pass\" )) orbit_band = ee . Algorithms . If ( orbit . compareTo ( \"DESCENDING\" ), ee . Image ( 1 ), ee . Image ( 0 ) ) vv = img . select ( \"VV\" ) vh = img . select ( \"VH\" ) ratio = vv . divide ( vh ) . rename ( \"ratio\" ) ndpi = vv . subtract ( vh ) . divide ( vv . add ( vh )) . rename ( \"ndpi\" ) extraFeatures = ee . Image . cat ( [ ee . Image ( orbit_band ) . rename ( \"orbit\" ), ratio , ndpi ] ) return img . addBands ( extraFeatures . clip ( bounds )) return self . apply_func ( _add_fusion_features , inplace = inplace )","title":"add_fusion_features()"},{"location":"datasets/#hydrafloods.datasets.Sentinel1.qa","text":"Custom QA masking method for Sentinel2 surface reflectance dataset Source code in hydrafloods/datasets.py @decorators . carry_metadata def qa ( self , img ): \"\"\"Custom QA masking method for Sentinel2 surface reflectance dataset \"\"\" angles = img . select ( \"angle\" ) return img . updateMask ( angles . lt ( 45 ) . And ( angles . gt ( 30 )))","title":"qa()"},{"location":"datasets/#hydrafloods.datasets.Sentinel2","text":"","title":"Sentinel2"},{"location":"datasets/#hydrafloods.datasets.Sentinel2.__init__","text":"Initialize Sentinel2 Dataset class Parameters: Name Type Description Default *args positional arguments to pass to Dataset (i.e. region , start_time , end_time ) () asset_id str asset id of the Sentinel2 earth engine collection. default=\"COPERNICUS/S2_SR\" 'COPERNICUS/S2_SR' apply_band_adjustment bool boolean switch to apply linear band pass equation to convert values to Landsat8. default=False False use_qa bool boolean to determine to use a private self.qa() function. default=True True **kwargs optional addtional arbitrary keywords to pass to Dataset {} Source code in hydrafloods/datasets.py def __init__ ( self , * args , asset_id = \"COPERNICUS/S2_SR\" , apply_band_adjustment = False , use_qa = True , ** kwargs , ): \"\"\"Initialize Sentinel2 Dataset class args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the Sentinel2 earth engine collection. default=\"COPERNICUS/S2_SR\" apply_band_adjustment (bool, optional): boolean switch to apply linear band pass equation to convert values to Landsat8. default=False use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Sentinel2 , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) coll = self . collection . select ( self . BANDREMAP . get ( \"sen2\" ), self . BANDREMAP . get ( \"new\" ) ) if apply_band_adjustment : # band bass adjustment coefficients taken HLS project https://hls.gsfc.nasa.gov/algorithms/bandpass-adjustment/ # slope coefficients self . gain = ee . Image . constant ( [ 0.9778 , 1.0053 , 0.9765 , 0.9983 , 0.9987 , 1.003 ] ) # y-intercept coefficients self . bias = ee . Image . constant ( [ - 0.00411 , - 0.00093 , 0.00094 , - 0.0001 , - 0.0015 , - 0.0012 ] ) . multiply ( 10000 ) coll = coll . map ( self . band_pass_adjustment ) self . collection = coll return","title":"__init__()"},{"location":"datasets/#hydrafloods.datasets.Sentinel2.qa","text":"Custom QA masking method for Sentinel2 surface reflectance dataset Source code in hydrafloods/datasets.py @decorators . carry_metadata def qa ( self , img ): \"\"\"Custom QA masking method for Sentinel2 surface reflectance dataset \"\"\" sclImg = img . select ( \"SCL\" ) # Scene Classification Map mask = sclImg . gte ( 4 ) . And ( sclImg . lte ( 6 )) return img . updateMask ( mask )","title":"qa()"},{"location":"datasets/#hydrafloods.datasets.Landsat8","text":"","title":"Landsat8"},{"location":"datasets/#hydrafloods.datasets.Landsat8.__init__","text":"Initialize Landsat8 Dataset class Can theoretically be useds with any Landsat surface reflectance collection (e.g. LANDSAT/LT05/C01/T1_SR) Parameters: Name Type Description Default *args positional arguments to pass to Dataset (i.e. region , start_time , end_time ) () asset_id str asset id of the Landsat earth engine collection. default=\"LANDSAT/LC08/C01/T1_SR\" 'LANDSAT/LC08/C01/T1_SR' use_qa bool boolean to determine to use a private self.qa() function. default=True True **kwargs optional addtional arbitrary keywords to pass to Dataset {} Source code in hydrafloods/datasets.py def __init__ ( self , * args , asset_id = \"LANDSAT/LC08/C01/T1_SR\" , use_qa = True , ** kwargs ): \"\"\"Initialize Landsat8 Dataset class Can theoretically be useds with any Landsat surface reflectance collection (e.g. LANDSAT/LT05/C01/T1_SR) args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the Landsat earth engine collection. default=\"LANDSAT/LC08/C01/T1_SR\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Landsat8 , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) self . collection = self . collection . select ( self . BANDREMAP . get ( \"landsat8\" ), self . BANDREMAP . get ( \"new\" ) ) return","title":"__init__()"},{"location":"datasets/#hydrafloods.datasets.Landsat8.qa","text":"Custom QA masking method for Landsat8 surface reflectance dataset Source code in hydrafloods/datasets.py @decorators . carry_metadata def qa ( self , img ): \"\"\"Custom QA masking method for Landsat8 surface reflectance dataset \"\"\" qa_band = img . select ( \"pixel_qa\" ) qaCloud = geeutils . extract_bits ( qa_band , start = 5 , new_name = \"cloud_mask\" ) . eq ( 0 ) qaShadow = geeutils . extract_bits ( qa_band , start = 3 , new_name = \"shadow_mask\" ) . eq ( 0 ) qaSnow = geeutils . extract_bits ( qa_band , start = 4 , new_name = \"snow_mask\" ) . eq ( 0 ) mask = qaCloud . And ( qaShadow ) . And ( qaSnow ) return img . updateMask ( mask )","title":"qa()"},{"location":"datasets/#hydrafloods.datasets.Landsat7","text":"","title":"Landsat7"},{"location":"datasets/#hydrafloods.datasets.Landsat7.__init__","text":"Initialize Landsat7 Dataset class Can theoretically be useds with any Landsat surface reflectance collection (e.g. LANDSAT/LT05/C01/T1_SR) Parameters: Name Type Description Default *args positional arguments to pass to Dataset (i.e. region , start_time , end_time ) () asset_id str asset id of the Landsat7 earth engine collection. default=\"LANDSAT/LE07/C01/T1_SR\" 'LANDSAT/LE07/C01/T1_SR' apply_band_adjustment bool boolean switch to apply linear band pass equation to convert values to Landsat8. default=False False use_qa bool boolean to determine to use a private self.qa() function. default=True True **kwargs optional addtional arbitrary keywords to pass to Dataset {} Source code in hydrafloods/datasets.py def __init__ ( self , * args , asset_id = \"LANDSAT/LE07/C01/T1_SR\" , apply_band_adjustment = False , use_qa = True , ** kwargs , ): \"\"\"Initialize Landsat7 Dataset class Can theoretically be useds with any Landsat surface reflectance collection (e.g. LANDSAT/LT05/C01/T1_SR) args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the Landsat7 earth engine collection. default=\"LANDSAT/LE07/C01/T1_SR\" apply_band_adjustment (bool, optional): boolean switch to apply linear band pass equation to convert values to Landsat8. default=False use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Landsat7 , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) coll = self . collection . select ( self . BANDREMAP . get ( \"landsat7\" ), self . BANDREMAP . get ( \"new\" ) ) if apply_band_adjustment : # band bass adjustment coefficients taken from Roy et al., 2016 http://dx.doi.org/10.1016/j.rse.2015.12.024 # slope coefficients self . gain = ee . Image . constant ( [ 0.8474 , 0.8483 , 0.9047 , 0.8462 , 0.8937 , 0.9071 ] ) # y-intercept coefficients self . bias = ee . Image . constant ( [ 0.0003 , 0.0088 , 0.0061 , 0.0412 , 0.0254 , 0.0172 ] ) . multiply ( 10000 ) coll = coll . map ( self . band_pass_adjustment ) self . collection = coll return","title":"__init__()"},{"location":"datasets/#hydrafloods.datasets.Landsat7.qa","text":"Custom QA masking method for Landsat7 surface reflectance dataset Source code in hydrafloods/datasets.py @decorators . carry_metadata def qa ( self , img ): \"\"\"Custom QA masking method for Landsat7 surface reflectance dataset \"\"\" qa_band = img . select ( \"pixel_qa\" ) qaCloud = geeutils . extract_bits ( qa_band , start = 5 , new_name = \"cloud_mask\" ) . eq ( 0 ) qaShadow = geeutils . extract_bits ( qa_band , start = 3 , new_name = \"shadow_mask\" ) . eq ( 0 ) qaSnow = geeutils . extract_bits ( qa_band , start = 4 , new_name = \"snow_mask\" ) . eq ( 0 ) mask = qaCloud . And ( qaShadow ) # .And(qaSnow) return img . updateMask ( mask )","title":"qa()"},{"location":"datasets/#hydrafloods.datasets.Viirs","text":"","title":"Viirs"},{"location":"datasets/#hydrafloods.datasets.Viirs.__init__","text":"Initialize VIIRS Dataset class Parameters: Name Type Description Default *args positional arguments to pass to Dataset (i.e. region , start_time , end_time ) () asset_id str asset id of the VIIRS earth engine collection. default=\"NOAA/VIIRS/001/VNP09GA\" 'NOAA/VIIRS/001/VNP09GA' apply_band_adjustment bool boolean switch to apply linear band pass equation to convert values to Landsat8. default=False False use_qa bool boolean to determine to use a private self.qa() function. default=True True **kwargs optional addtional arbitrary keywords to pass to Dataset {} Source code in hydrafloods/datasets.py def __init__ ( self , * args , asset_id = \"NOAA/VIIRS/001/VNP09GA\" , apply_band_adjustment = False , use_qa = True , ** kwargs , ): \"\"\"Initialize VIIRS Dataset class args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the VIIRS earth engine collection. default=\"NOAA/VIIRS/001/VNP09GA\" apply_band_adjustment (bool, optional): boolean switch to apply linear band pass equation to convert values to Landsat8. default=False use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Viirs , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) # get the bands and rename to common optical names coll = self . collection . select ( self . BANDREMAP . get ( \"viirs\" ), self . BANDREMAP . get ( \"new\" ) ) if apply_band_adjustment : # band bass adjustment coefficients taken calculated from https://code.earthengine.google.com/876f53861690e483fb3e3439a3571f27 # slope coefficients self . gain = ee . Image . constant ( [ 0.68328 , 0.66604 , 0.78901 , 0.95324 , 0.98593 , 0.88941 ] ) # y-intercept coefficients self . bias = ee . Image . constant ( [ 0.016728 , 0.030814 , 0.023199 , 0.036571 , 0.026923 , 0.021615 ] ) . multiply ( 10000 ) coll = coll . map ( self . band_pass_adjustment ) self . collection = coll return","title":"__init__()"},{"location":"datasets/#hydrafloods.datasets.Viirs.qa","text":"Custom QA masking method for VIIRS VNP09GA dataset Source code in hydrafloods/datasets.py @decorators . carry_metadata def qa ( self , img ): \"\"\"Custom QA masking method for VIIRS VNP09GA dataset \"\"\" cloudMask = geeutils . extract_bits ( img . select ( \"QF1\" ), 2 , end = 3 , new_name = \"cloud_qa\" ) . lt ( 1 ) shadowMask = geeutils . extract_bits ( img . select ( \"QF2\" ), 3 , new_name = \"shadow_qa\" ) . Not () snowMask = geeutils . extract_bits ( img . select ( \"QF2\" ), 5 , new_name = \"snow_qa\" ) . Not () sensorZenith = img . select ( \"SensorZenith\" ) . abs () . lt ( 6000 ) mask = cloudMask . And ( shadowMask ) . And ( sensorZenith ) return img . updateMask ( mask )","title":"qa()"},{"location":"datasets/#hydrafloods.datasets.Modis","text":"","title":"Modis"},{"location":"datasets/#hydrafloods.datasets.Modis.__init__","text":"Initialize MODIS Dataset class Can be used with MOD09GA and MYD09GA Parameters: Name Type Description Default *args positional arguments to pass to Dataset (i.e. region , start_time , end_time ) () asset_id str asset id of the MODIS earth engine collection. default=\"MODIS/006/MOD09GA\" 'MODIS/006/MOD09GA' use_qa bool boolean to determine to use a private self.qa() function. default=True True **kwargs optional addtional arbitrary keywords to pass to Dataset {} Source code in hydrafloods/datasets.py def __init__ ( self , * args , asset_id = \"MODIS/006/MOD09GA\" , use_qa = True , ** kwargs ): \"\"\"Initialize MODIS Dataset class Can be used with MOD09GA and MYD09GA args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the MODIS earth engine collection. default=\"MODIS/006/MOD09GA\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Modis , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) self . collection = self . collection . select ( self . BANDREMAP . get ( \"modis\" ), self . BANDREMAP . get ( \"new\" ) ) self . clip_to_region ( inplace = True ) return","title":"__init__()"},{"location":"datasets/#hydrafloods.datasets.Modis.qa","text":"Custom QA masking method for MODIS MXD09GA dataset Source code in hydrafloods/datasets.py @decorators . carry_metadata def qa ( self , img ): \"\"\"Custom QA masking method for MODIS MXD09GA dataset \"\"\" qa = img . select ( \"state_1km\" ) cloudMask = geeutils . extract_bits ( qa , 10 , end = 11 , new_name = \"cloud_qa\" ) . lt ( 1 ) shadowMask = geeutils . extract_bits ( qa , 2 , new_name = \"shadow_qa\" ) . Not () snowMask = geeutils . extract_bits ( qa , 12 , new_name = \"snow_qa\" ) . Not () sensorZenith = img . select ( \"SensorZenith\" ) . abs () . lt ( 6000 ) mask = cloudMask . And ( shadowMask ) . And ( snowMask ) . And ( sensorZenith ) return img . updateMask ( mask )","title":"qa()"},{"location":"decorators/","text":"hydrafloods.decorators carry_metadata ( func ) Decorator function to set the properties of an image from computations to that of the input Function to decorate should take an ee.Image object and return an ee.Image object Parameters: Name Type Description Default func object function object to wrap. Expects that an element within args is of type ee.Image and will use first ee.Image to carry metadata required Examples: @decorators . carry_metadata def ndvi ( img ): return img . normalizedDifference ([ b1 , b2 ]) Returned image(s) will have all of the same metadata properties as the input including system:time_start Source code in hydrafloods/decorators.py def carry_metadata ( func ): \"\"\"Decorator function to set the properties of an image from computations to that of the input Function to decorate should take an ee.Image object and return an ee.Image object args: func (object): function object to wrap. Expects that an element within args is of type ee.Image and will use first ee.Image to carry metadata Example: ```python @decorators.carry_metadata def ndvi(img): return img.normalizedDifference([b1,b2]) ``` Returned image(s) will have all of the same metadata properties as the input including `system:time_start` \"\"\" @functools . wraps ( func ) def wrapper ( * args , ** kwargs ): # expects an element within args is img # will set the metadata to first ee.Image instance # this assumption is true for 99% of fuctions used for ee.ImageCollection.map() result = ee . Image ( func ( * args , ** kwargs )) img = [ i for i in args if isinstance ( i , ee . Image )][ 0 ] return ee . Image ( result . copyProperties ( img ) . set ( \"system:time_start\" , img . get ( \"system:time_start\" ) ) ) return wrapper","title":"decorators module"},{"location":"decorators/#hydrafloods.decorators","text":"","title":"decorators"},{"location":"decorators/#hydrafloods.decorators.carry_metadata","text":"Decorator function to set the properties of an image from computations to that of the input Function to decorate should take an ee.Image object and return an ee.Image object Parameters: Name Type Description Default func object function object to wrap. Expects that an element within args is of type ee.Image and will use first ee.Image to carry metadata required Examples: @decorators . carry_metadata def ndvi ( img ): return img . normalizedDifference ([ b1 , b2 ]) Returned image(s) will have all of the same metadata properties as the input including system:time_start Source code in hydrafloods/decorators.py def carry_metadata ( func ): \"\"\"Decorator function to set the properties of an image from computations to that of the input Function to decorate should take an ee.Image object and return an ee.Image object args: func (object): function object to wrap. Expects that an element within args is of type ee.Image and will use first ee.Image to carry metadata Example: ```python @decorators.carry_metadata def ndvi(img): return img.normalizedDifference([b1,b2]) ``` Returned image(s) will have all of the same metadata properties as the input including `system:time_start` \"\"\" @functools . wraps ( func ) def wrapper ( * args , ** kwargs ): # expects an element within args is img # will set the metadata to first ee.Image instance # this assumption is true for 99% of fuctions used for ee.ImageCollection.map() result = ee . Image ( func ( * args , ** kwargs )) img = [ i for i in args if isinstance ( i , ee . Image )][ 0 ] return ee . Image ( result . copyProperties ( img ) . set ( \"system:time_start\" , img . get ( \"system:time_start\" ) ) ) return wrapper","title":"carry_metadata()"},{"location":"fetch/","text":"hydrafloods.fetch atms ( credentials , start_time = '2000-01-01' , end_time = None , region = [ - 180 , 60 , 180 , 85 ], out_directory = './' ) Function to download Suomi-NPP ATMS passive microwave data for specified time and region, wraps fetching() Parameters: Name Type Description Default credentials tuple | list EarthData username and password login credentials as iterable required start_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = 2000-01-01 '2000-01-01' end_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = start_time + 1day None region tuple | list Bounding box of region to search as iterable in W,S,E,N order default = [-180,60,180,85] [-180, 60, 180, 85] out_directory str | pathlib.Path, optioanl Local directory to downaload data to default = \"./\" './' Returns: Type Description list[pathlib.Path] List of local paths that data was downloaded to Source code in hydrafloods/fetch.py def atms ( credentials , start_time = \"2000-01-01\" , end_time = None , region = [ - 180 , 60 , 180 , 85 ], out_directory = \"./\" , ): \"\"\" Function to download Suomi-NPP ATMS passive microwave data for specified time and region, wraps `fetching()` args: credentials (tuple | list): EarthData username and password login credentials as iterable start_time (str, optional): Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = 2000-01-01 end_time (str, optional): Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = start_time + 1day region (tuple | list, optional): Bounding box of region to search as iterable in W,S,E,N order default = [-180,60,180,85] out_directory (str | pathlib.Path, optioanl): Local directory to downaload data to default = \"./\" returns: list[pathlib.Path]: List of local paths that data was downloaded to \"\"\" CONCEPTID = \"C1442068516-GES_DISC\" return fetching ( conceptid = CONCEPTID , start_time = start_time , region = region , credentials = credentials , out_directory = out_directory , max_results = 500 , end_time = end_time , ) fetching ( conceptid , start_time , region , credentials , out_directory , max_results = 500 , end_time = None ) Function to download data from NASA CMR by specifying a dataset, time and region. Uses CMR to handle spatio-temporal query and extracts data download urls Parameters: Name Type Description Default conceptid str String of dataset concept id to search for required start_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd) required region tuple[float] | list[float] Bounding box of region to search as iterable in W,S,E,N order required credentials tuple | list EarthData username and password login credentials as iterable required out_directory str|pathlib.Path Local directory to downaload data to required max_results int Maximum number of items to search and download. default = 500 500 end_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd). default = start_time + 1day None Returns: Type Description list[pathlib.Path] List of local paths that data was downloaded to Source code in hydrafloods/fetch.py def fetching ( conceptid , start_time , region , credentials , out_directory , max_results = 500 , end_time = None , ): \"\"\" Function to download data from NASA CMR by specifying a dataset, time and region. Uses CMR to handle spatio-temporal query and extracts data download urls args: conceptid (str): String of dataset concept id to search for start_time (str): Date as string preferrably as ISO8601 format (YYYY-MM-dd) region (tuple[float] | list[float]): Bounding box of region to search as iterable in W,S,E,N order credentials (tuple | list): EarthData username and password login credentials as iterable out_directory (str|pathlib.Path): Local directory to downaload data to max_results (int, optional): Maximum number of items to search and download. default = 500 end_time (str, optional): Date as string preferrably as ISO8601 format (YYYY-MM-dd). default = start_time + 1day returns: list[pathlib.Path]: List of local paths that data was downloaded to \"\"\" if type ( start_time ) != datetime . datetime : start_time = scmr . utils . decode_date ( start_time ) if end_time is None : end_time = start_time + datetime . timedelta ( seconds = 86399 ) else : end_time = scmr . utils . decode_date ( end_time ) # construct query query = scmr . Query ( conceptid = conceptid , startTime = start_time , endTime = end_time , spatialExtent = region , maxResults = max_results , ) # fetch datasets from query query . granules . fetch ( credentials = credentials , directory = out_directory , limit = max_results , maxWorkers = 4 , ) # return a list of the granules for later processing return query . granules . getLocalPaths ( directory = out_directory ) modis ( credentials , start_time = '2000-01-01' , end_time = None , region = [ - 180 , 60 , 180 , 85 ], out_directory = './' ) Function to download MODIS surface reflectance data for specified time and region, wraps fetching() Parameters: Name Type Description Default credentials tuple | list EarthData username and password login credentials as iterable required start_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = 2000-01-01 '2000-01-01' end_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = start_time + 1day None region tuple[float] | list[float] Bounding box of region to search as iterable in W,S,E,N order default = [-180,60,180,85] [-180, 60, 180, 85] out_directory str | pathlib.Path Local directory to downaload data to default = \"./\" './' Returns: Type Description list[pathlib.Path] List of local paths that data was downloaded to Source code in hydrafloods/fetch.py def modis ( credentials , start_time = \"2000-01-01\" , end_time = None , region = [ - 180 , 60 , 180 , 85 ], out_directory = \"./\" , ): \"\"\"Function to download MODIS surface reflectance data for specified time and region, wraps `fetching()` args: credentials (tuple | list): EarthData username and password login credentials as iterable start_time (str, optional): Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = 2000-01-01 end_time (str, optional): Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = start_time + 1day region (tuple[float] | list[float], optional): Bounding box of region to search as iterable in W,S,E,N order default = [-180,60,180,85] out_directory (str | pathlib.Path, optional): Local directory to downaload data to default = \"./\" returns: list[pathlib.Path]: List of local paths that data was downloaded to \"\"\" # check if date requested is within science-quality production time now = datetime . datetime . now () offset = now - scmr . utils . decode_date ( start_time ) if offset . days > 4 : # use science-quality collection CONCEPTID = \"C193529902-LPDAAC_ECS\" else : # use LANCE-NRT collection CONCEPTID = \"C1219249711-LANCEMODIS\" return fetching ( conceptid = CONCEPTID , start_time = start_time , region = region , credentials = credentials , out_directory = out_directory , max_results = 500 , end_time = end_time , ) viirs ( credentials , start_time = '2000-01-01' , end_time = None , region = [ - 180 , 60 , 180 , 85 ], out_directory = './' ) Function to download Suomi-NPP VIIRS surface reflectance data for specified time and region, wraps fetching() Parameters: Name Type Description Default credentials tuple | list EarthData username and password login credentials as iterable required start_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = 2000-01-01 '2000-01-01' end_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = start_time + 1day None region tuple | list Bounding box of region to search as iterable in W,S,E,N order default = [-180,60,180,85] [-180, 60, 180, 85] out_directory str | pathlib.Path, optioanl Local directory to downaload data to default = \"./\" './' Returns: Type Description list[pathlib.Path] List of local paths that data was downloaded to Source code in hydrafloods/fetch.py def viirs ( credentials , start_time = \"2000-01-01\" , end_time = None , region = [ - 180 , 60 , 180 , 85 ], out_directory = \"./\" , ): \"\"\"Function to download Suomi-NPP VIIRS surface reflectance data for specified time and region, wraps `fetching()` args: credentials (tuple | list): EarthData username and password login credentials as iterable start_time (str, optional): Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = 2000-01-01 end_time (str, optional): Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = start_time + 1day region (tuple | list, optional): Bounding box of region to search as iterable in W,S,E,N order default = [-180,60,180,85] out_directory (str | pathlib.Path, optioanl): Local directory to downaload data to default = \"./\" returns: list[pathlib.Path]: List of local paths that data was downloaded to \"\"\" # check if date requested is within science-quality production time now = datetime . datetime . now () offset = now - scmr . utils . decode_date ( start_time ) if offset . days > 4 : # use science-quality collection CONCEPTID = \"C1373412034-LPDAAC_ECS\" else : # use LANCE-NRT collection CONCEPTID = \"C1344293643-LANCEMODIS\" return fetching ( conceptid = CONCEPTID , start_time = start_time , region = region , credentials = credentials , out_directory = out_directory , max_results = 500 , end_time = end_time , )","title":"fetch module"},{"location":"fetch/#hydrafloods.fetch","text":"","title":"fetch"},{"location":"fetch/#hydrafloods.fetch.atms","text":"Function to download Suomi-NPP ATMS passive microwave data for specified time and region, wraps fetching() Parameters: Name Type Description Default credentials tuple | list EarthData username and password login credentials as iterable required start_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = 2000-01-01 '2000-01-01' end_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = start_time + 1day None region tuple | list Bounding box of region to search as iterable in W,S,E,N order default = [-180,60,180,85] [-180, 60, 180, 85] out_directory str | pathlib.Path, optioanl Local directory to downaload data to default = \"./\" './' Returns: Type Description list[pathlib.Path] List of local paths that data was downloaded to Source code in hydrafloods/fetch.py def atms ( credentials , start_time = \"2000-01-01\" , end_time = None , region = [ - 180 , 60 , 180 , 85 ], out_directory = \"./\" , ): \"\"\" Function to download Suomi-NPP ATMS passive microwave data for specified time and region, wraps `fetching()` args: credentials (tuple | list): EarthData username and password login credentials as iterable start_time (str, optional): Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = 2000-01-01 end_time (str, optional): Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = start_time + 1day region (tuple | list, optional): Bounding box of region to search as iterable in W,S,E,N order default = [-180,60,180,85] out_directory (str | pathlib.Path, optioanl): Local directory to downaload data to default = \"./\" returns: list[pathlib.Path]: List of local paths that data was downloaded to \"\"\" CONCEPTID = \"C1442068516-GES_DISC\" return fetching ( conceptid = CONCEPTID , start_time = start_time , region = region , credentials = credentials , out_directory = out_directory , max_results = 500 , end_time = end_time , )","title":"atms()"},{"location":"fetch/#hydrafloods.fetch.fetching","text":"Function to download data from NASA CMR by specifying a dataset, time and region. Uses CMR to handle spatio-temporal query and extracts data download urls Parameters: Name Type Description Default conceptid str String of dataset concept id to search for required start_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd) required region tuple[float] | list[float] Bounding box of region to search as iterable in W,S,E,N order required credentials tuple | list EarthData username and password login credentials as iterable required out_directory str|pathlib.Path Local directory to downaload data to required max_results int Maximum number of items to search and download. default = 500 500 end_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd). default = start_time + 1day None Returns: Type Description list[pathlib.Path] List of local paths that data was downloaded to Source code in hydrafloods/fetch.py def fetching ( conceptid , start_time , region , credentials , out_directory , max_results = 500 , end_time = None , ): \"\"\" Function to download data from NASA CMR by specifying a dataset, time and region. Uses CMR to handle spatio-temporal query and extracts data download urls args: conceptid (str): String of dataset concept id to search for start_time (str): Date as string preferrably as ISO8601 format (YYYY-MM-dd) region (tuple[float] | list[float]): Bounding box of region to search as iterable in W,S,E,N order credentials (tuple | list): EarthData username and password login credentials as iterable out_directory (str|pathlib.Path): Local directory to downaload data to max_results (int, optional): Maximum number of items to search and download. default = 500 end_time (str, optional): Date as string preferrably as ISO8601 format (YYYY-MM-dd). default = start_time + 1day returns: list[pathlib.Path]: List of local paths that data was downloaded to \"\"\" if type ( start_time ) != datetime . datetime : start_time = scmr . utils . decode_date ( start_time ) if end_time is None : end_time = start_time + datetime . timedelta ( seconds = 86399 ) else : end_time = scmr . utils . decode_date ( end_time ) # construct query query = scmr . Query ( conceptid = conceptid , startTime = start_time , endTime = end_time , spatialExtent = region , maxResults = max_results , ) # fetch datasets from query query . granules . fetch ( credentials = credentials , directory = out_directory , limit = max_results , maxWorkers = 4 , ) # return a list of the granules for later processing return query . granules . getLocalPaths ( directory = out_directory )","title":"fetching()"},{"location":"fetch/#hydrafloods.fetch.modis","text":"Function to download MODIS surface reflectance data for specified time and region, wraps fetching() Parameters: Name Type Description Default credentials tuple | list EarthData username and password login credentials as iterable required start_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = 2000-01-01 '2000-01-01' end_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = start_time + 1day None region tuple[float] | list[float] Bounding box of region to search as iterable in W,S,E,N order default = [-180,60,180,85] [-180, 60, 180, 85] out_directory str | pathlib.Path Local directory to downaload data to default = \"./\" './' Returns: Type Description list[pathlib.Path] List of local paths that data was downloaded to Source code in hydrafloods/fetch.py def modis ( credentials , start_time = \"2000-01-01\" , end_time = None , region = [ - 180 , 60 , 180 , 85 ], out_directory = \"./\" , ): \"\"\"Function to download MODIS surface reflectance data for specified time and region, wraps `fetching()` args: credentials (tuple | list): EarthData username and password login credentials as iterable start_time (str, optional): Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = 2000-01-01 end_time (str, optional): Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = start_time + 1day region (tuple[float] | list[float], optional): Bounding box of region to search as iterable in W,S,E,N order default = [-180,60,180,85] out_directory (str | pathlib.Path, optional): Local directory to downaload data to default = \"./\" returns: list[pathlib.Path]: List of local paths that data was downloaded to \"\"\" # check if date requested is within science-quality production time now = datetime . datetime . now () offset = now - scmr . utils . decode_date ( start_time ) if offset . days > 4 : # use science-quality collection CONCEPTID = \"C193529902-LPDAAC_ECS\" else : # use LANCE-NRT collection CONCEPTID = \"C1219249711-LANCEMODIS\" return fetching ( conceptid = CONCEPTID , start_time = start_time , region = region , credentials = credentials , out_directory = out_directory , max_results = 500 , end_time = end_time , )","title":"modis()"},{"location":"fetch/#hydrafloods.fetch.viirs","text":"Function to download Suomi-NPP VIIRS surface reflectance data for specified time and region, wraps fetching() Parameters: Name Type Description Default credentials tuple | list EarthData username and password login credentials as iterable required start_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = 2000-01-01 '2000-01-01' end_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = start_time + 1day None region tuple | list Bounding box of region to search as iterable in W,S,E,N order default = [-180,60,180,85] [-180, 60, 180, 85] out_directory str | pathlib.Path, optioanl Local directory to downaload data to default = \"./\" './' Returns: Type Description list[pathlib.Path] List of local paths that data was downloaded to Source code in hydrafloods/fetch.py def viirs ( credentials , start_time = \"2000-01-01\" , end_time = None , region = [ - 180 , 60 , 180 , 85 ], out_directory = \"./\" , ): \"\"\"Function to download Suomi-NPP VIIRS surface reflectance data for specified time and region, wraps `fetching()` args: credentials (tuple | list): EarthData username and password login credentials as iterable start_time (str, optional): Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = 2000-01-01 end_time (str, optional): Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = start_time + 1day region (tuple | list, optional): Bounding box of region to search as iterable in W,S,E,N order default = [-180,60,180,85] out_directory (str | pathlib.Path, optioanl): Local directory to downaload data to default = \"./\" returns: list[pathlib.Path]: List of local paths that data was downloaded to \"\"\" # check if date requested is within science-quality production time now = datetime . datetime . now () offset = now - scmr . utils . decode_date ( start_time ) if offset . days > 4 : # use science-quality collection CONCEPTID = \"C1373412034-LPDAAC_ECS\" else : # use LANCE-NRT collection CONCEPTID = \"C1344293643-LANCEMODIS\" return fetching ( conceptid = CONCEPTID , start_time = start_time , region = region , credentials = credentials , out_directory = out_directory , max_results = 500 , end_time = end_time , )","title":"viirs()"},{"location":"filtering/","text":"hydrafloods.filtering gamma_map ( img , window = 7 , enl = 4.9 ) Gamma Map speckle filtering algorithm. Algorithm adapted from https://groups.google.com/g/google-earth-engine-developers/c/a9W0Nlrhoq0/m/tnGMC45jAgAJ. Parameters: Name Type Description Default img ee.Image Earth engine image object. Expects that imagery is a SAR image required window int moving window size to apply filter (i.e. a value of 7 == 7x7 window). default = 7 7 enl float equivalent number of looks (enl) per pixel from a SAR scan. See https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/resolutions/level-1-ground-range-detected. default = 4.9 4.9 Returns: Type Description ee.Image filtered SAR image using the Gamma Map algorithm Source code in hydrafloods/filtering.py @decorators . carry_metadata def gamma_map ( img , window = 7 , enl = 4.9 ): \"\"\"Gamma Map speckle filtering algorithm. Algorithm adapted from https://groups.google.com/g/google-earth-engine-developers/c/a9W0Nlrhoq0/m/tnGMC45jAgAJ. args: img (ee.Image): Earth engine image object. Expects that imagery is a SAR image window (int, optional): moving window size to apply filter (i.e. a value of 7 == 7x7 window). default = 7 enl (float, optional): equivalent number of looks (enl) per pixel from a SAR scan. See https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/resolutions/level-1-ground-range-detected. default = 4.9 returns: ee.Image: filtered SAR image using the Gamma Map algorithm \"\"\" bandNames = img . bandNames () # Square kernel, window should be odd (typically 3, 5 or 7) weights = ee . List . repeat ( ee . List . repeat ( 1 , window ), window ) midPt = ( window // 2 ) + 1 if ( window % 2 ) != 0 else window // 2 # ~~(window/2) does integer division in JavaScript kernel = ee . Kernel . fixed ( window , window , weights , midPt , midPt , False ) # Convert image from dB to natural values nat_img = geeutils . db_to_power ( img ) # Get mean and variance mean = nat_img . reduceNeighborhood ( ee . Reducer . mean (), kernel ) variance = nat_img . reduceNeighborhood ( ee . Reducer . variance (), kernel ) # \"Pure speckle\" threshold ci = variance . sqrt () . divide ( mean ) # square root of inverse of enl # If ci <= cu, the kernel lies in a \"pure speckle\" area -> return simple mean cu = 1.0 / math . sqrt ( enl ) # If cu < ci < cmax the kernel lies in the low textured speckle area -> return the filtered value cmax = math . sqrt ( 2.0 ) * cu alpha = ee . Image ( 1.0 + cu * cu ) . divide ( ci . multiply ( ci ) . subtract ( cu * cu )) b = alpha . subtract ( enl + 1.0 ) d = ( mean . multiply ( mean ) . multiply ( b ) . multiply ( b ) . add ( alpha . multiply ( mean ) . multiply ( nat_img ) . multiply ( 4.0 * enl )) ) f = b . multiply ( mean ) . add ( d . sqrt ()) . divide ( alpha . multiply ( 2.0 )) caster = ee . Dictionary . fromLists ( bandNames , ee . List . repeat ( \"float\" , 3 )) img1 = ( geeutils . power_to_db ( mean . updateMask ( ci . lte ( cu ))) . rename ( bandNames ) . cast ( caster ) ) img2 = ( geeutils . power_to_db ( f . updateMask ( ci . gt ( cu )) . updateMask ( ci . lt ( cmax ))) . rename ( bandNames ) . cast ( caster ) ) img3 = img . updateMask ( ci . gte ( cmax )) . rename ( bandNames ) . cast ( caster ) # If ci > cmax do not filter at all (i.e. we don't do anything, other then masking) result = ( ee . ImageCollection ([ img1 , img2 , img3 ]) . reduce ( ee . Reducer . firstNonNull ()) . rename ( bandNames ) . clip ( img . geometry ()) ) # Compose a 3 band image with the mean filtered \"pure speckle\", the \"low textured\" filtered and the unfiltered portions return result lee_sigma ( img , window = 9 , sigma = 0.9 , looks = 4 , tk = 7 , keep_bands = 'angle' ) Lee Sigma speckle filtering algorithm. Implemented from interpreting https://doi.org/10.1109/TGRS.2008.2002881 Parameters: Name Type Description Default img ee.Image Earth engine image object. Expects that imagery is a SAR image required window int moving window size to apply filter (i.e. a value of 9 == 9x9 window). default = 9 9 sigma float sigma lookup value from table 1 in paper. default = 0.9 0.9 looks int look intensity value from table 1 in paper. default = 4 4 tk int threshold value to determine values in window as point targets. default = 7 7 keep_bands str | list[str] regex name or list of band names to drop during filtering and include in the result default = \"angle\" 'angle' Returns: Type Description ee.Image filtered SAR image using the Lee Sigma algorithm Source code in hydrafloods/filtering.py @decorators . carry_metadata def lee_sigma ( img , window = 9 , sigma = 0.9 , looks = 4 , tk = 7 , keep_bands = \"angle\" ): \"\"\"Lee Sigma speckle filtering algorithm. Implemented from interpreting https://doi.org/10.1109/TGRS.2008.2002881 args: img (ee.Image): Earth engine image object. Expects that imagery is a SAR image window (int, optional): moving window size to apply filter (i.e. a value of 9 == 9x9 window). default = 9 sigma (float, optional): sigma lookup value from table 1 in paper. default = 0.9 looks (int, optional): look intensity value from table 1 in paper. default = 4 tk (int, optional): threshold value to determine values in window as point targets. default = 7 keep_bands (str | list[str], optional): regex name or list of band names to drop during filtering and include in the result default = \"angle\" returns: ee.Image: filtered SAR image using the Lee Sigma algorithm \"\"\" band_names = img . bandNames () proc_bands = band_names . remove ( keep_bands ) keep_img = img . select ( keep_bands ) img = img . select ( proc_bands ) midPt = ( window // 2 ) + 1 if ( window % 2 ) != 0 else window // 2 kernelWeights = ee . List . repeat ( ee . List . repeat ( 1 , window ), window ) kernel = ee . Kernel . fixed ( window , window , kernelWeights , midPt , midPt ) targetWeights = ee . List . repeat ( ee . List . repeat ( 1 , 3 ), 3 ) targetkernel = ee . Kernel . fixed ( 3 , 3 , targetWeights , 1 , 1 ) # Lookup table for range and eta values for intensity sigmaLookup = ee . Dictionary ( { 1 : ee . Dictionary ( { 0.5 : ee . Dictionary ({ \"A1\" : 0.436 , \"A2\" : 1.92 , \"\u03b7\" : 0.4057 }), 0.6 : ee . Dictionary ({ \"A1\" : 0.343 , \"A2\" : 2.21 , \"\u03b7\" : 0.4954 }), 0.7 : ee . Dictionary ({ \"A1\" : 0.254 , \"A2\" : 2.582 , \"\u03b7\" : 0.5911 }), 0.8 : ee . Dictionary ({ \"A1\" : 0.168 , \"A2\" : 3.094 , \"\u03b7\" : 0.6966 }), 0.9 : ee . Dictionary ({ \"A1\" : 0.084 , \"A2\" : 3.941 , \"\u03b7\" : 0.8191 }), 0.95 : ee . Dictionary ({ \"A1\" : 0.043 , \"A2\" : 4.840 , \"\u03b7\" : 0.8599 }), } ), 2 : ee . Dictionary ( { 0.5 : ee . Dictionary ({ \"A1\" : 0.582 , \"A2\" : 1.584 , \"\u03b7\" : 0.2763 }), 0.6 : ee . Dictionary ({ \"A1\" : 0.501 , \"A2\" : 1.755 , \"\u03b7\" : 0.3388 }), 0.7 : ee . Dictionary ({ \"A1\" : 0.418 , \"A2\" : 1.972 , \"\u03b7\" : 0.4062 }), 0.8 : ee . Dictionary ({ \"A1\" : 0.327 , \"A2\" : 2.260 , \"\u03b7\" : 0.4819 }), 0.9 : ee . Dictionary ({ \"A1\" : 0.221 , \"A2\" : 2.744 , \"\u03b7\" : 0.5699 }), 0.95 : ee . Dictionary ({ \"A1\" : 0.152 , \"A2\" : 3.206 , \"\u03b7\" : 0.6254 }), } ), 3 : ee . Dictionary ( { 0.5 : ee . Dictionary ({ \"A1\" : 0.652 , \"A2\" : 1.458 , \"\u03b7\" : 0.2222 }), 0.6 : ee . Dictionary ({ \"A1\" : 0.580 , \"A2\" : 1.586 , \"\u03b7\" : 0.2736 }), 0.7 : ee . Dictionary ({ \"A1\" : 0.505 , \"A2\" : 1.751 , \"\u03b7\" : 0.3280 }), 0.8 : ee . Dictionary ({ \"A1\" : 0.419 , \"A2\" : 1.865 , \"\u03b7\" : 0.3892 }), 0.9 : ee . Dictionary ({ \"A1\" : 0.313 , \"A2\" : 2.320 , \"\u03b7\" : 0.4624 }), 0.95 : ee . Dictionary ({ \"A1\" : 0.238 , \"A2\" : 2.656 , \"\u03b7\" : 0.5084 }), } ), 4 : ee . Dictionary ( { 0.5 : ee . Dictionary ({ \"A1\" : 0.694 , \"A2\" : 1.385 , \"\u03b7\" : 0.1921 }), 0.6 : ee . Dictionary ({ \"A1\" : 0.630 , \"A2\" : 1.495 , \"\u03b7\" : 0.2348 }), 0.7 : ee . Dictionary ({ \"A1\" : 0.560 , \"A2\" : 1.627 , \"\u03b7\" : 0.2825 }), 0.8 : ee . Dictionary ({ \"A1\" : 0.480 , \"A2\" : 1.804 , \"\u03b7\" : 0.3354 }), 0.9 : ee . Dictionary ({ \"A1\" : 0.378 , \"A2\" : 2.094 , \"\u03b7\" : 0.3991 }), 0.95 : ee . Dictionary ({ \"A1\" : 0.302 , \"A2\" : 2.360 , \"\u03b7\" : 0.4391 }), } ), } ) # extract data from lookup looksDict = ee . Dictionary ( sigmaLookup . get ( ee . String ( str ( looks )))) sigmaImage = ee . Dictionary ( looksDict . get ( ee . String ( str ( sigma )))) . toImage () a1 = sigmaImage . select ( \"A1\" ) a2 = sigmaImage . select ( \"A2\" ) aRange = a2 . subtract ( a1 ) eta = sigmaImage . select ( \"\u03b7\" ) . pow ( 2 ) img = geeutils . db_to_power ( img ) # MMSE estimator mmseMask = img . gte ( a1 ) . Or ( img . lte ( a2 )) mmseIn = img . updateMask ( mmseMask ) oneImg = ee . Image ( 1 ) z = mmseIn . reduceNeighborhood ( ee . Reducer . mean (), kernel , None , True ) varz = mmseIn . reduceNeighborhood ( ee . Reducer . variance (), kernel ) varx = ( varz . subtract ( z . abs () . pow ( 2 ) . multiply ( eta ))) . divide ( oneImg . add ( eta )) b = varx . divide ( varz ) mmse = oneImg . subtract ( b ) . multiply ( z . abs ()) . add ( b . multiply ( mmseIn )) # workflow z99 = ee . Dictionary ( img . reduceRegion ( reducer = ee . Reducer . percentile ([ 99 ], None , 255 , 0.001 , 1e6 ), geometry = img . geometry (), scale = 10 , bestEffort = True , ) ) . toImage () overThresh = img . gte ( z99 ) K = overThresh . reduceNeighborhood ( ee . Reducer . sum (), targetkernel , None , True ) retainPixel = K . gte ( tk ) xHat = geeutils . power_to_db ( img . updateMask ( retainPixel ) . unmask ( mmse )) return ee . Image ( xHat ) . rename ( proc_bands ) . addBands ( keep_img ) p_median ( img , window = 5 ) P-Median filter for smoothing imagery. Calculates the average from the median along cross and diagnal pixels of a window Parameters: Name Type Description Default img ee.Image Earth engine image object to filter required window int moving window size to apply filter (i.e. a value of 5 == 5x5 window). default = 5 5 Returns: Type Description ee.Image filtered image Source code in hydrafloods/filtering.py @decorators . carry_metadata def p_median ( img , window = 5 ): \"\"\"P-Median filter for smoothing imagery. Calculates the average from the median along cross and diagnal pixels of a window args: img (ee.Image): Earth engine image object to filter window (int, optional): moving window size to apply filter (i.e. a value of 5 == 5x5 window). default = 5 returns: ee.Image: filtered image \"\"\" if window % 2 == 0 : window += 1 center_idx = ( window - 1 ) // 2 hv = [ [ 1 if i == center_idx or j == center_idx else 0 for j in range ( window )] for i in range ( window ) ] diag = [ [ 1 if i == j or i == (( window - 1 ) - j ) else 0 for j in range ( window )] for i in range ( window ) ] # method based on ??? band_names = img . bandNames () hv_weights = ee . List ( hv ) diag_weights = ee . List ( diag ) hv_kernel = ee . Kernel . fixed ( window , window , hv_weights ) diag_kernel = ee . Kernel . fixed ( window , window , diag_weights ) hv_median = img . reduceNeighborhood ( ee . Reducer . median (), hv_kernel ) diag_median = img . reduceNeighborhood ( ee . Reducer . median (), diag_kernel ) return ee . Image . cat ([ hv_median , diag_median ]) . reduce ( \"mean\" ) . rename ( band_names ) refined_lee ( image ) Refined Lee speckle filtering algorithm. Algorithm adapted from https://groups.google.com/g/google-earth-engine-developers/c/ExepnAmP-hQ/m/7e5DnjXXAQAJ Parameters: Name Type Description Default image ee.Image Earth engine image object. Expects that imagery is a SAR image required Returns: Type Description ee.Image filtered SAR image using the Refined Lee algorithm Source code in hydrafloods/filtering.py @decorators . carry_metadata def refined_lee ( image ): \"\"\"Refined Lee speckle filtering algorithm. Algorithm adapted from https://groups.google.com/g/google-earth-engine-developers/c/ExepnAmP-hQ/m/7e5DnjXXAQAJ args: image (ee.Image): Earth engine image object. Expects that imagery is a SAR image returns: ee.Image: filtered SAR image using the Refined Lee algorithm \"\"\" # TODO: include keep bands...maybe one-shot filtering if using keep_bands??? def apply_filter ( b ): \"\"\"Closure function to apply the refined lee algorithm on individual bands \"\"\" img = power . select ([ b ]) # img must be in natural units, i.e. not in dB! # Set up 3x3 kernels weights3 = ee . List . repeat ( ee . List . repeat ( 1 , 3 ), 3 ) kernel3 = ee . Kernel . fixed ( 3 , 3 , weights3 , 1 , 1 , False ) mean3 = img . reduceNeighborhood ( ee . Reducer . mean (), kernel3 ) variance3 = img . reduceNeighborhood ( ee . Reducer . variance (), kernel3 ) # Use a sample of the 3x3 windows inside a 7x7 windows to determine gradients and directions sample_weights = ee . List ( [ [ 0 , 0 , 0 , 0 , 0 , 0 , 0 ], [ 0 , 1 , 0 , 1 , 0 , 1 , 0 ], [ 0 , 0 , 0 , 0 , 0 , 0 , 0 ], [ 0 , 1 , 0 , 1 , 0 , 1 , 0 ], [ 0 , 0 , 0 , 0 , 0 , 0 , 0 ], [ 0 , 1 , 0 , 1 , 0 , 1 , 0 ], [ 0 , 0 , 0 , 0 , 0 , 0 , 0 ], ] ) sample_kernel = ee . Kernel . fixed ( 7 , 7 , sample_weights , 3 , 3 , False ) # Calculate mean and variance for the sampled windows and store as 9 bands sample_mean = mean3 . neighborhoodToBands ( sample_kernel ) sample_var = variance3 . neighborhoodToBands ( sample_kernel ) # Determine the 4 gradients for the sampled windows gradients = sample_mean . select ( 1 ) . subtract ( sample_mean . select ( 7 )) . abs () gradients = gradients . addBands ( sample_mean . select ( 6 ) . subtract ( sample_mean . select ( 2 )) . abs () ) gradients = gradients . addBands ( sample_mean . select ( 3 ) . subtract ( sample_mean . select ( 5 )) . abs () ) gradients = gradients . addBands ( sample_mean . select ( 0 ) . subtract ( sample_mean . select ( 8 )) . abs () ) # And find the maximum gradient amongst gradient bands max_gradient = gradients . reduce ( ee . Reducer . max ()) # Create a mask for band pixels that are the maximum gradient gradmask = gradients . eq ( max_gradient ) # duplicate gradmask bands: each gradient represents 2 directions gradmask = gradmask . addBands ( gradmask ) # Determine the 8 directions directions = ( sample_mean . select ( 1 ) . subtract ( sample_mean . select ( 4 )) . gt ( sample_mean . select ( 4 ) . subtract ( sample_mean . select ( 7 ))) . multiply ( 1 ) ) directions = directions . addBands ( sample_mean . select ( 6 ) . subtract ( sample_mean . select ( 4 )) . gt ( sample_mean . select ( 4 ) . subtract ( sample_mean . select ( 2 ))) . multiply ( 2 ) ) directions = directions . addBands ( sample_mean . select ( 3 ) . subtract ( sample_mean . select ( 4 )) . gt ( sample_mean . select ( 4 ) . subtract ( sample_mean . select ( 5 ))) . multiply ( 3 ) ) directions = directions . addBands ( sample_mean . select ( 0 ) . subtract ( sample_mean . select ( 4 )) . gt ( sample_mean . select ( 4 ) . subtract ( sample_mean . select ( 8 ))) . multiply ( 4 ) ) # The next 4 are the not() of the previous 4 directions = directions . addBands ( directions . select ( 0 ) . Not () . multiply ( 5 )) directions = directions . addBands ( directions . select ( 1 ) . Not () . multiply ( 6 )) directions = directions . addBands ( directions . select ( 2 ) . Not () . multiply ( 7 )) directions = directions . addBands ( directions . select ( 3 ) . Not () . multiply ( 8 )) # Mask all values that are not 1-8 directions = directions . updateMask ( gradmask ) # \"collapse\" the stack into a singe band image (due to masking, each pixel has just one value (1-8) in it's directional band, and is otherwise masked) directions = directions . reduce ( ee . Reducer . sum ()) sample_stats = sample_var . divide ( sample_mean . multiply ( sample_mean )) # Calculate localNoiseVariance sigmaV = ( sample_stats . toArray () . arraySort () . arraySlice ( 0 , 0 , 5 ) . arrayReduce ( ee . Reducer . mean (), [ 0 ]) ) # Set up the 7*7 kernels for directional statistics rect_weights = ee . List . repeat ( ee . List . repeat ( 0 , 7 ), 3 ) . cat ( ee . List . repeat ( ee . List . repeat ( 1 , 7 ), 4 ) ) diag_weights = ee . List ( [ [ 1 , 0 , 0 , 0 , 0 , 0 , 0 ], [ 1 , 1 , 0 , 0 , 0 , 0 , 0 ], [ 1 , 1 , 1 , 0 , 0 , 0 , 0 ], [ 1 , 1 , 1 , 1 , 0 , 0 , 0 ], [ 1 , 1 , 1 , 1 , 1 , 0 , 0 ], [ 1 , 1 , 1 , 1 , 1 , 1 , 0 ], [ 1 , 1 , 1 , 1 , 1 , 1 , 1 ], ] ) rect_kernel = ee . Kernel . fixed ( 7 , 7 , rect_weights , 3 , 3 , False ) diag_kernel = ee . Kernel . fixed ( 7 , 7 , diag_weights , 3 , 3 , False ) # Create stacks for mean and variance using the original kernels. Mask with relevant direction. dir_mean = img . reduceNeighborhood ( ee . Reducer . mean (), rect_kernel ) . updateMask ( directions . eq ( 1 ) ) dir_var = img . reduceNeighborhood ( ee . Reducer . variance (), rect_kernel ) . updateMask ( directions . eq ( 1 ) ) dir_mean = dir_mean . addBands ( img . reduceNeighborhood ( ee . Reducer . mean (), diag_kernel ) . updateMask ( directions . eq ( 2 ) ) ) dir_var = dir_var . addBands ( img . reduceNeighborhood ( ee . Reducer . variance (), diag_kernel ) . updateMask ( directions . eq ( 2 ) ) ) # and add the bands for rotated kernels for i in range ( 1 , 4 ): dir_mean = dir_mean . addBands ( img . reduceNeighborhood ( ee . Reducer . mean (), rect_kernel . rotate ( i ) ) . updateMask ( directions . eq ( 2 * i + 1 )) ) dir_var = dir_var . addBands ( img . reduceNeighborhood ( ee . Reducer . variance (), rect_kernel . rotate ( i ) ) . updateMask ( directions . eq ( 2 * i + 1 )) ) dir_mean = dir_mean . addBands ( img . reduceNeighborhood ( ee . Reducer . mean (), diag_kernel . rotate ( i ) ) . updateMask ( directions . eq ( 2 * i + 2 )) ) dir_var = dir_var . addBands ( img . reduceNeighborhood ( ee . Reducer . variance (), diag_kernel . rotate ( i ) ) . updateMask ( directions . eq ( 2 * i + 2 )) ) # \"collapse\" the stack into a single band image (due to masking, each pixel has just one value in it's directional band, and is otherwise masked) dir_mean = dir_mean . reduce ( ee . Reducer . sum ()) dir_var = dir_var . reduce ( ee . Reducer . sum ()) # A finally generate the filtered value varX = dir_var . subtract ( dir_mean . multiply ( dir_mean ) . multiply ( sigmaV )) . divide ( sigmaV . add ( 1.0 ) ) b = varX . divide ( dir_var ) # return multi-band image band from array return ( dir_mean . add ( b . multiply ( img . subtract ( dir_mean ))) . arrayProject ([ 0 ]) . arrayFlatten ([[ \"sum\" ]]) . float () ) bandNames = image . bandNames () power = geeutils . db_to_power ( image ) result = ee . ImageCollection ( bandNames . map ( apply_filter )) . toBands () . rename ( bandNames ) return geeutils . power_to_db ( ee . Image ( result ))","title":"filtering module"},{"location":"filtering/#hydrafloods.filtering","text":"","title":"filtering"},{"location":"filtering/#hydrafloods.filtering.gamma_map","text":"Gamma Map speckle filtering algorithm. Algorithm adapted from https://groups.google.com/g/google-earth-engine-developers/c/a9W0Nlrhoq0/m/tnGMC45jAgAJ. Parameters: Name Type Description Default img ee.Image Earth engine image object. Expects that imagery is a SAR image required window int moving window size to apply filter (i.e. a value of 7 == 7x7 window). default = 7 7 enl float equivalent number of looks (enl) per pixel from a SAR scan. See https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/resolutions/level-1-ground-range-detected. default = 4.9 4.9 Returns: Type Description ee.Image filtered SAR image using the Gamma Map algorithm Source code in hydrafloods/filtering.py @decorators . carry_metadata def gamma_map ( img , window = 7 , enl = 4.9 ): \"\"\"Gamma Map speckle filtering algorithm. Algorithm adapted from https://groups.google.com/g/google-earth-engine-developers/c/a9W0Nlrhoq0/m/tnGMC45jAgAJ. args: img (ee.Image): Earth engine image object. Expects that imagery is a SAR image window (int, optional): moving window size to apply filter (i.e. a value of 7 == 7x7 window). default = 7 enl (float, optional): equivalent number of looks (enl) per pixel from a SAR scan. See https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/resolutions/level-1-ground-range-detected. default = 4.9 returns: ee.Image: filtered SAR image using the Gamma Map algorithm \"\"\" bandNames = img . bandNames () # Square kernel, window should be odd (typically 3, 5 or 7) weights = ee . List . repeat ( ee . List . repeat ( 1 , window ), window ) midPt = ( window // 2 ) + 1 if ( window % 2 ) != 0 else window // 2 # ~~(window/2) does integer division in JavaScript kernel = ee . Kernel . fixed ( window , window , weights , midPt , midPt , False ) # Convert image from dB to natural values nat_img = geeutils . db_to_power ( img ) # Get mean and variance mean = nat_img . reduceNeighborhood ( ee . Reducer . mean (), kernel ) variance = nat_img . reduceNeighborhood ( ee . Reducer . variance (), kernel ) # \"Pure speckle\" threshold ci = variance . sqrt () . divide ( mean ) # square root of inverse of enl # If ci <= cu, the kernel lies in a \"pure speckle\" area -> return simple mean cu = 1.0 / math . sqrt ( enl ) # If cu < ci < cmax the kernel lies in the low textured speckle area -> return the filtered value cmax = math . sqrt ( 2.0 ) * cu alpha = ee . Image ( 1.0 + cu * cu ) . divide ( ci . multiply ( ci ) . subtract ( cu * cu )) b = alpha . subtract ( enl + 1.0 ) d = ( mean . multiply ( mean ) . multiply ( b ) . multiply ( b ) . add ( alpha . multiply ( mean ) . multiply ( nat_img ) . multiply ( 4.0 * enl )) ) f = b . multiply ( mean ) . add ( d . sqrt ()) . divide ( alpha . multiply ( 2.0 )) caster = ee . Dictionary . fromLists ( bandNames , ee . List . repeat ( \"float\" , 3 )) img1 = ( geeutils . power_to_db ( mean . updateMask ( ci . lte ( cu ))) . rename ( bandNames ) . cast ( caster ) ) img2 = ( geeutils . power_to_db ( f . updateMask ( ci . gt ( cu )) . updateMask ( ci . lt ( cmax ))) . rename ( bandNames ) . cast ( caster ) ) img3 = img . updateMask ( ci . gte ( cmax )) . rename ( bandNames ) . cast ( caster ) # If ci > cmax do not filter at all (i.e. we don't do anything, other then masking) result = ( ee . ImageCollection ([ img1 , img2 , img3 ]) . reduce ( ee . Reducer . firstNonNull ()) . rename ( bandNames ) . clip ( img . geometry ()) ) # Compose a 3 band image with the mean filtered \"pure speckle\", the \"low textured\" filtered and the unfiltered portions return result","title":"gamma_map()"},{"location":"filtering/#hydrafloods.filtering.lee_sigma","text":"Lee Sigma speckle filtering algorithm. Implemented from interpreting https://doi.org/10.1109/TGRS.2008.2002881 Parameters: Name Type Description Default img ee.Image Earth engine image object. Expects that imagery is a SAR image required window int moving window size to apply filter (i.e. a value of 9 == 9x9 window). default = 9 9 sigma float sigma lookup value from table 1 in paper. default = 0.9 0.9 looks int look intensity value from table 1 in paper. default = 4 4 tk int threshold value to determine values in window as point targets. default = 7 7 keep_bands str | list[str] regex name or list of band names to drop during filtering and include in the result default = \"angle\" 'angle' Returns: Type Description ee.Image filtered SAR image using the Lee Sigma algorithm Source code in hydrafloods/filtering.py @decorators . carry_metadata def lee_sigma ( img , window = 9 , sigma = 0.9 , looks = 4 , tk = 7 , keep_bands = \"angle\" ): \"\"\"Lee Sigma speckle filtering algorithm. Implemented from interpreting https://doi.org/10.1109/TGRS.2008.2002881 args: img (ee.Image): Earth engine image object. Expects that imagery is a SAR image window (int, optional): moving window size to apply filter (i.e. a value of 9 == 9x9 window). default = 9 sigma (float, optional): sigma lookup value from table 1 in paper. default = 0.9 looks (int, optional): look intensity value from table 1 in paper. default = 4 tk (int, optional): threshold value to determine values in window as point targets. default = 7 keep_bands (str | list[str], optional): regex name or list of band names to drop during filtering and include in the result default = \"angle\" returns: ee.Image: filtered SAR image using the Lee Sigma algorithm \"\"\" band_names = img . bandNames () proc_bands = band_names . remove ( keep_bands ) keep_img = img . select ( keep_bands ) img = img . select ( proc_bands ) midPt = ( window // 2 ) + 1 if ( window % 2 ) != 0 else window // 2 kernelWeights = ee . List . repeat ( ee . List . repeat ( 1 , window ), window ) kernel = ee . Kernel . fixed ( window , window , kernelWeights , midPt , midPt ) targetWeights = ee . List . repeat ( ee . List . repeat ( 1 , 3 ), 3 ) targetkernel = ee . Kernel . fixed ( 3 , 3 , targetWeights , 1 , 1 ) # Lookup table for range and eta values for intensity sigmaLookup = ee . Dictionary ( { 1 : ee . Dictionary ( { 0.5 : ee . Dictionary ({ \"A1\" : 0.436 , \"A2\" : 1.92 , \"\u03b7\" : 0.4057 }), 0.6 : ee . Dictionary ({ \"A1\" : 0.343 , \"A2\" : 2.21 , \"\u03b7\" : 0.4954 }), 0.7 : ee . Dictionary ({ \"A1\" : 0.254 , \"A2\" : 2.582 , \"\u03b7\" : 0.5911 }), 0.8 : ee . Dictionary ({ \"A1\" : 0.168 , \"A2\" : 3.094 , \"\u03b7\" : 0.6966 }), 0.9 : ee . Dictionary ({ \"A1\" : 0.084 , \"A2\" : 3.941 , \"\u03b7\" : 0.8191 }), 0.95 : ee . Dictionary ({ \"A1\" : 0.043 , \"A2\" : 4.840 , \"\u03b7\" : 0.8599 }), } ), 2 : ee . Dictionary ( { 0.5 : ee . Dictionary ({ \"A1\" : 0.582 , \"A2\" : 1.584 , \"\u03b7\" : 0.2763 }), 0.6 : ee . Dictionary ({ \"A1\" : 0.501 , \"A2\" : 1.755 , \"\u03b7\" : 0.3388 }), 0.7 : ee . Dictionary ({ \"A1\" : 0.418 , \"A2\" : 1.972 , \"\u03b7\" : 0.4062 }), 0.8 : ee . Dictionary ({ \"A1\" : 0.327 , \"A2\" : 2.260 , \"\u03b7\" : 0.4819 }), 0.9 : ee . Dictionary ({ \"A1\" : 0.221 , \"A2\" : 2.744 , \"\u03b7\" : 0.5699 }), 0.95 : ee . Dictionary ({ \"A1\" : 0.152 , \"A2\" : 3.206 , \"\u03b7\" : 0.6254 }), } ), 3 : ee . Dictionary ( { 0.5 : ee . Dictionary ({ \"A1\" : 0.652 , \"A2\" : 1.458 , \"\u03b7\" : 0.2222 }), 0.6 : ee . Dictionary ({ \"A1\" : 0.580 , \"A2\" : 1.586 , \"\u03b7\" : 0.2736 }), 0.7 : ee . Dictionary ({ \"A1\" : 0.505 , \"A2\" : 1.751 , \"\u03b7\" : 0.3280 }), 0.8 : ee . Dictionary ({ \"A1\" : 0.419 , \"A2\" : 1.865 , \"\u03b7\" : 0.3892 }), 0.9 : ee . Dictionary ({ \"A1\" : 0.313 , \"A2\" : 2.320 , \"\u03b7\" : 0.4624 }), 0.95 : ee . Dictionary ({ \"A1\" : 0.238 , \"A2\" : 2.656 , \"\u03b7\" : 0.5084 }), } ), 4 : ee . Dictionary ( { 0.5 : ee . Dictionary ({ \"A1\" : 0.694 , \"A2\" : 1.385 , \"\u03b7\" : 0.1921 }), 0.6 : ee . Dictionary ({ \"A1\" : 0.630 , \"A2\" : 1.495 , \"\u03b7\" : 0.2348 }), 0.7 : ee . Dictionary ({ \"A1\" : 0.560 , \"A2\" : 1.627 , \"\u03b7\" : 0.2825 }), 0.8 : ee . Dictionary ({ \"A1\" : 0.480 , \"A2\" : 1.804 , \"\u03b7\" : 0.3354 }), 0.9 : ee . Dictionary ({ \"A1\" : 0.378 , \"A2\" : 2.094 , \"\u03b7\" : 0.3991 }), 0.95 : ee . Dictionary ({ \"A1\" : 0.302 , \"A2\" : 2.360 , \"\u03b7\" : 0.4391 }), } ), } ) # extract data from lookup looksDict = ee . Dictionary ( sigmaLookup . get ( ee . String ( str ( looks )))) sigmaImage = ee . Dictionary ( looksDict . get ( ee . String ( str ( sigma )))) . toImage () a1 = sigmaImage . select ( \"A1\" ) a2 = sigmaImage . select ( \"A2\" ) aRange = a2 . subtract ( a1 ) eta = sigmaImage . select ( \"\u03b7\" ) . pow ( 2 ) img = geeutils . db_to_power ( img ) # MMSE estimator mmseMask = img . gte ( a1 ) . Or ( img . lte ( a2 )) mmseIn = img . updateMask ( mmseMask ) oneImg = ee . Image ( 1 ) z = mmseIn . reduceNeighborhood ( ee . Reducer . mean (), kernel , None , True ) varz = mmseIn . reduceNeighborhood ( ee . Reducer . variance (), kernel ) varx = ( varz . subtract ( z . abs () . pow ( 2 ) . multiply ( eta ))) . divide ( oneImg . add ( eta )) b = varx . divide ( varz ) mmse = oneImg . subtract ( b ) . multiply ( z . abs ()) . add ( b . multiply ( mmseIn )) # workflow z99 = ee . Dictionary ( img . reduceRegion ( reducer = ee . Reducer . percentile ([ 99 ], None , 255 , 0.001 , 1e6 ), geometry = img . geometry (), scale = 10 , bestEffort = True , ) ) . toImage () overThresh = img . gte ( z99 ) K = overThresh . reduceNeighborhood ( ee . Reducer . sum (), targetkernel , None , True ) retainPixel = K . gte ( tk ) xHat = geeutils . power_to_db ( img . updateMask ( retainPixel ) . unmask ( mmse )) return ee . Image ( xHat ) . rename ( proc_bands ) . addBands ( keep_img )","title":"lee_sigma()"},{"location":"filtering/#hydrafloods.filtering.p_median","text":"P-Median filter for smoothing imagery. Calculates the average from the median along cross and diagnal pixels of a window Parameters: Name Type Description Default img ee.Image Earth engine image object to filter required window int moving window size to apply filter (i.e. a value of 5 == 5x5 window). default = 5 5 Returns: Type Description ee.Image filtered image Source code in hydrafloods/filtering.py @decorators . carry_metadata def p_median ( img , window = 5 ): \"\"\"P-Median filter for smoothing imagery. Calculates the average from the median along cross and diagnal pixels of a window args: img (ee.Image): Earth engine image object to filter window (int, optional): moving window size to apply filter (i.e. a value of 5 == 5x5 window). default = 5 returns: ee.Image: filtered image \"\"\" if window % 2 == 0 : window += 1 center_idx = ( window - 1 ) // 2 hv = [ [ 1 if i == center_idx or j == center_idx else 0 for j in range ( window )] for i in range ( window ) ] diag = [ [ 1 if i == j or i == (( window - 1 ) - j ) else 0 for j in range ( window )] for i in range ( window ) ] # method based on ??? band_names = img . bandNames () hv_weights = ee . List ( hv ) diag_weights = ee . List ( diag ) hv_kernel = ee . Kernel . fixed ( window , window , hv_weights ) diag_kernel = ee . Kernel . fixed ( window , window , diag_weights ) hv_median = img . reduceNeighborhood ( ee . Reducer . median (), hv_kernel ) diag_median = img . reduceNeighborhood ( ee . Reducer . median (), diag_kernel ) return ee . Image . cat ([ hv_median , diag_median ]) . reduce ( \"mean\" ) . rename ( band_names )","title":"p_median()"},{"location":"filtering/#hydrafloods.filtering.refined_lee","text":"Refined Lee speckle filtering algorithm. Algorithm adapted from https://groups.google.com/g/google-earth-engine-developers/c/ExepnAmP-hQ/m/7e5DnjXXAQAJ Parameters: Name Type Description Default image ee.Image Earth engine image object. Expects that imagery is a SAR image required Returns: Type Description ee.Image filtered SAR image using the Refined Lee algorithm Source code in hydrafloods/filtering.py @decorators . carry_metadata def refined_lee ( image ): \"\"\"Refined Lee speckle filtering algorithm. Algorithm adapted from https://groups.google.com/g/google-earth-engine-developers/c/ExepnAmP-hQ/m/7e5DnjXXAQAJ args: image (ee.Image): Earth engine image object. Expects that imagery is a SAR image returns: ee.Image: filtered SAR image using the Refined Lee algorithm \"\"\" # TODO: include keep bands...maybe one-shot filtering if using keep_bands??? def apply_filter ( b ): \"\"\"Closure function to apply the refined lee algorithm on individual bands \"\"\" img = power . select ([ b ]) # img must be in natural units, i.e. not in dB! # Set up 3x3 kernels weights3 = ee . List . repeat ( ee . List . repeat ( 1 , 3 ), 3 ) kernel3 = ee . Kernel . fixed ( 3 , 3 , weights3 , 1 , 1 , False ) mean3 = img . reduceNeighborhood ( ee . Reducer . mean (), kernel3 ) variance3 = img . reduceNeighborhood ( ee . Reducer . variance (), kernel3 ) # Use a sample of the 3x3 windows inside a 7x7 windows to determine gradients and directions sample_weights = ee . List ( [ [ 0 , 0 , 0 , 0 , 0 , 0 , 0 ], [ 0 , 1 , 0 , 1 , 0 , 1 , 0 ], [ 0 , 0 , 0 , 0 , 0 , 0 , 0 ], [ 0 , 1 , 0 , 1 , 0 , 1 , 0 ], [ 0 , 0 , 0 , 0 , 0 , 0 , 0 ], [ 0 , 1 , 0 , 1 , 0 , 1 , 0 ], [ 0 , 0 , 0 , 0 , 0 , 0 , 0 ], ] ) sample_kernel = ee . Kernel . fixed ( 7 , 7 , sample_weights , 3 , 3 , False ) # Calculate mean and variance for the sampled windows and store as 9 bands sample_mean = mean3 . neighborhoodToBands ( sample_kernel ) sample_var = variance3 . neighborhoodToBands ( sample_kernel ) # Determine the 4 gradients for the sampled windows gradients = sample_mean . select ( 1 ) . subtract ( sample_mean . select ( 7 )) . abs () gradients = gradients . addBands ( sample_mean . select ( 6 ) . subtract ( sample_mean . select ( 2 )) . abs () ) gradients = gradients . addBands ( sample_mean . select ( 3 ) . subtract ( sample_mean . select ( 5 )) . abs () ) gradients = gradients . addBands ( sample_mean . select ( 0 ) . subtract ( sample_mean . select ( 8 )) . abs () ) # And find the maximum gradient amongst gradient bands max_gradient = gradients . reduce ( ee . Reducer . max ()) # Create a mask for band pixels that are the maximum gradient gradmask = gradients . eq ( max_gradient ) # duplicate gradmask bands: each gradient represents 2 directions gradmask = gradmask . addBands ( gradmask ) # Determine the 8 directions directions = ( sample_mean . select ( 1 ) . subtract ( sample_mean . select ( 4 )) . gt ( sample_mean . select ( 4 ) . subtract ( sample_mean . select ( 7 ))) . multiply ( 1 ) ) directions = directions . addBands ( sample_mean . select ( 6 ) . subtract ( sample_mean . select ( 4 )) . gt ( sample_mean . select ( 4 ) . subtract ( sample_mean . select ( 2 ))) . multiply ( 2 ) ) directions = directions . addBands ( sample_mean . select ( 3 ) . subtract ( sample_mean . select ( 4 )) . gt ( sample_mean . select ( 4 ) . subtract ( sample_mean . select ( 5 ))) . multiply ( 3 ) ) directions = directions . addBands ( sample_mean . select ( 0 ) . subtract ( sample_mean . select ( 4 )) . gt ( sample_mean . select ( 4 ) . subtract ( sample_mean . select ( 8 ))) . multiply ( 4 ) ) # The next 4 are the not() of the previous 4 directions = directions . addBands ( directions . select ( 0 ) . Not () . multiply ( 5 )) directions = directions . addBands ( directions . select ( 1 ) . Not () . multiply ( 6 )) directions = directions . addBands ( directions . select ( 2 ) . Not () . multiply ( 7 )) directions = directions . addBands ( directions . select ( 3 ) . Not () . multiply ( 8 )) # Mask all values that are not 1-8 directions = directions . updateMask ( gradmask ) # \"collapse\" the stack into a singe band image (due to masking, each pixel has just one value (1-8) in it's directional band, and is otherwise masked) directions = directions . reduce ( ee . Reducer . sum ()) sample_stats = sample_var . divide ( sample_mean . multiply ( sample_mean )) # Calculate localNoiseVariance sigmaV = ( sample_stats . toArray () . arraySort () . arraySlice ( 0 , 0 , 5 ) . arrayReduce ( ee . Reducer . mean (), [ 0 ]) ) # Set up the 7*7 kernels for directional statistics rect_weights = ee . List . repeat ( ee . List . repeat ( 0 , 7 ), 3 ) . cat ( ee . List . repeat ( ee . List . repeat ( 1 , 7 ), 4 ) ) diag_weights = ee . List ( [ [ 1 , 0 , 0 , 0 , 0 , 0 , 0 ], [ 1 , 1 , 0 , 0 , 0 , 0 , 0 ], [ 1 , 1 , 1 , 0 , 0 , 0 , 0 ], [ 1 , 1 , 1 , 1 , 0 , 0 , 0 ], [ 1 , 1 , 1 , 1 , 1 , 0 , 0 ], [ 1 , 1 , 1 , 1 , 1 , 1 , 0 ], [ 1 , 1 , 1 , 1 , 1 , 1 , 1 ], ] ) rect_kernel = ee . Kernel . fixed ( 7 , 7 , rect_weights , 3 , 3 , False ) diag_kernel = ee . Kernel . fixed ( 7 , 7 , diag_weights , 3 , 3 , False ) # Create stacks for mean and variance using the original kernels. Mask with relevant direction. dir_mean = img . reduceNeighborhood ( ee . Reducer . mean (), rect_kernel ) . updateMask ( directions . eq ( 1 ) ) dir_var = img . reduceNeighborhood ( ee . Reducer . variance (), rect_kernel ) . updateMask ( directions . eq ( 1 ) ) dir_mean = dir_mean . addBands ( img . reduceNeighborhood ( ee . Reducer . mean (), diag_kernel ) . updateMask ( directions . eq ( 2 ) ) ) dir_var = dir_var . addBands ( img . reduceNeighborhood ( ee . Reducer . variance (), diag_kernel ) . updateMask ( directions . eq ( 2 ) ) ) # and add the bands for rotated kernels for i in range ( 1 , 4 ): dir_mean = dir_mean . addBands ( img . reduceNeighborhood ( ee . Reducer . mean (), rect_kernel . rotate ( i ) ) . updateMask ( directions . eq ( 2 * i + 1 )) ) dir_var = dir_var . addBands ( img . reduceNeighborhood ( ee . Reducer . variance (), rect_kernel . rotate ( i ) ) . updateMask ( directions . eq ( 2 * i + 1 )) ) dir_mean = dir_mean . addBands ( img . reduceNeighborhood ( ee . Reducer . mean (), diag_kernel . rotate ( i ) ) . updateMask ( directions . eq ( 2 * i + 2 )) ) dir_var = dir_var . addBands ( img . reduceNeighborhood ( ee . Reducer . variance (), diag_kernel . rotate ( i ) ) . updateMask ( directions . eq ( 2 * i + 2 )) ) # \"collapse\" the stack into a single band image (due to masking, each pixel has just one value in it's directional band, and is otherwise masked) dir_mean = dir_mean . reduce ( ee . Reducer . sum ()) dir_var = dir_var . reduce ( ee . Reducer . sum ()) # A finally generate the filtered value varX = dir_var . subtract ( dir_mean . multiply ( dir_mean ) . multiply ( sigmaV )) . divide ( sigmaV . add ( 1.0 ) ) b = varX . divide ( dir_var ) # return multi-band image band from array return ( dir_mean . add ( b . multiply ( img . subtract ( dir_mean ))) . arrayProject ([ 0 ]) . arrayFlatten ([[ \"sum\" ]]) . float () ) bandNames = image . bandNames () power = geeutils . db_to_power ( image ) result = ee . ImageCollection ( bandNames . map ( apply_filter )) . toBands () . rename ( bandNames ) return geeutils . power_to_db ( ee . Image ( result ))","title":"refined_lee()"},{"location":"geeutils/","text":"hydrafloods.geeutils add_indices ( img , indices = [ 'mndwi' ]) Function to calculate multiple band indices and add to image as bands Parameters: Name Type Description Default img ee.Image image to calculate indices from required indices list[str] list of strings of index names to calculate. can use any named index function in geeutils. default = [\"ndvi\"] ['mndwi'] Returns: Type Description ee.Image image object with added indices Source code in hydrafloods/geeutils.py @decorators . carry_metadata def add_indices ( img , indices = [ \"mndwi\" ]): \"\"\"Function to calculate multiple band indices and add to image as bands args: img (ee.Image): image to calculate indices from indices (list[str], optional): list of strings of index names to calculate. can use any named index function in geeutils. default = [\"ndvi\"] returns: ee.Image: image object with added indices \"\"\" # create a dict to look up index functions local_funcs = globals () # loop through each index and append to images list cat_bands = [ img ] for index in indices : cat_bands . append ( local_funcs [ index ]( img )) # return images as concatenated bands return ee . Image . cat ( cat_bands ) aewinsh ( img ) Function to calculate automated water extraction index (AEWI) no shadow Expects image has \"green\", \"nir\", \"swir1\" and \"swir2\" bands. Parameters: Name Type Description Default img ee.Image image to calculate AEWInsh required Returns: Type Description ee.Image AEWInsh image Source code in hydrafloods/geeutils.py @decorators . carry_metadata def aewinsh ( img ): \"\"\"Function to calculate automated water extraction index (AEWI) no shadow Expects image has \"green\", \"nir\", \"swir1\" and \"swir2\" bands. args: img (ee.Image): image to calculate AEWInsh returns: ee.Image: AEWInsh image \"\"\" return img . expression ( \"4.0 * (g-s) - ((0.25*n) + (2.75*w))\" , { \"g\" : img . select ( \"green\" ), \"s\" : img . select ( \"swir1\" ), \"n\" : img . select ( \"nir\" ), \"w\" : img . select ( \"swir2\" ), }, ) . rename ( \"aewinsh\" ) aewish ( img ) Function to calculate automated water extraction index (AEWI) shadow Expects image has \"blue\", \"green\", \"nir\", \"swir1\" and \"swir2\" bands. Parameters: Name Type Description Default img ee.Image image to calculate AEWIsh required Returns: Type Description ee.Image AEWIsh image Source code in hydrafloods/geeutils.py @decorators . carry_metadata def aewish ( img ): \"\"\"Function to calculate automated water extraction index (AEWI) shadow Expects image has \"blue\", \"green\", \"nir\", \"swir1\" and \"swir2\" bands. args: img (ee.Image): image to calculate AEWIsh returns: ee.Image: AEWIsh image \"\"\" return img . expression ( \"b+2.5*g-1.5*(n+s)-0.25*w\" , { \"b\" : img . select ( \"blue\" ), \"g\" : img . select ( \"green\" ), \"n\" : img . select ( \"nir\" ), \"s\" : img . select ( \"swir1\" ), \"w\" : img . select ( \"swir2\" ), }, ) . rename ( \"aewish\" ) batch_export ( collection , collection_asset , region = None , prefix = None , suffix = None , scale = 1000 , crs = 'EPSG:4326' , pyramiding = None , metadata = None , verbose = False ) Function to export each image in a collection Wraps export_image will set YYYYMMdd formatted time in file name Parameters: Name Type Description Default collection ee.ImageCollection image collection to export required collection_asset str image collection asset ID to export to required region ee.Geometry region to export image None prefix str prefix string to add before time info in name None suffix str suffix string to add after time info in name None scale int resolution in meters to export image to. default = 1000 1000 crs str epsg code to export image to. default = \"EPSG:4326\" 'EPSG:4326' pyramiding dict | None dictionary defining band pyramiding scheme. if None then \"mean\" will be used as default for all bands. default = None None metadata dict | None None verbose bool False Source code in hydrafloods/geeutils.py def batch_export ( collection , collection_asset , region = None , prefix = None , suffix = None , scale = 1000 , crs = \"EPSG:4326\" , pyramiding = None , metadata = None , verbose = False , ): \"\"\"Function to export each image in a collection Wraps `export_image` will set YYYYMMdd formatted time in file name args: collection (ee.ImageCollection): image collection to export collection_asset (str): image collection asset ID to export to region (ee.Geometry): region to export image prefix (str): prefix string to add before time info in name suffix (str): suffix string to add after time info in name scale (int, optional): resolution in meters to export image to. default = 1000 crs (str, optional): epsg code to export image to. default = \"EPSG:4326\" pyramiding (dict | None, optional): dictionary defining band pyramiding scheme. if None then \"mean\" will be used as default for all bands. default = None metadata (dict | None, optional): verbose (bool, optional): \"\"\" if type ( collection ) is not ee . imagecollection . ImageCollection : try : collection = getattr ( collection , \"collection\" ) except Exception as e : raise TypeError ( \"argument collection needs to be either of type ee.ImageCollection \" \"or hydrafloods.hfCollection\" ) n = collection . size () exportImages = collection . sort ( \"system:time_start\" , False ) . toList ( n ) nIter = n . getInfo () for i in range ( nIter ): img = ee . Image ( exportImages . get ( i )) if metadata is not None : img = img . set ( metadata ) t = img . get ( \"system:time_start\" ) . getInfo () date = datetime . datetime . utcfromtimestamp ( t / 1e3 ) . strftime ( \"%Y%m %d \" ) if region is None : region = img . geometry () exportName = date if prefix is not None : exportName = f \" { prefix } _\" + exportName if suffix is not None : exportName = exportName + f \"_ { suffix } \" description = exportName if verbose : print ( f \"running export for { description } \" ) if not collection_asset . endswith ( \"/\" ): collection_asset += \"/\" exportName = collection_asset + description export_image ( img , region , exportName , description = description , scale = scale , crs = crs , pyramiding = pyramiding , ) return country_bbox ( country_name , max_error = 100 ) Function to get a bounding box geometry of a country Parameters: Name Type Description Default country_name str US-recognized country name required max_error float,optional The maximum amount of error tolerated when performing any necessary reprojection. default = 100 100 Returns: Type Description ee.Geometry geometry of country bounding box Source code in hydrafloods/geeutils.py def country_bbox ( country_name , max_error = 100 ): \"\"\"Function to get a bounding box geometry of a country args: country_name (str): US-recognized country name max_error (float,optional): The maximum amount of error tolerated when performing any necessary reprojection. default = 100 returns: ee.Geometry: geometry of country bounding box \"\"\" all_countries = ee . FeatureCollection ( \"USDOS/LSIB_SIMPLE/2017\" ) return ( all_countries . filter ( ee . Filter . eq ( \"country_na\" , country_name )) . geometry ( max_error ) . bounds ( max_error ) ) db_to_power ( img ) Function to convert SAR units from dB to power Parameters: Name Type Description Default img ee.Image SAR dB image to convert to power required Returns: Type Description ee.Image power SAR image Source code in hydrafloods/geeutils.py @decorators . carry_metadata def db_to_power ( img ): \"\"\"Function to convert SAR units from dB to power args: img (ee.Image): SAR dB image to convert to power returns: ee.Image: power SAR image \"\"\" return ee . Image ( 10 ) . pow ( img . divide ( 10 )) evi ( img ) Function to calculate Enhanced Vegetation Index (EVI). Expects image has \"blue\", \"red\", and \"nir\" bands. Parameters: Name Type Description Default img ee.Image image to calculate EVI required Returns: Type Description ee.Image EVI image Source code in hydrafloods/geeutils.py @decorators . carry_metadata def evi ( img ): \"\"\"Function to calculate Enhanced Vegetation Index (EVI). Expects image has \"blue\", \"red\", and \"nir\" bands. args: img (ee.Image): image to calculate EVI returns: ee.Image: EVI image \"\"\" return img . expression ( \"2.5*(nir-red)/(nir+6.0*red-7.5*blue+1)\" , { \"blue\" : img . select ( \"blue\" ), \"red\" : img . select ( \"red\" ), \"nir\" : img . select ( \"nir\" ), }, ) . rename ( \"evi\" ) export_image ( image , region , asset_id , description = None , scale = 1000 , crs = 'EPSG:4326' , pyramiding = None ) Function to wrap image export with EE Python API Parameters: Name Type Description Default image ee.Image image to export required region ee.Geometry region to export image required asset_id str asset ID to export image to required description str | None description to identify image export/ if None then description will be random string. default = None None scale int resolution in meters to export image to. default = 1000 1000 crs str epsg code to export image to. default = \"EPSG:4326\" 'EPSG:4326' pyramiding dict | None dictionary defining band pyramiding scheme. if None then \"mean\" will be used as default for all bands. default = None None Source code in hydrafloods/geeutils.py def export_image ( image , region , asset_id , description = None , scale = 1000 , crs = \"EPSG:4326\" , pyramiding = None , ): \"\"\"Function to wrap image export with EE Python API args: image (ee.Image): image to export region (ee.Geometry): region to export image asset_id (str): asset ID to export image to description (str | None, optional): description to identify image export/ if None then description will be random string. default = None scale (int, optional): resolution in meters to export image to. default = 1000 crs (str, optional): epsg code to export image to. default = \"EPSG:4326\" pyramiding (dict | None, optional): dictionary defining band pyramiding scheme. if None then \"mean\" will be used as default for all bands. default = None \"\"\" if ( description == None ) or ( type ( description ) != str ): description = \"\" . join ( random . SystemRandom () . choice ( string . ascii_letters ) for _ in range ( 8 ) ) . lower () # get serializable geometry for export export_region = region . bounds ( maxError = 10 ) . getInfo ()[ \"coordinates\" ] if pyramiding is None : pyramiding = { \".default\" : \"mean\" } # set export process export = ee . batch . Export . image . toAsset ( image , description = description , assetId = asset_id , scale = scale , region = export_region , maxPixels = 1e13 , crs = crs , pyramidingPolicy = pyramiding , ) # start export process export . start () return extract_bits ( image , start , end = None , new_name = None ) Function to conver qa bits to binary flag image Parameters: Name Type Description Default image ee.Image qa image to extract bit from required start int starting bit for flag required end int | None ending bit for flag, if None then will only use start bit. default = None None new_name str | None output name of resulting image, if None name will be {start}Bits. default = None None Returns: Type Description ee.Image image with extract bits Source code in hydrafloods/geeutils.py def extract_bits ( image , start , end = None , new_name = None ): \"\"\"Function to conver qa bits to binary flag image args: image (ee.Image): qa image to extract bit from start (int): starting bit for flag end (int | None, optional): ending bit for flag, if None then will only use start bit. default = None new_name (str | None, optional): output name of resulting image, if None name will be {start}Bits. default = None returns: ee.Image: image with extract bits \"\"\" newname = new_name if new_name is not None else f \" { start } Bits\" if ( start == end ) or ( end is None ): # perform a bit shift with bitwiseAnd return image . select ([ 0 ], [ newname ]) . bitwiseAnd ( 1 << start ) else : # Compute the bits we need to extract. pattern = 0 for i in range ( start , end ): pattern += int ( math . pow ( 2 , i )) # Return a single band image of the extracted QA bits, giving the band # a new name. return image . select ([ 0 ], [ newname ]) . bitwiseAnd ( pattern ) . rightShift ( start ) get_geoms ( img ) Helper function to get geometry from image Parameters: Name Type Description Default img ee.Image image to get geometry from required Returns: Type Description ee.Geometry geometry of image Source code in hydrafloods/geeutils.py def get_geoms ( img ): \"\"\"Helper function to get geometry from image args: img (ee.Image): image to get geometry from returns: ee.Geometry: geometry of image \"\"\" return img . geometry () gwi ( img ) Function to calculate general water index (GWI) Expects image has \"green\", \"red\", \"nir\", and \"swir1\" bands. Parameters: Name Type Description Default img ee.Image image to calculate GWI required Returns: Type Description ee.Image GWI image Source code in hydrafloods/geeutils.py @decorators . carry_metadata def gwi ( img ): \"\"\"Function to calculate general water index (GWI) Expects image has \"green\", \"red\", \"nir\", and \"swir1\" bands. args: img (ee.Image): image to calculate GWI returns: ee.Image: GWI image \"\"\" return img . expression ( \"(g+r)-(n+s)\" , { \"g\" : img . select ( \"green\" ), \"r\" : img . select ( \"red\" ), \"n\" : img . select ( \"nir\" ), \"s\" : img . select ( \"swir1\" ), }, ) . rename ( \"gwi\" ) lswi ( img ) Function to calculate land surface water index (LSWI). Expects image has \"nir\" and \"swir1\" bands. Parameters: Name Type Description Default img ee.Image image to calculate LSWI required Returns: Type Description ee.Image LSWI image Source code in hydrafloods/geeutils.py @decorators . carry_metadata def lswi ( img ): \"\"\"Function to calculate land surface water index (LSWI). Expects image has \"nir\" and \"swir1\" bands. args: img (ee.Image): image to calculate LSWI returns: ee.Image: LSWI image \"\"\" return img . expression ( \"(nir-swir)/(nir+swir)\" , { \"nir\" : img . select ( \"nir\" ), \"swir\" : img . select ( \"swir1\" )} ) . rename ( \"lswi\" ) mndwi ( img ) Function to calculate modified Difference Water Index (MNDWI). Expects image has \"green\" and \"swir1\" bands. Parameters: Name Type Description Default img ee.Image image to calculate MNDWI required Returns: Type Description ee.Image MNDWI image Source code in hydrafloods/geeutils.py @decorators . carry_metadata def mndwi ( img ): \"\"\"Function to calculate modified Difference Water Index (MNDWI). Expects image has \"green\" and \"swir1\" bands. args: img (ee.Image): image to calculate MNDWI returns: ee.Image: MNDWI image \"\"\" return img . normalizedDifference ([ \"green\" , \"swir1\" ]) . rename ( \"mndwi\" ) ndvi ( img ) Function to calculate Normalized Difference Vegetation Index (NDVI). Expects image has \"nir\" and \"red\" bands. Parameters: Name Type Description Default img ee.Image image to calculate NDVI required Returns: Type Description ee.Image NDVI image Source code in hydrafloods/geeutils.py @decorators . carry_metadata def ndvi ( img ): \"\"\"Function to calculate Normalized Difference Vegetation Index (NDVI). Expects image has \"nir\" and \"red\" bands. args: img (ee.Image): image to calculate NDVI returns: ee.Image: NDVI image \"\"\" return img . normalizedDifference ([ \"nir\" , \"red\" ]) . rename ( \"ndvi\" ) nwi ( img ) Function to calculate new water index (NWI). Expects image has \"blue\", \"nir\", \"swir1\" and \"swir2\" bands. Parameters: Name Type Description Default img ee.Image image to calculate NWI required Returns: Type Description ee.Image NWI image Source code in hydrafloods/geeutils.py @decorators . carry_metadata def nwi ( img ): \"\"\"Function to calculate new water index (NWI). Expects image has \"blue\", \"nir\", \"swir1\" and \"swir2\" bands. args: img (ee.Image): image to calculate NWI returns: ee.Image: NWI image \"\"\" return img . expression ( \"((b-(n+s+w))/(b+(n+s+w))*100)\" , { \"b\" : img . select ( \"blue\" ), \"n\" : img . select ( \"nir\" ), \"s\" : img . select ( \"swir1\" ), \"w\" : img . select ( \"swir2\" ), }, ) . rename ( \"nwi\" ) power_to_db ( img ) Function to convert SAR units from power to dB Parameters: Name Type Description Default img ee.Image SAR power image to convert to dB required Returns: Type Description ee.Image dB SAR image Source code in hydrafloods/geeutils.py @decorators . carry_metadata def power_to_db ( img ): \"\"\"Function to convert SAR units from power to dB args: img (ee.Image): SAR power image to convert to dB returns: ee.Image: dB SAR image \"\"\" return ee . Image ( 10 ) . multiply ( img . log10 ()) tile_region ( region , grid_size = 0.1 , intersect_geom = None , contain_geom = None ) Function to create a feature collection of tiles covering a region Parameters: Name Type Description Default region ee.Geometry region to create tile grid over required grid_size float resolution in decimal degrees to create tiles. default = 0.1 0.1 intersect_geom ee.Geometry | None geometry object to filter tiles that intesect with geometry useful for filtering tiles that are created over oceans with no data. default = None None contain_geom ee.Geometry | None geometry object to filter tiles that are contained within geometry useful for filtering tiles that are only in an area. default = None None Returns: Type Description ee.FeatureCollection collection of feature tiles at a given grid_size over a region Source code in hydrafloods/geeutils.py def tile_region ( region , grid_size = 0.1 , intersect_geom = None , contain_geom = None ): \"\"\"Function to create a feature collection of tiles covering a region args: region (ee.Geometry): region to create tile grid over grid_size (float, optional): resolution in decimal degrees to create tiles. default = 0.1 intersect_geom (ee.Geometry | None, optional): geometry object to filter tiles that intesect with geometry useful for filtering tiles that are created over oceans with no data. default = None contain_geom (ee.Geometry | None, optional): geometry object to filter tiles that are contained within geometry useful for filtering tiles that are only in an area. default = None returns: ee.FeatureCollection: collection of feature tiles at a given grid_size over a region \"\"\" # nesting grid construction along y and then x coordinates def constuctGrid ( i ): \"\"\"Closure function to contruct grid \"\"\" def contructXGrid ( j ): j = ee . Number ( j ) box = ee . Feature ( ee . Geometry . Rectangle ( [ j , i , j . add ( grid_size ), i . add ( grid_size )], \"epsg:4326\" , geodesic = False , ) ) if contain_geom is not None : out = ee . Algorithms . If ( region . contains ( contain_geom , maxError = 10 ), box , None ) elif intersect_geom is not None : out = ee . Algorithms . If ( region . intersects ( intersect_geom , maxError = 10 ), box , None ) else : out = box return ee . Feature ( out ) i = ee . Number ( i ) out = ee . List . sequence ( west , east . subtract ( grid_size ), grid_size ) . map ( contructXGrid ) return out if ( contain_geom is not None ) and ( intersect_geom is not None ): raise ValueError ( \"contains and intersection keywords are mutually exclusive, please define only one\" ) bounds = region . bounds ( maxError = 100 ) coords = ee . List ( bounds . coordinates () . get ( 0 )) grid_res = ee . Number ( grid_size ) west = ee . Number ( ee . List ( coords . get ( 0 )) . get ( 0 )) south = ee . Number ( ee . List ( coords . get ( 0 )) . get ( 1 )) east = ee . Number ( ee . List ( coords . get ( 2 )) . get ( 0 )) north = ee . Number ( ee . List ( coords . get ( 2 )) . get ( 1 )) west = west . subtract ( west . mod ( grid_res )) south = south . subtract ( south . mod ( grid_res )) east = east . add ( grid_res . subtract ( east . mod ( grid_res ))) north = north . add ( grid_res . subtract ( north . mod ( grid_res ))) grid = ee . FeatureCollection ( ee . List . sequence ( south , north . subtract ( grid_res ), grid_res ) . map ( constuctGrid ) . flatten () ) return grid","title":"geeutils module"},{"location":"geeutils/#hydrafloods.geeutils","text":"","title":"geeutils"},{"location":"geeutils/#hydrafloods.geeutils.add_indices","text":"Function to calculate multiple band indices and add to image as bands Parameters: Name Type Description Default img ee.Image image to calculate indices from required indices list[str] list of strings of index names to calculate. can use any named index function in geeutils. default = [\"ndvi\"] ['mndwi'] Returns: Type Description ee.Image image object with added indices Source code in hydrafloods/geeutils.py @decorators . carry_metadata def add_indices ( img , indices = [ \"mndwi\" ]): \"\"\"Function to calculate multiple band indices and add to image as bands args: img (ee.Image): image to calculate indices from indices (list[str], optional): list of strings of index names to calculate. can use any named index function in geeutils. default = [\"ndvi\"] returns: ee.Image: image object with added indices \"\"\" # create a dict to look up index functions local_funcs = globals () # loop through each index and append to images list cat_bands = [ img ] for index in indices : cat_bands . append ( local_funcs [ index ]( img )) # return images as concatenated bands return ee . Image . cat ( cat_bands )","title":"add_indices()"},{"location":"geeutils/#hydrafloods.geeutils.aewinsh","text":"Function to calculate automated water extraction index (AEWI) no shadow Expects image has \"green\", \"nir\", \"swir1\" and \"swir2\" bands. Parameters: Name Type Description Default img ee.Image image to calculate AEWInsh required Returns: Type Description ee.Image AEWInsh image Source code in hydrafloods/geeutils.py @decorators . carry_metadata def aewinsh ( img ): \"\"\"Function to calculate automated water extraction index (AEWI) no shadow Expects image has \"green\", \"nir\", \"swir1\" and \"swir2\" bands. args: img (ee.Image): image to calculate AEWInsh returns: ee.Image: AEWInsh image \"\"\" return img . expression ( \"4.0 * (g-s) - ((0.25*n) + (2.75*w))\" , { \"g\" : img . select ( \"green\" ), \"s\" : img . select ( \"swir1\" ), \"n\" : img . select ( \"nir\" ), \"w\" : img . select ( \"swir2\" ), }, ) . rename ( \"aewinsh\" )","title":"aewinsh()"},{"location":"geeutils/#hydrafloods.geeutils.aewish","text":"Function to calculate automated water extraction index (AEWI) shadow Expects image has \"blue\", \"green\", \"nir\", \"swir1\" and \"swir2\" bands. Parameters: Name Type Description Default img ee.Image image to calculate AEWIsh required Returns: Type Description ee.Image AEWIsh image Source code in hydrafloods/geeutils.py @decorators . carry_metadata def aewish ( img ): \"\"\"Function to calculate automated water extraction index (AEWI) shadow Expects image has \"blue\", \"green\", \"nir\", \"swir1\" and \"swir2\" bands. args: img (ee.Image): image to calculate AEWIsh returns: ee.Image: AEWIsh image \"\"\" return img . expression ( \"b+2.5*g-1.5*(n+s)-0.25*w\" , { \"b\" : img . select ( \"blue\" ), \"g\" : img . select ( \"green\" ), \"n\" : img . select ( \"nir\" ), \"s\" : img . select ( \"swir1\" ), \"w\" : img . select ( \"swir2\" ), }, ) . rename ( \"aewish\" )","title":"aewish()"},{"location":"geeutils/#hydrafloods.geeutils.batch_export","text":"Function to export each image in a collection Wraps export_image will set YYYYMMdd formatted time in file name Parameters: Name Type Description Default collection ee.ImageCollection image collection to export required collection_asset str image collection asset ID to export to required region ee.Geometry region to export image None prefix str prefix string to add before time info in name None suffix str suffix string to add after time info in name None scale int resolution in meters to export image to. default = 1000 1000 crs str epsg code to export image to. default = \"EPSG:4326\" 'EPSG:4326' pyramiding dict | None dictionary defining band pyramiding scheme. if None then \"mean\" will be used as default for all bands. default = None None metadata dict | None None verbose bool False Source code in hydrafloods/geeutils.py def batch_export ( collection , collection_asset , region = None , prefix = None , suffix = None , scale = 1000 , crs = \"EPSG:4326\" , pyramiding = None , metadata = None , verbose = False , ): \"\"\"Function to export each image in a collection Wraps `export_image` will set YYYYMMdd formatted time in file name args: collection (ee.ImageCollection): image collection to export collection_asset (str): image collection asset ID to export to region (ee.Geometry): region to export image prefix (str): prefix string to add before time info in name suffix (str): suffix string to add after time info in name scale (int, optional): resolution in meters to export image to. default = 1000 crs (str, optional): epsg code to export image to. default = \"EPSG:4326\" pyramiding (dict | None, optional): dictionary defining band pyramiding scheme. if None then \"mean\" will be used as default for all bands. default = None metadata (dict | None, optional): verbose (bool, optional): \"\"\" if type ( collection ) is not ee . imagecollection . ImageCollection : try : collection = getattr ( collection , \"collection\" ) except Exception as e : raise TypeError ( \"argument collection needs to be either of type ee.ImageCollection \" \"or hydrafloods.hfCollection\" ) n = collection . size () exportImages = collection . sort ( \"system:time_start\" , False ) . toList ( n ) nIter = n . getInfo () for i in range ( nIter ): img = ee . Image ( exportImages . get ( i )) if metadata is not None : img = img . set ( metadata ) t = img . get ( \"system:time_start\" ) . getInfo () date = datetime . datetime . utcfromtimestamp ( t / 1e3 ) . strftime ( \"%Y%m %d \" ) if region is None : region = img . geometry () exportName = date if prefix is not None : exportName = f \" { prefix } _\" + exportName if suffix is not None : exportName = exportName + f \"_ { suffix } \" description = exportName if verbose : print ( f \"running export for { description } \" ) if not collection_asset . endswith ( \"/\" ): collection_asset += \"/\" exportName = collection_asset + description export_image ( img , region , exportName , description = description , scale = scale , crs = crs , pyramiding = pyramiding , ) return","title":"batch_export()"},{"location":"geeutils/#hydrafloods.geeutils.country_bbox","text":"Function to get a bounding box geometry of a country Parameters: Name Type Description Default country_name str US-recognized country name required max_error float,optional The maximum amount of error tolerated when performing any necessary reprojection. default = 100 100 Returns: Type Description ee.Geometry geometry of country bounding box Source code in hydrafloods/geeutils.py def country_bbox ( country_name , max_error = 100 ): \"\"\"Function to get a bounding box geometry of a country args: country_name (str): US-recognized country name max_error (float,optional): The maximum amount of error tolerated when performing any necessary reprojection. default = 100 returns: ee.Geometry: geometry of country bounding box \"\"\" all_countries = ee . FeatureCollection ( \"USDOS/LSIB_SIMPLE/2017\" ) return ( all_countries . filter ( ee . Filter . eq ( \"country_na\" , country_name )) . geometry ( max_error ) . bounds ( max_error ) )","title":"country_bbox()"},{"location":"geeutils/#hydrafloods.geeutils.db_to_power","text":"Function to convert SAR units from dB to power Parameters: Name Type Description Default img ee.Image SAR dB image to convert to power required Returns: Type Description ee.Image power SAR image Source code in hydrafloods/geeutils.py @decorators . carry_metadata def db_to_power ( img ): \"\"\"Function to convert SAR units from dB to power args: img (ee.Image): SAR dB image to convert to power returns: ee.Image: power SAR image \"\"\" return ee . Image ( 10 ) . pow ( img . divide ( 10 ))","title":"db_to_power()"},{"location":"geeutils/#hydrafloods.geeutils.evi","text":"Function to calculate Enhanced Vegetation Index (EVI). Expects image has \"blue\", \"red\", and \"nir\" bands. Parameters: Name Type Description Default img ee.Image image to calculate EVI required Returns: Type Description ee.Image EVI image Source code in hydrafloods/geeutils.py @decorators . carry_metadata def evi ( img ): \"\"\"Function to calculate Enhanced Vegetation Index (EVI). Expects image has \"blue\", \"red\", and \"nir\" bands. args: img (ee.Image): image to calculate EVI returns: ee.Image: EVI image \"\"\" return img . expression ( \"2.5*(nir-red)/(nir+6.0*red-7.5*blue+1)\" , { \"blue\" : img . select ( \"blue\" ), \"red\" : img . select ( \"red\" ), \"nir\" : img . select ( \"nir\" ), }, ) . rename ( \"evi\" )","title":"evi()"},{"location":"geeutils/#hydrafloods.geeutils.export_image","text":"Function to wrap image export with EE Python API Parameters: Name Type Description Default image ee.Image image to export required region ee.Geometry region to export image required asset_id str asset ID to export image to required description str | None description to identify image export/ if None then description will be random string. default = None None scale int resolution in meters to export image to. default = 1000 1000 crs str epsg code to export image to. default = \"EPSG:4326\" 'EPSG:4326' pyramiding dict | None dictionary defining band pyramiding scheme. if None then \"mean\" will be used as default for all bands. default = None None Source code in hydrafloods/geeutils.py def export_image ( image , region , asset_id , description = None , scale = 1000 , crs = \"EPSG:4326\" , pyramiding = None , ): \"\"\"Function to wrap image export with EE Python API args: image (ee.Image): image to export region (ee.Geometry): region to export image asset_id (str): asset ID to export image to description (str | None, optional): description to identify image export/ if None then description will be random string. default = None scale (int, optional): resolution in meters to export image to. default = 1000 crs (str, optional): epsg code to export image to. default = \"EPSG:4326\" pyramiding (dict | None, optional): dictionary defining band pyramiding scheme. if None then \"mean\" will be used as default for all bands. default = None \"\"\" if ( description == None ) or ( type ( description ) != str ): description = \"\" . join ( random . SystemRandom () . choice ( string . ascii_letters ) for _ in range ( 8 ) ) . lower () # get serializable geometry for export export_region = region . bounds ( maxError = 10 ) . getInfo ()[ \"coordinates\" ] if pyramiding is None : pyramiding = { \".default\" : \"mean\" } # set export process export = ee . batch . Export . image . toAsset ( image , description = description , assetId = asset_id , scale = scale , region = export_region , maxPixels = 1e13 , crs = crs , pyramidingPolicy = pyramiding , ) # start export process export . start () return","title":"export_image()"},{"location":"geeutils/#hydrafloods.geeutils.extract_bits","text":"Function to conver qa bits to binary flag image Parameters: Name Type Description Default image ee.Image qa image to extract bit from required start int starting bit for flag required end int | None ending bit for flag, if None then will only use start bit. default = None None new_name str | None output name of resulting image, if None name will be {start}Bits. default = None None Returns: Type Description ee.Image image with extract bits Source code in hydrafloods/geeutils.py def extract_bits ( image , start , end = None , new_name = None ): \"\"\"Function to conver qa bits to binary flag image args: image (ee.Image): qa image to extract bit from start (int): starting bit for flag end (int | None, optional): ending bit for flag, if None then will only use start bit. default = None new_name (str | None, optional): output name of resulting image, if None name will be {start}Bits. default = None returns: ee.Image: image with extract bits \"\"\" newname = new_name if new_name is not None else f \" { start } Bits\" if ( start == end ) or ( end is None ): # perform a bit shift with bitwiseAnd return image . select ([ 0 ], [ newname ]) . bitwiseAnd ( 1 << start ) else : # Compute the bits we need to extract. pattern = 0 for i in range ( start , end ): pattern += int ( math . pow ( 2 , i )) # Return a single band image of the extracted QA bits, giving the band # a new name. return image . select ([ 0 ], [ newname ]) . bitwiseAnd ( pattern ) . rightShift ( start )","title":"extract_bits()"},{"location":"geeutils/#hydrafloods.geeutils.get_geoms","text":"Helper function to get geometry from image Parameters: Name Type Description Default img ee.Image image to get geometry from required Returns: Type Description ee.Geometry geometry of image Source code in hydrafloods/geeutils.py def get_geoms ( img ): \"\"\"Helper function to get geometry from image args: img (ee.Image): image to get geometry from returns: ee.Geometry: geometry of image \"\"\" return img . geometry ()","title":"get_geoms()"},{"location":"geeutils/#hydrafloods.geeutils.gwi","text":"Function to calculate general water index (GWI) Expects image has \"green\", \"red\", \"nir\", and \"swir1\" bands. Parameters: Name Type Description Default img ee.Image image to calculate GWI required Returns: Type Description ee.Image GWI image Source code in hydrafloods/geeutils.py @decorators . carry_metadata def gwi ( img ): \"\"\"Function to calculate general water index (GWI) Expects image has \"green\", \"red\", \"nir\", and \"swir1\" bands. args: img (ee.Image): image to calculate GWI returns: ee.Image: GWI image \"\"\" return img . expression ( \"(g+r)-(n+s)\" , { \"g\" : img . select ( \"green\" ), \"r\" : img . select ( \"red\" ), \"n\" : img . select ( \"nir\" ), \"s\" : img . select ( \"swir1\" ), }, ) . rename ( \"gwi\" )","title":"gwi()"},{"location":"geeutils/#hydrafloods.geeutils.lswi","text":"Function to calculate land surface water index (LSWI). Expects image has \"nir\" and \"swir1\" bands. Parameters: Name Type Description Default img ee.Image image to calculate LSWI required Returns: Type Description ee.Image LSWI image Source code in hydrafloods/geeutils.py @decorators . carry_metadata def lswi ( img ): \"\"\"Function to calculate land surface water index (LSWI). Expects image has \"nir\" and \"swir1\" bands. args: img (ee.Image): image to calculate LSWI returns: ee.Image: LSWI image \"\"\" return img . expression ( \"(nir-swir)/(nir+swir)\" , { \"nir\" : img . select ( \"nir\" ), \"swir\" : img . select ( \"swir1\" )} ) . rename ( \"lswi\" )","title":"lswi()"},{"location":"geeutils/#hydrafloods.geeutils.mndwi","text":"Function to calculate modified Difference Water Index (MNDWI). Expects image has \"green\" and \"swir1\" bands. Parameters: Name Type Description Default img ee.Image image to calculate MNDWI required Returns: Type Description ee.Image MNDWI image Source code in hydrafloods/geeutils.py @decorators . carry_metadata def mndwi ( img ): \"\"\"Function to calculate modified Difference Water Index (MNDWI). Expects image has \"green\" and \"swir1\" bands. args: img (ee.Image): image to calculate MNDWI returns: ee.Image: MNDWI image \"\"\" return img . normalizedDifference ([ \"green\" , \"swir1\" ]) . rename ( \"mndwi\" )","title":"mndwi()"},{"location":"geeutils/#hydrafloods.geeutils.ndvi","text":"Function to calculate Normalized Difference Vegetation Index (NDVI). Expects image has \"nir\" and \"red\" bands. Parameters: Name Type Description Default img ee.Image image to calculate NDVI required Returns: Type Description ee.Image NDVI image Source code in hydrafloods/geeutils.py @decorators . carry_metadata def ndvi ( img ): \"\"\"Function to calculate Normalized Difference Vegetation Index (NDVI). Expects image has \"nir\" and \"red\" bands. args: img (ee.Image): image to calculate NDVI returns: ee.Image: NDVI image \"\"\" return img . normalizedDifference ([ \"nir\" , \"red\" ]) . rename ( \"ndvi\" )","title":"ndvi()"},{"location":"geeutils/#hydrafloods.geeutils.nwi","text":"Function to calculate new water index (NWI). Expects image has \"blue\", \"nir\", \"swir1\" and \"swir2\" bands. Parameters: Name Type Description Default img ee.Image image to calculate NWI required Returns: Type Description ee.Image NWI image Source code in hydrafloods/geeutils.py @decorators . carry_metadata def nwi ( img ): \"\"\"Function to calculate new water index (NWI). Expects image has \"blue\", \"nir\", \"swir1\" and \"swir2\" bands. args: img (ee.Image): image to calculate NWI returns: ee.Image: NWI image \"\"\" return img . expression ( \"((b-(n+s+w))/(b+(n+s+w))*100)\" , { \"b\" : img . select ( \"blue\" ), \"n\" : img . select ( \"nir\" ), \"s\" : img . select ( \"swir1\" ), \"w\" : img . select ( \"swir2\" ), }, ) . rename ( \"nwi\" )","title":"nwi()"},{"location":"geeutils/#hydrafloods.geeutils.power_to_db","text":"Function to convert SAR units from power to dB Parameters: Name Type Description Default img ee.Image SAR power image to convert to dB required Returns: Type Description ee.Image dB SAR image Source code in hydrafloods/geeutils.py @decorators . carry_metadata def power_to_db ( img ): \"\"\"Function to convert SAR units from power to dB args: img (ee.Image): SAR power image to convert to dB returns: ee.Image: dB SAR image \"\"\" return ee . Image ( 10 ) . multiply ( img . log10 ())","title":"power_to_db()"},{"location":"geeutils/#hydrafloods.geeutils.tile_region","text":"Function to create a feature collection of tiles covering a region Parameters: Name Type Description Default region ee.Geometry region to create tile grid over required grid_size float resolution in decimal degrees to create tiles. default = 0.1 0.1 intersect_geom ee.Geometry | None geometry object to filter tiles that intesect with geometry useful for filtering tiles that are created over oceans with no data. default = None None contain_geom ee.Geometry | None geometry object to filter tiles that are contained within geometry useful for filtering tiles that are only in an area. default = None None Returns: Type Description ee.FeatureCollection collection of feature tiles at a given grid_size over a region Source code in hydrafloods/geeutils.py def tile_region ( region , grid_size = 0.1 , intersect_geom = None , contain_geom = None ): \"\"\"Function to create a feature collection of tiles covering a region args: region (ee.Geometry): region to create tile grid over grid_size (float, optional): resolution in decimal degrees to create tiles. default = 0.1 intersect_geom (ee.Geometry | None, optional): geometry object to filter tiles that intesect with geometry useful for filtering tiles that are created over oceans with no data. default = None contain_geom (ee.Geometry | None, optional): geometry object to filter tiles that are contained within geometry useful for filtering tiles that are only in an area. default = None returns: ee.FeatureCollection: collection of feature tiles at a given grid_size over a region \"\"\" # nesting grid construction along y and then x coordinates def constuctGrid ( i ): \"\"\"Closure function to contruct grid \"\"\" def contructXGrid ( j ): j = ee . Number ( j ) box = ee . Feature ( ee . Geometry . Rectangle ( [ j , i , j . add ( grid_size ), i . add ( grid_size )], \"epsg:4326\" , geodesic = False , ) ) if contain_geom is not None : out = ee . Algorithms . If ( region . contains ( contain_geom , maxError = 10 ), box , None ) elif intersect_geom is not None : out = ee . Algorithms . If ( region . intersects ( intersect_geom , maxError = 10 ), box , None ) else : out = box return ee . Feature ( out ) i = ee . Number ( i ) out = ee . List . sequence ( west , east . subtract ( grid_size ), grid_size ) . map ( contructXGrid ) return out if ( contain_geom is not None ) and ( intersect_geom is not None ): raise ValueError ( \"contains and intersection keywords are mutually exclusive, please define only one\" ) bounds = region . bounds ( maxError = 100 ) coords = ee . List ( bounds . coordinates () . get ( 0 )) grid_res = ee . Number ( grid_size ) west = ee . Number ( ee . List ( coords . get ( 0 )) . get ( 0 )) south = ee . Number ( ee . List ( coords . get ( 0 )) . get ( 1 )) east = ee . Number ( ee . List ( coords . get ( 2 )) . get ( 0 )) north = ee . Number ( ee . List ( coords . get ( 2 )) . get ( 1 )) west = west . subtract ( west . mod ( grid_res )) south = south . subtract ( south . mod ( grid_res )) east = east . add ( grid_res . subtract ( east . mod ( grid_res ))) north = north . add ( grid_res . subtract ( north . mod ( grid_res ))) grid = ee . FeatureCollection ( ee . List . sequence ( south , north . subtract ( grid_res ), grid_res ) . map ( constuctGrid ) . flatten () ) return grid","title":"tile_region()"},{"location":"getting-started/","text":"Here are some quick examples of what you can do with hydrafloods . It is expected that the code is run in an interactive python session such as IPython or in a Jupyter Notebook as later code blocks will use variables from previous ones. To get started, first import the ee , trigger the Earth Engine authentication flow, and import the hydrafloods package: import ee ee . Initialize () import hydrafloods as hf Get a hf.Dataset You can access commonly used image collections on Earth Engine as a hydrafloods.Dataset to quickly filter by space and time as well as apply pre-written QA masking functions. # define a geographic region region = hf . country_bbox ( \"Cambodia\" ) # define start and end times start_time = \"2019-09-15\" end_time = \"2019-09-20\" # get the Sentinel 1 collection as a Dataset s1 = hf . Sentinel1 ( region , start_time , end_time ) # print dataset info print ( s1 ) # print the number of images in Dataset print ( s1 . n_images ) # print a list of image acquisition dates for the Dataset print ( s1 . dates ) # access the actual ee.ImageCollection object ee_collection = s1 . collection The hydrafloods.Dataset object is a wrapper around an ee.ImageCollection by applying the spatial and temporal filtering upon initialization. This provides a quick and consistent access to imagery. The Dataset class also provides utility functionality to make working with and managing multiple image collections less verbose. There are many ways to interface with datasets (i.e. ImageCollections) using hydrafloods , more examples on merging or joining datasets can be found on the Using Dataset class page. Image processing The main purpose of hydrafloods is to lower the barrier to creating high-quality surface water maps, this requires image processing. Although the Dataset class wraps an Earth Engine image collection we can apply image processing functions using apply_func() by passing a function object. This method wraps a function that accepts an image as the first argument (which most hydrafloods image processing algorithms do) and maps it over the collection. For example, we would like to apply a speckle filter algorithm on SAR imagery. We can easily do this with the following code. # apply a speckle filtering algorithm on SAR imagery # here we will use the Gamma Map filter filtered = s1 . apply_func ( hf . gamma_map ) The previous example is synonymous with using s1.collection = s1.collection.map(hf.gamma_map) which access the image collection, applies the function, and sets the results to the s1.collection property. Although this technically works, using the apply_func() method is advantageous and preferred as it allows us to pass arbitrary keyword parameters to functions which we want to apply. For example, the water mapping algorithms found in hydrafloods.thresholding take many keyword parameters and we can customize function as in the following example. # apply the edge otsu surface water mapping # we apply this on the speckle filtered SAR data water_maps = filtered . apply_func ( hf . edge_otsu , initial_threshold =- 16 , edge_buffer = 300 , scale = 250 ) It should be noted that using the apply_func() method will return a hydrafloods.Dataset where the collection property has the results of the function. One can access the ee.ImageCollection object and reduce to and image using the following code: # reduce the Dataset.collection property to an ee.Image water_img = water_maps . collection . reduce ( \"mode\" ) There are a variety of image processing functions available in hydrafloods , more information on specific algorithms can be found on the Algorithms page. Time series processing In addition to image processing, processing data in time is valuable. Therefore, hydrafloods has a specific module for time series processing, hydrafloods.timeseries , specifically for processing stacks of imagery in time. # import in the timeseries module from hydrafloods import timeseries Here we are going to take a longer time series of SAR imagery for 2019 so we have more data for our model: # define start and end times for one year in 2019 start_time = \"2019-01-01\" end_time = \"2020-01-01\" # get the Sentinel 1 collection as a Dataset # using Cambodia still as the region s1 = hf . Sentinel1 ( region , start_time , end_time ) Now that we have our time series of data, we can begin to model some temporal information. For example, we want to model a harmonic trend of SAR imagery to predict an image using time information. # fit a harmonic trend model on the VV band in time # use two harmonic cycles harmonics_weights = timeseries . fit_harmonic_trend ( s1 , dependent = 'VV' , n_cycles = 2 ) The result from fit_harmonic_trend() will be an image with many bands. Some bands are the coefficeint weights for prediction, others can be awareness information (like number of valid observations used). So we will filter out the bands we need which start with either \"c\", \"t\", or \"s\". Then get a dummy image with time information and apply the prediction. # extract bands needed for prediction harmonic_weights = harmonics . select ( \"^(c|t|s).*\" ) # get a dummy image with just time information for prediction # for flooding date in Oct 2019 dummy_img = timeseries . get_dummy_img ( \"2019-10-05\" ) # predict the VV values using the dummy img and computed harmonic coeffients prediction = ( timeseries . add_harmonic_coefs ( dummy_img ) . multiply ( harmonic_weights ) . reduce ( \"sum\" ) ) Time series functionality in hydrafloods is focused around modeling data in time, more information on the functions can be found in the timeseries module API reference Machine Learning hydrafloods also has a specific module for machine learning workflows with Earth Engine, hydrafloods.ml . # import in the ml module from hydrafloods import ml The aim with this module is to make high-quality machine learning workflows easier and less verbose when working with Earth Engine. However, we will will still need to access feature collection information to train models. Here we will define some parameters for an example: # define some parameters for the ml workflow we will use # define feature columns to use for training/prediction feature_names = [ 'VV' , 'VH' , 'ratio' , 'ndpi' ] # get a feature collection for training/testing fc = ( ee . FeatureCollection ( \"projects/servir-ee/assets/sar_wi_samples_20200825104400\" ) . randomColumn ( \"random\" ) ) # split the feature collection into training/testing datasets # good practice to do this training = fc . filter ( ee . Filter . lte ( \"random\" , 0.7 )) testing = fc . filter ( ee . Filter . gt ( \"random\" , 0.7 )) Now that we have our datasets and features defined, we can begin the workflow. Typically with machine learning one would perform a feature scaling to get all features within the same range, this helps with numerical stability, training speed, and model accuracy. This can be quite cumbersome to do efficiently in Earth Engine...however, the ml module allows us to scale and train in one shot. # scale training dataset and train random forest model # note this returns a trained ee.Classifier and dictionary to scale data later rf , scaling_dict = ml . random_forest_ee ( 25 , training , feature_names , 'mndwi' , scaling = \"standard\" , mode = \"regression\" ) This function returns a train random forest ee.Classifier and a ee.Dictionary with per band values needed to scale other feature collections or imagery as seen in the next example. Here we scale the testing dataset using the values from the training dataset and apply the model on the feature collection. # scale the testing dataset using the scaling values from training testing_norm = ml . standard_feature_scaling ( testing , scaling_dict , feature_names ) # apply random forest model on scaled test feature collection dataset y_test = testing_norm . classify ( rf , \"predicted\" ) Majority of the time we would like to apply the predictions on imagery and the ml module has functionality to perfrom the scaling for imagery easily. First we have to add the bands to dataset collection which the Sentinel1 dataset class has a custom method to add the VV/VH ratio and VV-VH normalized difference bands. # add bands for features used in RF model s1_features = s1 . add_fusion_features () # scale the bands using the scaling_dict s1_norm = s1_features . apply_func ( ml . standard_image_scaling , scaling_dict = scaling_dict , ) # apply the prediction on the dataset predicted = s1_norm . apply_func ( lambda x : x . classify ( rf )) Again, most of the functionality around the hydrafloods.ml module is to make end-to-end machine learning work flows more straightforward. Please see the ml module documentation for information on functions.","title":"Getting Started"},{"location":"getting-started/#get-a-hfdataset","text":"You can access commonly used image collections on Earth Engine as a hydrafloods.Dataset to quickly filter by space and time as well as apply pre-written QA masking functions. # define a geographic region region = hf . country_bbox ( \"Cambodia\" ) # define start and end times start_time = \"2019-09-15\" end_time = \"2019-09-20\" # get the Sentinel 1 collection as a Dataset s1 = hf . Sentinel1 ( region , start_time , end_time ) # print dataset info print ( s1 ) # print the number of images in Dataset print ( s1 . n_images ) # print a list of image acquisition dates for the Dataset print ( s1 . dates ) # access the actual ee.ImageCollection object ee_collection = s1 . collection The hydrafloods.Dataset object is a wrapper around an ee.ImageCollection by applying the spatial and temporal filtering upon initialization. This provides a quick and consistent access to imagery. The Dataset class also provides utility functionality to make working with and managing multiple image collections less verbose. There are many ways to interface with datasets (i.e. ImageCollections) using hydrafloods , more examples on merging or joining datasets can be found on the Using Dataset class page.","title":"Get a hf.Dataset"},{"location":"getting-started/#image-processing","text":"The main purpose of hydrafloods is to lower the barrier to creating high-quality surface water maps, this requires image processing. Although the Dataset class wraps an Earth Engine image collection we can apply image processing functions using apply_func() by passing a function object. This method wraps a function that accepts an image as the first argument (which most hydrafloods image processing algorithms do) and maps it over the collection. For example, we would like to apply a speckle filter algorithm on SAR imagery. We can easily do this with the following code. # apply a speckle filtering algorithm on SAR imagery # here we will use the Gamma Map filter filtered = s1 . apply_func ( hf . gamma_map ) The previous example is synonymous with using s1.collection = s1.collection.map(hf.gamma_map) which access the image collection, applies the function, and sets the results to the s1.collection property. Although this technically works, using the apply_func() method is advantageous and preferred as it allows us to pass arbitrary keyword parameters to functions which we want to apply. For example, the water mapping algorithms found in hydrafloods.thresholding take many keyword parameters and we can customize function as in the following example. # apply the edge otsu surface water mapping # we apply this on the speckle filtered SAR data water_maps = filtered . apply_func ( hf . edge_otsu , initial_threshold =- 16 , edge_buffer = 300 , scale = 250 ) It should be noted that using the apply_func() method will return a hydrafloods.Dataset where the collection property has the results of the function. One can access the ee.ImageCollection object and reduce to and image using the following code: # reduce the Dataset.collection property to an ee.Image water_img = water_maps . collection . reduce ( \"mode\" ) There are a variety of image processing functions available in hydrafloods , more information on specific algorithms can be found on the Algorithms page.","title":"Image processing"},{"location":"getting-started/#time-series-processing","text":"In addition to image processing, processing data in time is valuable. Therefore, hydrafloods has a specific module for time series processing, hydrafloods.timeseries , specifically for processing stacks of imagery in time. # import in the timeseries module from hydrafloods import timeseries Here we are going to take a longer time series of SAR imagery for 2019 so we have more data for our model: # define start and end times for one year in 2019 start_time = \"2019-01-01\" end_time = \"2020-01-01\" # get the Sentinel 1 collection as a Dataset # using Cambodia still as the region s1 = hf . Sentinel1 ( region , start_time , end_time ) Now that we have our time series of data, we can begin to model some temporal information. For example, we want to model a harmonic trend of SAR imagery to predict an image using time information. # fit a harmonic trend model on the VV band in time # use two harmonic cycles harmonics_weights = timeseries . fit_harmonic_trend ( s1 , dependent = 'VV' , n_cycles = 2 ) The result from fit_harmonic_trend() will be an image with many bands. Some bands are the coefficeint weights for prediction, others can be awareness information (like number of valid observations used). So we will filter out the bands we need which start with either \"c\", \"t\", or \"s\". Then get a dummy image with time information and apply the prediction. # extract bands needed for prediction harmonic_weights = harmonics . select ( \"^(c|t|s).*\" ) # get a dummy image with just time information for prediction # for flooding date in Oct 2019 dummy_img = timeseries . get_dummy_img ( \"2019-10-05\" ) # predict the VV values using the dummy img and computed harmonic coeffients prediction = ( timeseries . add_harmonic_coefs ( dummy_img ) . multiply ( harmonic_weights ) . reduce ( \"sum\" ) ) Time series functionality in hydrafloods is focused around modeling data in time, more information on the functions can be found in the timeseries module API reference","title":"Time series processing"},{"location":"getting-started/#machine-learning","text":"hydrafloods also has a specific module for machine learning workflows with Earth Engine, hydrafloods.ml . # import in the ml module from hydrafloods import ml The aim with this module is to make high-quality machine learning workflows easier and less verbose when working with Earth Engine. However, we will will still need to access feature collection information to train models. Here we will define some parameters for an example: # define some parameters for the ml workflow we will use # define feature columns to use for training/prediction feature_names = [ 'VV' , 'VH' , 'ratio' , 'ndpi' ] # get a feature collection for training/testing fc = ( ee . FeatureCollection ( \"projects/servir-ee/assets/sar_wi_samples_20200825104400\" ) . randomColumn ( \"random\" ) ) # split the feature collection into training/testing datasets # good practice to do this training = fc . filter ( ee . Filter . lte ( \"random\" , 0.7 )) testing = fc . filter ( ee . Filter . gt ( \"random\" , 0.7 )) Now that we have our datasets and features defined, we can begin the workflow. Typically with machine learning one would perform a feature scaling to get all features within the same range, this helps with numerical stability, training speed, and model accuracy. This can be quite cumbersome to do efficiently in Earth Engine...however, the ml module allows us to scale and train in one shot. # scale training dataset and train random forest model # note this returns a trained ee.Classifier and dictionary to scale data later rf , scaling_dict = ml . random_forest_ee ( 25 , training , feature_names , 'mndwi' , scaling = \"standard\" , mode = \"regression\" ) This function returns a train random forest ee.Classifier and a ee.Dictionary with per band values needed to scale other feature collections or imagery as seen in the next example. Here we scale the testing dataset using the values from the training dataset and apply the model on the feature collection. # scale the testing dataset using the scaling values from training testing_norm = ml . standard_feature_scaling ( testing , scaling_dict , feature_names ) # apply random forest model on scaled test feature collection dataset y_test = testing_norm . classify ( rf , \"predicted\" ) Majority of the time we would like to apply the predictions on imagery and the ml module has functionality to perfrom the scaling for imagery easily. First we have to add the bands to dataset collection which the Sentinel1 dataset class has a custom method to add the VV/VH ratio and VV-VH normalized difference bands. # add bands for features used in RF model s1_features = s1 . add_fusion_features () # scale the bands using the scaling_dict s1_norm = s1_features . apply_func ( ml . standard_image_scaling , scaling_dict = scaling_dict , ) # apply the prediction on the dataset predicted = s1_norm . apply_func ( lambda x : x . classify ( rf )) Again, most of the functionality around the hydrafloods.ml module is to make end-to-end machine learning work flows more straightforward. Please see the ml module documentation for information on functions.","title":"Machine Learning"},{"location":"installation/","text":"Installation hydrafloods itself is a pure Python package, but its dependencies are not. Furthermore, the package relies on Google Cloud and Google Earth Engine to stage and process data relying on specific software and even more importantly account authentication. There are two ways to install for use, one through a Docker Image and another via a manual installation. Using the Docker Image The easiest way to get up and started using the hydrafloods packages is via a Docker Image. The Docker Image comes with pre-installed software and dependencies so you do not have to deal with mis-matching dependencies or sometimes difficult installations, such as GDAL. To start you will need to have Docker installed on your system and running. You will need to pull the pre-built Docker Image for hydrafloods and start a new Container from the Image using the following command: docker run --interactive --tty \\ --volume ~/<PROJECT-DIR>/:/mnt/ \\ --name hydrafloods_container kmarkert/hydrafloods This command should be a one-time process to download the package and start the Container. Additionally, this command will mount a local directory (i.e. ~/<PROJECT-DIR>/ ) for use within the Docker Container which allows you to edit files locally and use within the container. Be sure to change <PROJECT-DIR> within the command to an exisiting local directory. Now the Docker Container is running for use! Within the Docker Container the hydrafloods package and dependencies are pre-installed so all that is left is to authenticate the cloud APIs then we will be ready to test and start processing. If you have exited the Docker Container and want to start it again, use the following command: docker start -ia hydrafloods_container This command to restart an existing Container is important especially after authenticating the cloud environment so that you do not have to go through the authentication process everytime you run the Docker container. For more information on working with Docker Images/Containers using the CLI see the Docker command line documentation . Manual installation Another convient way to install the package and its dependencies is using anaconda . It is recommend using the community maintained conda-forge channel to handle dependencies. Furthermore, it is good practice to use a virtual environment within conda. To create a new environment, install dependencies, and activate the environment: conda create -n hydra -c conda-forge python = 3 .7 \\ numpy \\ scipy \\ pandas \\ requests \\ yaml \\ xmltodict \\ gdal \\ shapely \\ pyproj \\ netCDF4 \\ xarray \\ scikit-learn \\ pyresample \\ geopandas \\ earthengine-api \\ gcsfs \\ fire -y conda activate hydra Finally, we need to install the hydrafloods package and one last dependency via pip : pip install simplecmr hydrafloods You will now also need to install the Google Cloud SDK to interface to with the Google cloud. Follow the directions provided by the website. Once all of the source code and dependencies has been installed successfully, you will need to authenticate the cloud APIs Cloud authentication After successful installation of the package and dependencies we will need to authenticate our local installation (or within the Docker Container) to interface with Google Cloud and Earth Engine. Running these command will prompt you through the authentication process using a web browser. Warning: Make sure you initialize the earthengine and gcloud APIs with Google accounts that have permissions to read and write to Google Cloud Storage and Google Earth Engine assets. To intialize the Google Cloud environment and authenticate using your credentials, run the following command: gcloud init To authenticate the Earth Engine Python API with your credentials, run the following: earthengine authenticate Now we are ready to test our installation! Testing installation \ud83d\udea7 Coming soon! \ud83d\udea7","title":"Installation"},{"location":"installation/#installation","text":"hydrafloods itself is a pure Python package, but its dependencies are not. Furthermore, the package relies on Google Cloud and Google Earth Engine to stage and process data relying on specific software and even more importantly account authentication. There are two ways to install for use, one through a Docker Image and another via a manual installation.","title":"Installation"},{"location":"installation/#using-the-docker-image","text":"The easiest way to get up and started using the hydrafloods packages is via a Docker Image. The Docker Image comes with pre-installed software and dependencies so you do not have to deal with mis-matching dependencies or sometimes difficult installations, such as GDAL. To start you will need to have Docker installed on your system and running. You will need to pull the pre-built Docker Image for hydrafloods and start a new Container from the Image using the following command: docker run --interactive --tty \\ --volume ~/<PROJECT-DIR>/:/mnt/ \\ --name hydrafloods_container kmarkert/hydrafloods This command should be a one-time process to download the package and start the Container. Additionally, this command will mount a local directory (i.e. ~/<PROJECT-DIR>/ ) for use within the Docker Container which allows you to edit files locally and use within the container. Be sure to change <PROJECT-DIR> within the command to an exisiting local directory. Now the Docker Container is running for use! Within the Docker Container the hydrafloods package and dependencies are pre-installed so all that is left is to authenticate the cloud APIs then we will be ready to test and start processing. If you have exited the Docker Container and want to start it again, use the following command: docker start -ia hydrafloods_container This command to restart an existing Container is important especially after authenticating the cloud environment so that you do not have to go through the authentication process everytime you run the Docker container. For more information on working with Docker Images/Containers using the CLI see the Docker command line documentation .","title":"Using the Docker Image"},{"location":"installation/#manual-installation","text":"Another convient way to install the package and its dependencies is using anaconda . It is recommend using the community maintained conda-forge channel to handle dependencies. Furthermore, it is good practice to use a virtual environment within conda. To create a new environment, install dependencies, and activate the environment: conda create -n hydra -c conda-forge python = 3 .7 \\ numpy \\ scipy \\ pandas \\ requests \\ yaml \\ xmltodict \\ gdal \\ shapely \\ pyproj \\ netCDF4 \\ xarray \\ scikit-learn \\ pyresample \\ geopandas \\ earthengine-api \\ gcsfs \\ fire -y conda activate hydra Finally, we need to install the hydrafloods package and one last dependency via pip : pip install simplecmr hydrafloods You will now also need to install the Google Cloud SDK to interface to with the Google cloud. Follow the directions provided by the website. Once all of the source code and dependencies has been installed successfully, you will need to authenticate the cloud APIs","title":"Manual installation"},{"location":"installation/#cloud-authentication","text":"After successful installation of the package and dependencies we will need to authenticate our local installation (or within the Docker Container) to interface with Google Cloud and Earth Engine. Running these command will prompt you through the authentication process using a web browser. Warning: Make sure you initialize the earthengine and gcloud APIs with Google accounts that have permissions to read and write to Google Cloud Storage and Google Earth Engine assets. To intialize the Google Cloud environment and authenticate using your credentials, run the following command: gcloud init To authenticate the Earth Engine Python API with your credentials, run the following: earthengine authenticate Now we are ready to test our installation!","title":"Cloud authentication"},{"location":"installation/#testing-installation","text":"\ud83d\udea7 Coming soon! \ud83d\udea7","title":"Testing installation"},{"location":"ml/","text":"hydrafloods.ml minmax_feature_scaling ( fc , scaling_dict , feature_names ) Function to apply min/max scaling to feature collection Parameters: Name Type Description Default fc ee.FeatureCollection feature collection to scale required scaling_dict ee.Dictionary dictionary of min/max values to scale to required feature_names list[str] names of feature columns to calculate apply scaling to required Returns: Type Description ee.FeatureCollection scaled feature collection Source code in hydrafloods/ml.py def minmax_feature_scaling ( fc , scaling_dict , feature_names ): \"\"\"Function to apply min/max scaling to feature collection args: fc (ee.FeatureCollection): feature collection to scale scaling_dict (ee.Dictionary): dictionary of min/max values to scale to feature_names (list[str]): names of feature columns to calculate apply scaling to returns: ee.FeatureCollection: scaled feature collection \"\"\" def feature_scaling ( feature ): \"\"\"Nested closure function to apply scaling on each column in each feature \"\"\" def iter_cols ( i ): \"\"\"Loops through feature columns \"\"\" i = ee . String ( i ) v = ee . Number ( feature . get ( i )) minv = ee . Number ( scaling_dict . get ( i . cat ( \"_min\" ))) maxv = ee . Number ( scaling_dict . get ( i . cat ( \"_max\" ))) return v . subtract ( minv ) . divide ( maxv . subtract ( minv )) # apply scaling on each column of feature scaled = ee_feature_names . map ( iter_cols ) # get a dictionary of new values with old feature names newVals = ee . Dictionary . fromLists ( ee_feature_names , scaled ) # set feature columns new values return feature . set ( newVals ) # force ee types fc = ee . FeatureCollection ( fc ) ee_feature_names = ee . List ( feature_names ) # normalize the features in the entire featureCollection fc_norm = fc . map ( feature_scaling ) return fc_norm minmax_image_scaling ( image , scaling_dict , feature_names ) Function to scale image between min/max values Expects that scaling_dict keys match bands Parameters: Name Type Description Default image ee.Image image to scale required scaling_dict ee.Dictionary dictionary of min/max values to scale to required returns ee.Image: scaled image Source code in hydrafloods/ml.py @decorators . carry_metadata def minmax_image_scaling ( image , scaling_dict , feature_names ): \"\"\"Function to scale image between min/max values Expects that scaling_dict keys match bands args: image (ee.Image): image to scale scaling_dict (ee.Dictionary): dictionary of min/max values to scale to returns ee.Image: scaled image \"\"\" # get dict as image scaling_img = scaling_dict . toImage () # extract the min/max values per band min_img = scaling_img . select ( \".*_min\" ) max_img = scaling_img . select ( \".*_max\" ) # apply scaling return ( image . select ( sorted ( feature_names )) . subtract ( min_img ) . divide ( max_img . subtract ( min_img )) . float () ) minmax_scaling_dict ( fc , feature_names ) Function to calculate the minimum and maximum values of feautures in a collection Expects that fc has all feature names Parameters: Name Type Description Default fc ee.FeatureCollection feature collection with the features used to calculate min/max value required feature_names list[str] names of feature columns to calculat min/max values from required returns ee.Dictionary: dictionary of minimum and maximum values for each feature name Source code in hydrafloods/ml.py def minmax_scaling_dict ( fc , feature_names ): \"\"\"Function to calculate the minimum and maximum values of feautures in a collection Expects that fc has all feature names args: fc (ee.FeatureCollection): feature collection with the features used to calculate min/max value feature_names (list[str]): names of feature columns to calculat min/max values from returns ee.Dictionary: dictionary of minimum and maximum values for each feature name \"\"\" # force ee types fc = ee . FeatureCollection ( fc ) ee_feature_names = ee . List ( feature_names ) # apply reducer on each feature column feature_min_max = fc . reduceColumns ( ee . Reducer . minMax () . repeat ( ee_feature_names . length ()), ee_feature_names ) # min/max feature names names = ee_feature_names . map ( lambda x : ee . List ([ ee . String ( x ) . cat ( \"_min\" ), ee . String ( x ) . cat ( \"_max\" )]) ) . flatten () # get the min/max values for each feature # used to scale values from 0-1 min_max_dict = ee . Dictionary . fromLists ( names , ee . List ( feature_min_max . get ( \"min\" )) . zip ( feature_min_max . get ( \"max\" )) . flatten (), ) return min_max_dict pca ( image , region = None , scale = 90 , max_pixels = 1000000000.0 ) Principal component analysis decomposition of image bands Parameters: Name Type Description Default image ee.Image image to apply pca to required region ee.Geometry | None region to sample values for covariance matrix, if set to None will use img.geometry(). default = None None scale int scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 90 max_pixels int maximum number of pixels to use in reduction operations. default = 1e9 1000000000.0 Returns: Type Description ee.Image principal components scaled by Source code in hydrafloods/ml.py def pca ( image , region = None , scale = 90 , max_pixels = 1e9 ): \"\"\"Principal component analysis decomposition of image bands args: image (ee.Image): image to apply pca to region (ee.Geometry | None, optional): region to sample values for covariance matrix, if set to `None` will use img.geometry(). default = None scale (int, optional): scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 max_pixels (int, optional): maximum number of pixels to use in reduction operations. default = 1e9 returns: ee.Image: principal components scaled by \"\"\" bandNames = image . bandNames () out_band_names = ee . List . sequence ( 1 , bandNames . length ()) . map ( lambda x : ee . String ( \"pc_\" ) . cat ( ee . Number ( b ) . int ()) ) # Mean center the data to enable a faster covariance reducer # and an SD stretch of the principal components. meanDict = image . reduceRegion ( reducer = ee . Reducer . mean (), geometry = region , scale = scale , maxPixels = max_pixels ) means = ee . Image . constant ( meanDict . values ( bandNames )) centered = image . subtract ( means ) # Collapse the bands of the image into a 1D array per pixel. arrays = centered . toArray () # Compute the covariance of the bands within the region. covar = arrays . reduceRegion ( reducer = ee . Reducer . centeredCovariance (), geometry = region , scale = scale , maxPixels = max_pixels , ) # Get the 'array' covariance result and cast to an array. # This represents the band-to-band covariance within the region. covarArray = ee . Array ( covar . get ( \"array\" )) # Perform an eigen analysis and slice apart the values and vectors. eigens = covarArray . eigen () # This is a P-length vector of Eigenvalues. eigenValues = eigens . slice ( 1 , 0 , 1 ) # This is a PxP matrix with eigenvectors in rows. eigenVectors = eigens . slice ( 1 , 1 ) # Convert the array image to 2D arrays for matrix computations. arrayImage = arrays . toArray ( 1 ) # Left multiply the image array by the matrix of eigenvectors. principalComponents = ee . Image ( eigenVectors ) . matrixMultiply ( arrayImage ) # Turn the square roots of the Eigenvalues into a P-band image. sdImage = ( ee . Image ( eigenValues . sqrt ()) . arrayProject ([ 0 ]) . arrayFlatten ([ out_band_names ]) ) # Turn the PCs into a P-band image, normalized by SD. return ( principalComponents # Throw out an an unneeded dimension, [[]] -> []. . arrayProject ([ 0 ]) # Make the one band array image a multi-band image, [] -> image. . arrayFlatten ([ out_band_names ]) # Normalize the PCs by their SDs. . divide ( sdImage ) ) random_forest_ee ( n_trees , feature_collection , feature_names , label , scaling = None , mode = 'classification' ) Helper function to scale feature collection and train random forest model Parameters: Name Type Description Default n_trees int number of trees for random forest model required feature_collection ee.FeatureCollection features to train random forest model required feature_names list[str] names of feature columns to use in random forest model (x values) required label str name of feature column to fit random forest model (y value) required scaling str | None name of scaling to apply before training. One of: \"minmax\", \"standard\", None . default = None None mode str The output mode of the random forest model. One of: \"classification\", \"regression\", \"probability\". default = \"classification\" 'classification' Source code in hydrafloods/ml.py def random_forest_ee ( n_trees , feature_collection , feature_names , label , scaling = None , mode = \"classification\" , ): \"\"\"Helper function to scale feature collection and train random forest model args: n_trees (int): number of trees for random forest model feature_collection (ee.FeatureCollection): features to train random forest model feature_names (list[str]): names of feature columns to use in random forest model (x values) label (str): name of feature column to fit random forest model (y value) scaling (str | None, optional): name of scaling to apply before training. One of: \"minmax\", \"standard\", `None`. default = `None` mode (str, optional): The output mode of the random forest model. One of: \"classification\", \"regression\", \"probability\". default = \"classification\" \"\"\" if scaling == \"minmax\" : scaling_dict = minmax_scaling_dict ( feature_collection , feature_names ) fc_norm = minmax_feature_scaling ( feature_collection , scaling_dict , feature_names ) elif scaling == \"standard\" : scaling_dict = standard_scaling_dict ( feature_collection , feature_names ) fc_norm = standard_feature_scaling ( feature_collection , scaling_dict , feature_names ) elif scaling is None : scaling_dict = None fc_norm = feature_collection else : raise ValueError ( \"Could not determine scaling option. Options are ['minmax', 'standar', or None]\" ) classifier = ( ee . Classifier . smileRandomForest ( n_trees ) . setOutputMode ( mode . upper ()) . train ( fc_norm , label , feature_names ) ) return classifier , scaling_dict standard_feature_scaling ( fc , scaling_dict , feature_names ) Function to apply standard (Z-score) scaling to feature collection Parameters: Name Type Description Default fc ee.FeatureCollection feature collection to scale required scaling_dict ee.Dictionary dictionary of mean/std dev values for scaling required feature_names list[str] names of feature columns to calculate apply scaling to required Returns: Type Description ee.FeatureCollection scaled feature collection Source code in hydrafloods/ml.py def standard_feature_scaling ( fc , scaling_dict , feature_names ): \"\"\"Function to apply standard (Z-score) scaling to feature collection args: fc (ee.FeatureCollection): feature collection to scale scaling_dict (ee.Dictionary): dictionary of mean/std dev values for scaling feature_names (list[str]): names of feature columns to calculate apply scaling to returns: ee.FeatureCollection: scaled feature collection \"\"\" def feature_scaling ( feature ): \"\"\"Nested closure function to apply scaling on each column in each feature \"\"\" def iter_cols ( i ): \"\"\"Loops through feature columns \"\"\" i = ee . String ( i ) v = ee . Number ( feature . get ( i )) mean = ee . Number ( scaling_dict . get ( i . cat ( \"_mean\" ))) stddev = ee . Number ( scaling_dict . get ( i . cat ( \"_stdDev\" ))) return v . subtract ( mean ) . divide ( stddev ) # apply scaling on each column of feature scaled = ee_feature_names . map ( iter_cols ) # get a dictionary of new values with old feature names newVals = ee . Dictionary . fromLists ( ee_feature_names , scaled ) # set feature columns new values return feature . set ( newVals ) # force ee types fc = ee . FeatureCollection ( fc ) ee_feature_names = ee . List ( feature_names ) # normalize the features in the entire featureCollection fc_norm = fc . map ( feature_scaling ) return fc_norm standard_image_scaling ( image , scaling_dict , feature_names ) Function to apply z-score scaling to image Expects that scaling_dict keys match bands Parameters: Name Type Description Default image ee.Image image to scale required scaling_dict ee.Dictionary dictionary of mean/std dev values to scale to required returns ee.Image: scaled image Source code in hydrafloods/ml.py @decorators . carry_metadata def standard_image_scaling ( image , scaling_dict , feature_names ): \"\"\"Function to apply z-score scaling to image Expects that scaling_dict keys match bands args: image (ee.Image): image to scale scaling_dict (ee.Dictionary): dictionary of mean/std dev values to scale to returns ee.Image: scaled image \"\"\" # get dict as image scaling_img = scaling_dict . toImage () # extract the min/max values per band mean_img = scaling_img . select ( \".*_mean\" ) stddev_img = scaling_img . select ( \".*_stdDev\" ) # apply scaling return ( image . select ( sorted ( feature_names )) . subtract ( mean_img ) . divide ( stddev_img ) . float () ) standard_scaling_dict ( fc , feature_names ) Function to calculate the mean and standard deviation values of feautures in a collection Expects that fc has all feature names Parameters: Name Type Description Default fc ee.FeatureCollection feature collection with the features used to calculate mean/std dev value required feature_names list[str] names of feature columns to calculat mean/std dev values from required returns ee.Dictionary: dictionary of mean and standard deviation values for each feature name Source code in hydrafloods/ml.py def standard_scaling_dict ( fc , feature_names ): \"\"\"Function to calculate the mean and standard deviation values of feautures in a collection Expects that fc has all feature names args: fc (ee.FeatureCollection): feature collection with the features used to calculate mean/std dev value feature_names (list[str]): names of feature columns to calculat mean/std dev values from returns ee.Dictionary: dictionary of mean and standard deviation values for each feature name \"\"\" # force ee types fc = ee . FeatureCollection ( fc ) ee_feature_names = ee . List ( feature_names ) # get a combined reducer for caluclating mean and standard dev mean_stddev = ee . Reducer . mean () . combine ( ee . Reducer . stdDev (), None , True ) # apply reducer on each feature column feature_mean_stddev = fc . reduceColumns ( mean_stddev . repeat ( ee_feature_names . length ()), ee_feature_names ) # mean / std dev feature names names = ee_feature_names . map ( lambda x : ee . List ([ ee . String ( x ) . cat ( \"_mean\" ), ee . String ( x ) . cat ( \"_stdDev\" )]) ) . flatten () # get the mean / std dev values for each feature # used to scale values from ~ -3 to 3 mean_stddev_dict = ee . Dictionary . fromLists ( names , ee . List ( feature_mean_stddev . get ( \"mean\" )) . zip ( feature_mean_stddev . get ( \"stdDev\" )) . flatten (), ) return mean_stddev_dict","title":"ml module"},{"location":"ml/#hydrafloods.ml","text":"","title":"ml"},{"location":"ml/#hydrafloods.ml.minmax_feature_scaling","text":"Function to apply min/max scaling to feature collection Parameters: Name Type Description Default fc ee.FeatureCollection feature collection to scale required scaling_dict ee.Dictionary dictionary of min/max values to scale to required feature_names list[str] names of feature columns to calculate apply scaling to required Returns: Type Description ee.FeatureCollection scaled feature collection Source code in hydrafloods/ml.py def minmax_feature_scaling ( fc , scaling_dict , feature_names ): \"\"\"Function to apply min/max scaling to feature collection args: fc (ee.FeatureCollection): feature collection to scale scaling_dict (ee.Dictionary): dictionary of min/max values to scale to feature_names (list[str]): names of feature columns to calculate apply scaling to returns: ee.FeatureCollection: scaled feature collection \"\"\" def feature_scaling ( feature ): \"\"\"Nested closure function to apply scaling on each column in each feature \"\"\" def iter_cols ( i ): \"\"\"Loops through feature columns \"\"\" i = ee . String ( i ) v = ee . Number ( feature . get ( i )) minv = ee . Number ( scaling_dict . get ( i . cat ( \"_min\" ))) maxv = ee . Number ( scaling_dict . get ( i . cat ( \"_max\" ))) return v . subtract ( minv ) . divide ( maxv . subtract ( minv )) # apply scaling on each column of feature scaled = ee_feature_names . map ( iter_cols ) # get a dictionary of new values with old feature names newVals = ee . Dictionary . fromLists ( ee_feature_names , scaled ) # set feature columns new values return feature . set ( newVals ) # force ee types fc = ee . FeatureCollection ( fc ) ee_feature_names = ee . List ( feature_names ) # normalize the features in the entire featureCollection fc_norm = fc . map ( feature_scaling ) return fc_norm","title":"minmax_feature_scaling()"},{"location":"ml/#hydrafloods.ml.minmax_image_scaling","text":"Function to scale image between min/max values Expects that scaling_dict keys match bands Parameters: Name Type Description Default image ee.Image image to scale required scaling_dict ee.Dictionary dictionary of min/max values to scale to required returns ee.Image: scaled image Source code in hydrafloods/ml.py @decorators . carry_metadata def minmax_image_scaling ( image , scaling_dict , feature_names ): \"\"\"Function to scale image between min/max values Expects that scaling_dict keys match bands args: image (ee.Image): image to scale scaling_dict (ee.Dictionary): dictionary of min/max values to scale to returns ee.Image: scaled image \"\"\" # get dict as image scaling_img = scaling_dict . toImage () # extract the min/max values per band min_img = scaling_img . select ( \".*_min\" ) max_img = scaling_img . select ( \".*_max\" ) # apply scaling return ( image . select ( sorted ( feature_names )) . subtract ( min_img ) . divide ( max_img . subtract ( min_img )) . float () )","title":"minmax_image_scaling()"},{"location":"ml/#hydrafloods.ml.minmax_scaling_dict","text":"Function to calculate the minimum and maximum values of feautures in a collection Expects that fc has all feature names Parameters: Name Type Description Default fc ee.FeatureCollection feature collection with the features used to calculate min/max value required feature_names list[str] names of feature columns to calculat min/max values from required returns ee.Dictionary: dictionary of minimum and maximum values for each feature name Source code in hydrafloods/ml.py def minmax_scaling_dict ( fc , feature_names ): \"\"\"Function to calculate the minimum and maximum values of feautures in a collection Expects that fc has all feature names args: fc (ee.FeatureCollection): feature collection with the features used to calculate min/max value feature_names (list[str]): names of feature columns to calculat min/max values from returns ee.Dictionary: dictionary of minimum and maximum values for each feature name \"\"\" # force ee types fc = ee . FeatureCollection ( fc ) ee_feature_names = ee . List ( feature_names ) # apply reducer on each feature column feature_min_max = fc . reduceColumns ( ee . Reducer . minMax () . repeat ( ee_feature_names . length ()), ee_feature_names ) # min/max feature names names = ee_feature_names . map ( lambda x : ee . List ([ ee . String ( x ) . cat ( \"_min\" ), ee . String ( x ) . cat ( \"_max\" )]) ) . flatten () # get the min/max values for each feature # used to scale values from 0-1 min_max_dict = ee . Dictionary . fromLists ( names , ee . List ( feature_min_max . get ( \"min\" )) . zip ( feature_min_max . get ( \"max\" )) . flatten (), ) return min_max_dict","title":"minmax_scaling_dict()"},{"location":"ml/#hydrafloods.ml.pca","text":"Principal component analysis decomposition of image bands Parameters: Name Type Description Default image ee.Image image to apply pca to required region ee.Geometry | None region to sample values for covariance matrix, if set to None will use img.geometry(). default = None None scale int scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 90 max_pixels int maximum number of pixels to use in reduction operations. default = 1e9 1000000000.0 Returns: Type Description ee.Image principal components scaled by Source code in hydrafloods/ml.py def pca ( image , region = None , scale = 90 , max_pixels = 1e9 ): \"\"\"Principal component analysis decomposition of image bands args: image (ee.Image): image to apply pca to region (ee.Geometry | None, optional): region to sample values for covariance matrix, if set to `None` will use img.geometry(). default = None scale (int, optional): scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 max_pixels (int, optional): maximum number of pixels to use in reduction operations. default = 1e9 returns: ee.Image: principal components scaled by \"\"\" bandNames = image . bandNames () out_band_names = ee . List . sequence ( 1 , bandNames . length ()) . map ( lambda x : ee . String ( \"pc_\" ) . cat ( ee . Number ( b ) . int ()) ) # Mean center the data to enable a faster covariance reducer # and an SD stretch of the principal components. meanDict = image . reduceRegion ( reducer = ee . Reducer . mean (), geometry = region , scale = scale , maxPixels = max_pixels ) means = ee . Image . constant ( meanDict . values ( bandNames )) centered = image . subtract ( means ) # Collapse the bands of the image into a 1D array per pixel. arrays = centered . toArray () # Compute the covariance of the bands within the region. covar = arrays . reduceRegion ( reducer = ee . Reducer . centeredCovariance (), geometry = region , scale = scale , maxPixels = max_pixels , ) # Get the 'array' covariance result and cast to an array. # This represents the band-to-band covariance within the region. covarArray = ee . Array ( covar . get ( \"array\" )) # Perform an eigen analysis and slice apart the values and vectors. eigens = covarArray . eigen () # This is a P-length vector of Eigenvalues. eigenValues = eigens . slice ( 1 , 0 , 1 ) # This is a PxP matrix with eigenvectors in rows. eigenVectors = eigens . slice ( 1 , 1 ) # Convert the array image to 2D arrays for matrix computations. arrayImage = arrays . toArray ( 1 ) # Left multiply the image array by the matrix of eigenvectors. principalComponents = ee . Image ( eigenVectors ) . matrixMultiply ( arrayImage ) # Turn the square roots of the Eigenvalues into a P-band image. sdImage = ( ee . Image ( eigenValues . sqrt ()) . arrayProject ([ 0 ]) . arrayFlatten ([ out_band_names ]) ) # Turn the PCs into a P-band image, normalized by SD. return ( principalComponents # Throw out an an unneeded dimension, [[]] -> []. . arrayProject ([ 0 ]) # Make the one band array image a multi-band image, [] -> image. . arrayFlatten ([ out_band_names ]) # Normalize the PCs by their SDs. . divide ( sdImage ) )","title":"pca()"},{"location":"ml/#hydrafloods.ml.random_forest_ee","text":"Helper function to scale feature collection and train random forest model Parameters: Name Type Description Default n_trees int number of trees for random forest model required feature_collection ee.FeatureCollection features to train random forest model required feature_names list[str] names of feature columns to use in random forest model (x values) required label str name of feature column to fit random forest model (y value) required scaling str | None name of scaling to apply before training. One of: \"minmax\", \"standard\", None . default = None None mode str The output mode of the random forest model. One of: \"classification\", \"regression\", \"probability\". default = \"classification\" 'classification' Source code in hydrafloods/ml.py def random_forest_ee ( n_trees , feature_collection , feature_names , label , scaling = None , mode = \"classification\" , ): \"\"\"Helper function to scale feature collection and train random forest model args: n_trees (int): number of trees for random forest model feature_collection (ee.FeatureCollection): features to train random forest model feature_names (list[str]): names of feature columns to use in random forest model (x values) label (str): name of feature column to fit random forest model (y value) scaling (str | None, optional): name of scaling to apply before training. One of: \"minmax\", \"standard\", `None`. default = `None` mode (str, optional): The output mode of the random forest model. One of: \"classification\", \"regression\", \"probability\". default = \"classification\" \"\"\" if scaling == \"minmax\" : scaling_dict = minmax_scaling_dict ( feature_collection , feature_names ) fc_norm = minmax_feature_scaling ( feature_collection , scaling_dict , feature_names ) elif scaling == \"standard\" : scaling_dict = standard_scaling_dict ( feature_collection , feature_names ) fc_norm = standard_feature_scaling ( feature_collection , scaling_dict , feature_names ) elif scaling is None : scaling_dict = None fc_norm = feature_collection else : raise ValueError ( \"Could not determine scaling option. Options are ['minmax', 'standar', or None]\" ) classifier = ( ee . Classifier . smileRandomForest ( n_trees ) . setOutputMode ( mode . upper ()) . train ( fc_norm , label , feature_names ) ) return classifier , scaling_dict","title":"random_forest_ee()"},{"location":"ml/#hydrafloods.ml.standard_feature_scaling","text":"Function to apply standard (Z-score) scaling to feature collection Parameters: Name Type Description Default fc ee.FeatureCollection feature collection to scale required scaling_dict ee.Dictionary dictionary of mean/std dev values for scaling required feature_names list[str] names of feature columns to calculate apply scaling to required Returns: Type Description ee.FeatureCollection scaled feature collection Source code in hydrafloods/ml.py def standard_feature_scaling ( fc , scaling_dict , feature_names ): \"\"\"Function to apply standard (Z-score) scaling to feature collection args: fc (ee.FeatureCollection): feature collection to scale scaling_dict (ee.Dictionary): dictionary of mean/std dev values for scaling feature_names (list[str]): names of feature columns to calculate apply scaling to returns: ee.FeatureCollection: scaled feature collection \"\"\" def feature_scaling ( feature ): \"\"\"Nested closure function to apply scaling on each column in each feature \"\"\" def iter_cols ( i ): \"\"\"Loops through feature columns \"\"\" i = ee . String ( i ) v = ee . Number ( feature . get ( i )) mean = ee . Number ( scaling_dict . get ( i . cat ( \"_mean\" ))) stddev = ee . Number ( scaling_dict . get ( i . cat ( \"_stdDev\" ))) return v . subtract ( mean ) . divide ( stddev ) # apply scaling on each column of feature scaled = ee_feature_names . map ( iter_cols ) # get a dictionary of new values with old feature names newVals = ee . Dictionary . fromLists ( ee_feature_names , scaled ) # set feature columns new values return feature . set ( newVals ) # force ee types fc = ee . FeatureCollection ( fc ) ee_feature_names = ee . List ( feature_names ) # normalize the features in the entire featureCollection fc_norm = fc . map ( feature_scaling ) return fc_norm","title":"standard_feature_scaling()"},{"location":"ml/#hydrafloods.ml.standard_image_scaling","text":"Function to apply z-score scaling to image Expects that scaling_dict keys match bands Parameters: Name Type Description Default image ee.Image image to scale required scaling_dict ee.Dictionary dictionary of mean/std dev values to scale to required returns ee.Image: scaled image Source code in hydrafloods/ml.py @decorators . carry_metadata def standard_image_scaling ( image , scaling_dict , feature_names ): \"\"\"Function to apply z-score scaling to image Expects that scaling_dict keys match bands args: image (ee.Image): image to scale scaling_dict (ee.Dictionary): dictionary of mean/std dev values to scale to returns ee.Image: scaled image \"\"\" # get dict as image scaling_img = scaling_dict . toImage () # extract the min/max values per band mean_img = scaling_img . select ( \".*_mean\" ) stddev_img = scaling_img . select ( \".*_stdDev\" ) # apply scaling return ( image . select ( sorted ( feature_names )) . subtract ( mean_img ) . divide ( stddev_img ) . float () )","title":"standard_image_scaling()"},{"location":"ml/#hydrafloods.ml.standard_scaling_dict","text":"Function to calculate the mean and standard deviation values of feautures in a collection Expects that fc has all feature names Parameters: Name Type Description Default fc ee.FeatureCollection feature collection with the features used to calculate mean/std dev value required feature_names list[str] names of feature columns to calculat mean/std dev values from required returns ee.Dictionary: dictionary of mean and standard deviation values for each feature name Source code in hydrafloods/ml.py def standard_scaling_dict ( fc , feature_names ): \"\"\"Function to calculate the mean and standard deviation values of feautures in a collection Expects that fc has all feature names args: fc (ee.FeatureCollection): feature collection with the features used to calculate mean/std dev value feature_names (list[str]): names of feature columns to calculat mean/std dev values from returns ee.Dictionary: dictionary of mean and standard deviation values for each feature name \"\"\" # force ee types fc = ee . FeatureCollection ( fc ) ee_feature_names = ee . List ( feature_names ) # get a combined reducer for caluclating mean and standard dev mean_stddev = ee . Reducer . mean () . combine ( ee . Reducer . stdDev (), None , True ) # apply reducer on each feature column feature_mean_stddev = fc . reduceColumns ( mean_stddev . repeat ( ee_feature_names . length ()), ee_feature_names ) # mean / std dev feature names names = ee_feature_names . map ( lambda x : ee . List ([ ee . String ( x ) . cat ( \"_mean\" ), ee . String ( x ) . cat ( \"_stdDev\" )]) ) . flatten () # get the mean / std dev values for each feature # used to scale values from ~ -3 to 3 mean_stddev_dict = ee . Dictionary . fromLists ( names , ee . List ( feature_mean_stddev . get ( \"mean\" )) . zip ( feature_mean_stddev . get ( \"stdDev\" )) . flatten (), ) return mean_stddev_dict","title":"standard_scaling_dict()"},{"location":"thresholding/","text":"hydrafloods.thresholding bmax_otsu ( img , band = None , region = None , scale = 90 , initial_threshold = 0 , invert = False , grid_size = 0.1 , bmax_threshold = 0.75 , max_boxes = 100 , seed = 7 , max_buckets = 255 , min_bucket_width = 0.001 , max_raw = 1000000.0 , return_threshold = False ) Implementation of the B-Max Otsu thresholding algorithm. Detailed explanation of algorithm can be found at https://doi.org/10.3390/rs12152469 Parameters: Name Type Description Default img ee.Image input image to thresholding algorithm required band str | None,optional band name to use for thresholding, if set to None will use first band in image. default = None None region ee.Geometry | None region to determine threshold, if set to None will use img.geometry(). default = None None scale int scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 90 initial_threshold float initial estimate of water/no-water for estimating the probabilities of classes in segment. default = 0 0 invert bool boolean switch to determine if to threshold greater than (True) or less than (False). default = False False grid_size float size in decimal degrees to tile image/region to check for bimodality. default = 0.1 0.1 bmax_threshold float value 0-1 to determine if a value of bmax is bimodal or not. default = 0.75 0.75 max_boxes int maximum number of tiles/boxes to use when determining threshold. default = 100 100 seed int random number generator seed for randomly selected max_boxes. default = 7 7 max_buckets int The maximum number of buckets to use when building a histogram; will be rounded up to a power of 2. default = 255 255 min_bucket_width float The minimum histogram bucket width to allow any power of 2. default = 0.001 0.001 max_raw int The number of values to accumulate before building the initial histogram. default = 1e6 1000000.0 return_threshold bool boolean switch, if set to true then function will return threshold number, else thresholded image. default = False False Returns: Type Description ee.Image thresholded image based (if return_threshold==False) or threshold value (if return_threshold==True) based on the threshold determined by the algorithm Source code in hydrafloods/thresholding.py @decorators . carry_metadata def bmax_otsu ( img , band = None , region = None , scale = 90 , initial_threshold = 0 , invert = False , grid_size = 0.1 , bmax_threshold = 0.75 , max_boxes = 100 , seed = 7 , max_buckets = 255 , min_bucket_width = 0.001 , max_raw = 1e6 , return_threshold = False , ): \"\"\"Implementation of the B-Max Otsu thresholding algorithm. Detailed explanation of algorithm can be found at https://doi.org/10.3390/rs12152469 args: img (ee.Image): input image to thresholding algorithm band (str | None,optional): band name to use for thresholding, if set to `None` will use first band in image. default = None region (ee.Geometry | None, optional): region to determine threshold, if set to `None` will use img.geometry(). default = None scale (int, optional): scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 initial_threshold (float, optional): initial estimate of water/no-water for estimating the probabilities of classes in segment. default = 0 invert (bool, optional): boolean switch to determine if to threshold greater than (True) or less than (False). default = False grid_size (float, optional): size in decimal degrees to tile image/region to check for bimodality. default = 0.1 bmax_threshold (float, optional): value 0-1 to determine if a value of bmax is bimodal or not. default = 0.75 max_boxes (int, optional): maximum number of tiles/boxes to use when determining threshold. default = 100 seed (int, optional): random number generator seed for randomly selected max_boxes. default = 7 max_buckets (int, optional): The maximum number of buckets to use when building a histogram; will be rounded up to a power of 2. default = 255 min_bucket_width (float, optional): The minimum histogram bucket width to allow any power of 2. default = 0.001 max_raw (int, optional): The number of values to accumulate before building the initial histogram. default = 1e6 return_threshold (bool, optional): boolean switch, if set to true then function will return threshold number, else thresholded image. default = False returns: ee.Image: thresholded image based (if return_threshold==False) or threshold value (if return_threshold==True) based on the threshold determined by the algorithm \"\"\" def calcBmax ( feature ): \"\"\"Closure function to calculate Bmax for each feature covering image \"\"\" segment = img initial = segment . lt ( initial_threshold ) p1 = ee . Number ( initial . reduceRegion ( reducer = ee . Reducer . mean (), geometry = feature . geometry (), bestEffort = True , scale = scale , ) . get ( histBand ) ) p1 = ee . Number ( ee . Algorithms . If ( p1 , p1 , 0.99 )) p2 = ee . Number ( 1 ) . subtract ( p1 ) m = ( segment . updateMask ( initial ) . rename ( \"m1\" ) . addBands ( segment . updateMask ( initial . Not ()) . rename ( \"m2\" )) ) mReduced = m . reduceRegion ( reducer = ee . Reducer . mean (), geometry = feature . geometry (), bestEffort = True , scale = scale , ) m1 = ee . Number ( mReduced . get ( \"m1\" )) m2 = ee . Number ( mReduced . get ( \"m2\" )) m1 = ee . Number ( ee . Algorithms . If ( m1 , m1 , - 25 )) m2 = ee . Number ( ee . Algorithms . If ( m2 , m2 , 0 )) sigmab = p1 . multiply ( p2 . multiply ( m1 . subtract ( m2 ) . pow ( 2 ))) sigmat = ee . Number ( segment . reduceRegion ( reducer = ee . Reducer . variance (), geometry = feature . geometry (), bestEffort = True , scale = scale , ) . get ( histBand ) ) sigmat = ee . Number ( ee . Algorithms . If ( sigmat , sigmat , 2 )) bmax = sigmab . divide ( sigmat ) return feature . set ({ \"bmax\" : bmax }) if band is None : img = img . select ([ 0 ]) histBand = ee . String ( img . bandNames () . get ( 0 )) else : histBand = ee . String ( band ) img = img . select ( histBand ) if region is None : region = img . geometry () grid = geeutils . tile_region ( region , intersect_geom = region , grid_size = 0.1 ) bmaxes = ( grid . map ( calcBmax ) . filter ( ee . Filter . gt ( \"bmax\" , bmax_threshold )) . randomColumn ( \"random\" , seed ) ) nBoxes = ee . Number ( bmaxes . size ()) randomThresh = ee . Number ( max_boxes ) . divide ( nBoxes ) selection = bmaxes . filter ( ee . Filter . lt ( \"random\" , randomThresh )) histogram = img . reduceRegion ( ee . Reducer . histogram ( max_buckets , min_bucket_width , max_raw ) . combine ( \"mean\" , None , True ) . combine ( \"variance\" , None , True ), selection , scale , bestEffort = True , tileScale = 16 , ) threshold = otsu ( histogram . get ( histBand . cat ( \"_histogram\" ))) if return_threshold is True : return ee . Image ( threshold ) else : water = ee . Image ( ee . Algorithms . If ( invert , img . gt ( threshold ), img . lt ( threshold ))) return water . rename ( \"water\" ) . uint8 () edge_otsu ( img , band = None , region = None , scale = 90 , initial_threshold = 0 , invert = False , canny_threshold = 0.05 , canny_sigma = 0 , canny_lt = 0.05 , connected_pixels = 200 , edge_length = 50 , edge_buffer = 100 , max_buckets = 255 , min_bucket_width = 0.001 , max_raw = 1000000.0 , return_threshold = False ) Implementation of the Edge Otsu thresholding algorithm. Detailed explanation of algorithm can be found at https://doi.org/10.3390/rs12152469 Parameters: Name Type Description Default img ee.Image input image to thresholding algorithm required band str | None,optional band name to use for thresholding, if set to None will use first band in image. default = None None region ee.Geometry | None region to determine threshold, if set to None will use img.geometry(). default = None None scale int scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 90 initial_threshold float initial estimate of water/no-water for estimating the edges. default = 0 0 invert bool boolean switch to determine if to threshold greater than (True) or less than (False). default = False False canny_threshold float threshold for canny edge detection. default = 0.05 0.05 canny_sigma float sigma value for gaussian filter in canny edge detection. default = 0 0 canny_lt float lower threshold for canny detection. default = 0.05 0.05 connected_pixels int maximum size of the neighborhood in pixels to determine if connected. default = 200 200 edge_length int minimum length of edges from canny detection to be considered edge. default = 50 50 edge_buffer int number of pixels to buffer edges on a side for histogram sampling. default = 100 100 max_buckets int The maximum number of buckets to use when building a histogram; will be rounded up to a power of 2. default = 255 255 min_bucket_width float The minimum histogram bucket width to allow any power of 2. default = 0.001 0.001 max_raw int The number of values to accumulate before building the initial histogram. default = 1e6 1000000.0 return_threshold bool boolean switch, if set to true then function will return threshold number, else thresholded image. default = False False Returns: Type Description ee.Image thresholded image based (if return_threshold==False) or threshold value (if return_threshold==True) based on the threshold determined by the algorithm Source code in hydrafloods/thresholding.py @decorators . carry_metadata def edge_otsu ( img , band = None , region = None , scale = 90 , initial_threshold = 0 , invert = False , canny_threshold = 0.05 , canny_sigma = 0 , canny_lt = 0.05 , connected_pixels = 200 , edge_length = 50 , edge_buffer = 100 , max_buckets = 255 , min_bucket_width = 0.001 , max_raw = 1e6 , return_threshold = False , ): \"\"\"Implementation of the Edge Otsu thresholding algorithm. Detailed explanation of algorithm can be found at https://doi.org/10.3390/rs12152469 args: img (ee.Image): input image to thresholding algorithm band (str | None,optional): band name to use for thresholding, if set to `None` will use first band in image. default = None region (ee.Geometry | None, optional): region to determine threshold, if set to `None` will use img.geometry(). default = None scale (int, optional): scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 initial_threshold (float, optional): initial estimate of water/no-water for estimating the edges. default = 0 invert (bool, optional): boolean switch to determine if to threshold greater than (True) or less than (False). default = False canny_threshold (float, optional): threshold for canny edge detection. default = 0.05 canny_sigma (float, optional): sigma value for gaussian filter in canny edge detection. default = 0 canny_lt (float, optional): lower threshold for canny detection. default = 0.05 connected_pixels (int, optional): maximum size of the neighborhood in pixels to determine if connected. default = 200 edge_length (int, optional): minimum length of edges from canny detection to be considered edge. default = 50 edge_buffer (int, optional): number of pixels to buffer edges on a side for histogram sampling. default = 100 max_buckets (int, optional): The maximum number of buckets to use when building a histogram; will be rounded up to a power of 2. default = 255 min_bucket_width (float, optional): The minimum histogram bucket width to allow any power of 2. default = 0.001 max_raw (int, optional): The number of values to accumulate before building the initial histogram. default = 1e6 return_threshold (bool, optional): boolean switch, if set to true then function will return threshold number, else thresholded image. default = False returns: ee.Image: thresholded image based (if return_threshold==False) or threshold value (if return_threshold==True) based on the threshold determined by the algorithm \"\"\" if band is None : img = img . select ([ 0 ]) histBand = ee . String ( img . bandNames () . get ( 0 )) else : histBand = ee . String ( band ) img = img . select ( histBand ) if region is None : region = img . geometry () binary = img . lt ( initial_threshold ) . rename ( \"binary\" ) # get canny edges canny = ee . Algorithms . CannyEdgeDetector ( binary , canny_threshold , canny_sigma ) # process canny edges connected = ( canny . mask ( canny ) . lt ( canny_lt ) . connectedPixelCount ( connected_pixels , True ) ) edges = connected . gte ( edge_length ) edgeBuffer = edges . focal_max ( edge_buffer , \"square\" , \"meters\" ) # mask out areas to get histogram for Otsu histogram_image = img . updateMask ( edgeBuffer ) histogram = histogram_image . reduceRegion ( ee . Reducer . histogram ( max_buckets , min_bucket_width , max_raw ) . combine ( \"mean\" , None , True ) . combine ( \"variance\" , None , True ), region , scale , bestEffort = True , tileScale = 16 , ) threshold = otsu ( histogram . get ( histBand . cat ( \"_histogram\" ))) if return_threshold is True : return threshold else : water = ee . Image ( ee . Algorithms . If ( invert , img . gt ( threshold ), img . lt ( threshold ))) return water . rename ( \"water\" ) . uint8 () kmeans_extent ( img , hand , initial_threshold = 0 , region = None , band = None , scale = 90 ) Water thresholding methodology using image values and HAND. Method taken from https://doi.org/10.1016/j.rse.2020.111732 Parameters: Name Type Description Default img ee.Image input image to thresholding algorithm required hand ee.Image Height Above Nearest Drainage image used as axis in clustering required initial_threshold float initial estimate of water/no-water for stratified sampling. default = 0 0 region ee.Geometry | None region to sample values for KMeans clustering, if set to None will use img.geometry(). default = None None band str | None,optional band name to use for thresholding, if set to None will use first band in image. default = None None scale int scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 90 Returns: Type Description ee.Image clustered image from KMeans clusterer. Classes assumed to be water/no-water Source code in hydrafloods/thresholding.py def kmeans_extent ( img , hand , initial_threshold = 0 , region = None , band = None , scale = 90 ): \"\"\"Water thresholding methodology using image values and HAND. Method taken from https://doi.org/10.1016/j.rse.2020.111732 args: img (ee.Image): input image to thresholding algorithm hand (ee.Image): Height Above Nearest Drainage image used as axis in clustering initial_threshold (float, optional): initial estimate of water/no-water for stratified sampling. default = 0 region (ee.Geometry | None, optional): region to sample values for KMeans clustering, if set to `None` will use img.geometry(). default = None band (str | None,optional): band name to use for thresholding, if set to `None` will use first band in image. default = None scale (int, optional): scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 returns: ee.Image: clustered image from KMeans clusterer. Classes assumed to be water/no-water \"\"\" if region is None : region = img . geometry () if band is None : img = img . select ([ 0 ]) band = ee . String ( img . bandNames () . get ( 0 )) else : img = img . select ( band ) hand_band = ee . String ( hand . bandNames () . get ( 0 )) strata = img . gt ( initial_threshold ) . rename ( \"strata\" ) samples = ee . Image . cat ([ img , hand , strata ]) . stratifiedSample ( numPoints = 50 , classBand = \"strata\" , region = region , scale = scale , classValues = [ 0 , 1 ], classPoints = [ 500 , 500 ], tileScale = 16 , seed = 7 , ) clusterer = ee . Clusterer . wekaKMeans ( 2 , 2 ) . train ( samples , [ band , hand_band ]) water = ee . Image . cat ([ img , hand . unmask ( 0 )]) . cluster ( clusterer ) return water . rename ( \"water\" ) . uint8 () otsu ( histogram ) Otsu's method threhsolding algorithm. Computes single intensity threshold that separate histogram into two classes, foreground and background Parameters: Name Type Description Default histogram ee.Dictionary computed object from ee.Reducer.histogram with keys \"histogram\" and \"bucketMeans\" required Returns: Type Description ee.Number value of maximum inter-class intensity variance based on histogram Source code in hydrafloods/thresholding.py def otsu ( histogram ): \"\"\"Otsu's method threhsolding algorithm. Computes single intensity threshold that separate histogram into two classes, foreground and background args: histogram (ee.Dictionary): computed object from ee.Reducer.histogram with keys \"histogram\" and \"bucketMeans\" returns: ee.Number: value of maximum inter-class intensity variance based on histogram \"\"\" counts = ee . Array ( ee . Dictionary ( histogram ) . get ( \"histogram\" )) means = ee . Array ( ee . Dictionary ( histogram ) . get ( \"bucketMeans\" )) size = means . length () . get ([ 0 ]) total = counts . reduce ( ee . Reducer . sum (), [ 0 ]) . get ([ 0 ]) sums = means . multiply ( counts ) . reduce ( ee . Reducer . sum (), [ 0 ]) . get ([ 0 ]) mean = sums . divide ( total ) indices = ee . List . sequence ( 1 , size ) # Compute between sum of squares, where each mean partitions the data. def bss_function ( i ): aCounts = counts . slice ( 0 , 0 , i ) aCount = aCounts . reduce ( ee . Reducer . sum (), [ 0 ]) . get ([ 0 ]) aMeans = means . slice ( 0 , 0 , i ) aMean = ( aMeans . multiply ( aCounts ) . reduce ( ee . Reducer . sum (), [ 0 ]) . get ([ 0 ]) . divide ( aCount ) ) bCount = total . subtract ( aCount ) bMean = sums . subtract ( aCount . multiply ( aMean )) . divide ( bCount ) return aCount . multiply ( aMean . subtract ( mean ) . pow ( 2 )) . add ( bCount . multiply ( bMean . subtract ( mean ) . pow ( 2 )) ) bss = indices . map ( bss_function ) output = means . sort ( bss ) . get ([ - 1 ]) return ee . Number ( output )","title":"thresholding module"},{"location":"thresholding/#hydrafloods.thresholding","text":"","title":"thresholding"},{"location":"thresholding/#hydrafloods.thresholding.bmax_otsu","text":"Implementation of the B-Max Otsu thresholding algorithm. Detailed explanation of algorithm can be found at https://doi.org/10.3390/rs12152469 Parameters: Name Type Description Default img ee.Image input image to thresholding algorithm required band str | None,optional band name to use for thresholding, if set to None will use first band in image. default = None None region ee.Geometry | None region to determine threshold, if set to None will use img.geometry(). default = None None scale int scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 90 initial_threshold float initial estimate of water/no-water for estimating the probabilities of classes in segment. default = 0 0 invert bool boolean switch to determine if to threshold greater than (True) or less than (False). default = False False grid_size float size in decimal degrees to tile image/region to check for bimodality. default = 0.1 0.1 bmax_threshold float value 0-1 to determine if a value of bmax is bimodal or not. default = 0.75 0.75 max_boxes int maximum number of tiles/boxes to use when determining threshold. default = 100 100 seed int random number generator seed for randomly selected max_boxes. default = 7 7 max_buckets int The maximum number of buckets to use when building a histogram; will be rounded up to a power of 2. default = 255 255 min_bucket_width float The minimum histogram bucket width to allow any power of 2. default = 0.001 0.001 max_raw int The number of values to accumulate before building the initial histogram. default = 1e6 1000000.0 return_threshold bool boolean switch, if set to true then function will return threshold number, else thresholded image. default = False False Returns: Type Description ee.Image thresholded image based (if return_threshold==False) or threshold value (if return_threshold==True) based on the threshold determined by the algorithm Source code in hydrafloods/thresholding.py @decorators . carry_metadata def bmax_otsu ( img , band = None , region = None , scale = 90 , initial_threshold = 0 , invert = False , grid_size = 0.1 , bmax_threshold = 0.75 , max_boxes = 100 , seed = 7 , max_buckets = 255 , min_bucket_width = 0.001 , max_raw = 1e6 , return_threshold = False , ): \"\"\"Implementation of the B-Max Otsu thresholding algorithm. Detailed explanation of algorithm can be found at https://doi.org/10.3390/rs12152469 args: img (ee.Image): input image to thresholding algorithm band (str | None,optional): band name to use for thresholding, if set to `None` will use first band in image. default = None region (ee.Geometry | None, optional): region to determine threshold, if set to `None` will use img.geometry(). default = None scale (int, optional): scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 initial_threshold (float, optional): initial estimate of water/no-water for estimating the probabilities of classes in segment. default = 0 invert (bool, optional): boolean switch to determine if to threshold greater than (True) or less than (False). default = False grid_size (float, optional): size in decimal degrees to tile image/region to check for bimodality. default = 0.1 bmax_threshold (float, optional): value 0-1 to determine if a value of bmax is bimodal or not. default = 0.75 max_boxes (int, optional): maximum number of tiles/boxes to use when determining threshold. default = 100 seed (int, optional): random number generator seed for randomly selected max_boxes. default = 7 max_buckets (int, optional): The maximum number of buckets to use when building a histogram; will be rounded up to a power of 2. default = 255 min_bucket_width (float, optional): The minimum histogram bucket width to allow any power of 2. default = 0.001 max_raw (int, optional): The number of values to accumulate before building the initial histogram. default = 1e6 return_threshold (bool, optional): boolean switch, if set to true then function will return threshold number, else thresholded image. default = False returns: ee.Image: thresholded image based (if return_threshold==False) or threshold value (if return_threshold==True) based on the threshold determined by the algorithm \"\"\" def calcBmax ( feature ): \"\"\"Closure function to calculate Bmax for each feature covering image \"\"\" segment = img initial = segment . lt ( initial_threshold ) p1 = ee . Number ( initial . reduceRegion ( reducer = ee . Reducer . mean (), geometry = feature . geometry (), bestEffort = True , scale = scale , ) . get ( histBand ) ) p1 = ee . Number ( ee . Algorithms . If ( p1 , p1 , 0.99 )) p2 = ee . Number ( 1 ) . subtract ( p1 ) m = ( segment . updateMask ( initial ) . rename ( \"m1\" ) . addBands ( segment . updateMask ( initial . Not ()) . rename ( \"m2\" )) ) mReduced = m . reduceRegion ( reducer = ee . Reducer . mean (), geometry = feature . geometry (), bestEffort = True , scale = scale , ) m1 = ee . Number ( mReduced . get ( \"m1\" )) m2 = ee . Number ( mReduced . get ( \"m2\" )) m1 = ee . Number ( ee . Algorithms . If ( m1 , m1 , - 25 )) m2 = ee . Number ( ee . Algorithms . If ( m2 , m2 , 0 )) sigmab = p1 . multiply ( p2 . multiply ( m1 . subtract ( m2 ) . pow ( 2 ))) sigmat = ee . Number ( segment . reduceRegion ( reducer = ee . Reducer . variance (), geometry = feature . geometry (), bestEffort = True , scale = scale , ) . get ( histBand ) ) sigmat = ee . Number ( ee . Algorithms . If ( sigmat , sigmat , 2 )) bmax = sigmab . divide ( sigmat ) return feature . set ({ \"bmax\" : bmax }) if band is None : img = img . select ([ 0 ]) histBand = ee . String ( img . bandNames () . get ( 0 )) else : histBand = ee . String ( band ) img = img . select ( histBand ) if region is None : region = img . geometry () grid = geeutils . tile_region ( region , intersect_geom = region , grid_size = 0.1 ) bmaxes = ( grid . map ( calcBmax ) . filter ( ee . Filter . gt ( \"bmax\" , bmax_threshold )) . randomColumn ( \"random\" , seed ) ) nBoxes = ee . Number ( bmaxes . size ()) randomThresh = ee . Number ( max_boxes ) . divide ( nBoxes ) selection = bmaxes . filter ( ee . Filter . lt ( \"random\" , randomThresh )) histogram = img . reduceRegion ( ee . Reducer . histogram ( max_buckets , min_bucket_width , max_raw ) . combine ( \"mean\" , None , True ) . combine ( \"variance\" , None , True ), selection , scale , bestEffort = True , tileScale = 16 , ) threshold = otsu ( histogram . get ( histBand . cat ( \"_histogram\" ))) if return_threshold is True : return ee . Image ( threshold ) else : water = ee . Image ( ee . Algorithms . If ( invert , img . gt ( threshold ), img . lt ( threshold ))) return water . rename ( \"water\" ) . uint8 ()","title":"bmax_otsu()"},{"location":"thresholding/#hydrafloods.thresholding.edge_otsu","text":"Implementation of the Edge Otsu thresholding algorithm. Detailed explanation of algorithm can be found at https://doi.org/10.3390/rs12152469 Parameters: Name Type Description Default img ee.Image input image to thresholding algorithm required band str | None,optional band name to use for thresholding, if set to None will use first band in image. default = None None region ee.Geometry | None region to determine threshold, if set to None will use img.geometry(). default = None None scale int scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 90 initial_threshold float initial estimate of water/no-water for estimating the edges. default = 0 0 invert bool boolean switch to determine if to threshold greater than (True) or less than (False). default = False False canny_threshold float threshold for canny edge detection. default = 0.05 0.05 canny_sigma float sigma value for gaussian filter in canny edge detection. default = 0 0 canny_lt float lower threshold for canny detection. default = 0.05 0.05 connected_pixels int maximum size of the neighborhood in pixels to determine if connected. default = 200 200 edge_length int minimum length of edges from canny detection to be considered edge. default = 50 50 edge_buffer int number of pixels to buffer edges on a side for histogram sampling. default = 100 100 max_buckets int The maximum number of buckets to use when building a histogram; will be rounded up to a power of 2. default = 255 255 min_bucket_width float The minimum histogram bucket width to allow any power of 2. default = 0.001 0.001 max_raw int The number of values to accumulate before building the initial histogram. default = 1e6 1000000.0 return_threshold bool boolean switch, if set to true then function will return threshold number, else thresholded image. default = False False Returns: Type Description ee.Image thresholded image based (if return_threshold==False) or threshold value (if return_threshold==True) based on the threshold determined by the algorithm Source code in hydrafloods/thresholding.py @decorators . carry_metadata def edge_otsu ( img , band = None , region = None , scale = 90 , initial_threshold = 0 , invert = False , canny_threshold = 0.05 , canny_sigma = 0 , canny_lt = 0.05 , connected_pixels = 200 , edge_length = 50 , edge_buffer = 100 , max_buckets = 255 , min_bucket_width = 0.001 , max_raw = 1e6 , return_threshold = False , ): \"\"\"Implementation of the Edge Otsu thresholding algorithm. Detailed explanation of algorithm can be found at https://doi.org/10.3390/rs12152469 args: img (ee.Image): input image to thresholding algorithm band (str | None,optional): band name to use for thresholding, if set to `None` will use first band in image. default = None region (ee.Geometry | None, optional): region to determine threshold, if set to `None` will use img.geometry(). default = None scale (int, optional): scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 initial_threshold (float, optional): initial estimate of water/no-water for estimating the edges. default = 0 invert (bool, optional): boolean switch to determine if to threshold greater than (True) or less than (False). default = False canny_threshold (float, optional): threshold for canny edge detection. default = 0.05 canny_sigma (float, optional): sigma value for gaussian filter in canny edge detection. default = 0 canny_lt (float, optional): lower threshold for canny detection. default = 0.05 connected_pixels (int, optional): maximum size of the neighborhood in pixels to determine if connected. default = 200 edge_length (int, optional): minimum length of edges from canny detection to be considered edge. default = 50 edge_buffer (int, optional): number of pixels to buffer edges on a side for histogram sampling. default = 100 max_buckets (int, optional): The maximum number of buckets to use when building a histogram; will be rounded up to a power of 2. default = 255 min_bucket_width (float, optional): The minimum histogram bucket width to allow any power of 2. default = 0.001 max_raw (int, optional): The number of values to accumulate before building the initial histogram. default = 1e6 return_threshold (bool, optional): boolean switch, if set to true then function will return threshold number, else thresholded image. default = False returns: ee.Image: thresholded image based (if return_threshold==False) or threshold value (if return_threshold==True) based on the threshold determined by the algorithm \"\"\" if band is None : img = img . select ([ 0 ]) histBand = ee . String ( img . bandNames () . get ( 0 )) else : histBand = ee . String ( band ) img = img . select ( histBand ) if region is None : region = img . geometry () binary = img . lt ( initial_threshold ) . rename ( \"binary\" ) # get canny edges canny = ee . Algorithms . CannyEdgeDetector ( binary , canny_threshold , canny_sigma ) # process canny edges connected = ( canny . mask ( canny ) . lt ( canny_lt ) . connectedPixelCount ( connected_pixels , True ) ) edges = connected . gte ( edge_length ) edgeBuffer = edges . focal_max ( edge_buffer , \"square\" , \"meters\" ) # mask out areas to get histogram for Otsu histogram_image = img . updateMask ( edgeBuffer ) histogram = histogram_image . reduceRegion ( ee . Reducer . histogram ( max_buckets , min_bucket_width , max_raw ) . combine ( \"mean\" , None , True ) . combine ( \"variance\" , None , True ), region , scale , bestEffort = True , tileScale = 16 , ) threshold = otsu ( histogram . get ( histBand . cat ( \"_histogram\" ))) if return_threshold is True : return threshold else : water = ee . Image ( ee . Algorithms . If ( invert , img . gt ( threshold ), img . lt ( threshold ))) return water . rename ( \"water\" ) . uint8 ()","title":"edge_otsu()"},{"location":"thresholding/#hydrafloods.thresholding.kmeans_extent","text":"Water thresholding methodology using image values and HAND. Method taken from https://doi.org/10.1016/j.rse.2020.111732 Parameters: Name Type Description Default img ee.Image input image to thresholding algorithm required hand ee.Image Height Above Nearest Drainage image used as axis in clustering required initial_threshold float initial estimate of water/no-water for stratified sampling. default = 0 0 region ee.Geometry | None region to sample values for KMeans clustering, if set to None will use img.geometry(). default = None None band str | None,optional band name to use for thresholding, if set to None will use first band in image. default = None None scale int scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 90 Returns: Type Description ee.Image clustered image from KMeans clusterer. Classes assumed to be water/no-water Source code in hydrafloods/thresholding.py def kmeans_extent ( img , hand , initial_threshold = 0 , region = None , band = None , scale = 90 ): \"\"\"Water thresholding methodology using image values and HAND. Method taken from https://doi.org/10.1016/j.rse.2020.111732 args: img (ee.Image): input image to thresholding algorithm hand (ee.Image): Height Above Nearest Drainage image used as axis in clustering initial_threshold (float, optional): initial estimate of water/no-water for stratified sampling. default = 0 region (ee.Geometry | None, optional): region to sample values for KMeans clustering, if set to `None` will use img.geometry(). default = None band (str | None,optional): band name to use for thresholding, if set to `None` will use first band in image. default = None scale (int, optional): scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 returns: ee.Image: clustered image from KMeans clusterer. Classes assumed to be water/no-water \"\"\" if region is None : region = img . geometry () if band is None : img = img . select ([ 0 ]) band = ee . String ( img . bandNames () . get ( 0 )) else : img = img . select ( band ) hand_band = ee . String ( hand . bandNames () . get ( 0 )) strata = img . gt ( initial_threshold ) . rename ( \"strata\" ) samples = ee . Image . cat ([ img , hand , strata ]) . stratifiedSample ( numPoints = 50 , classBand = \"strata\" , region = region , scale = scale , classValues = [ 0 , 1 ], classPoints = [ 500 , 500 ], tileScale = 16 , seed = 7 , ) clusterer = ee . Clusterer . wekaKMeans ( 2 , 2 ) . train ( samples , [ band , hand_band ]) water = ee . Image . cat ([ img , hand . unmask ( 0 )]) . cluster ( clusterer ) return water . rename ( \"water\" ) . uint8 ()","title":"kmeans_extent()"},{"location":"thresholding/#hydrafloods.thresholding.otsu","text":"Otsu's method threhsolding algorithm. Computes single intensity threshold that separate histogram into two classes, foreground and background Parameters: Name Type Description Default histogram ee.Dictionary computed object from ee.Reducer.histogram with keys \"histogram\" and \"bucketMeans\" required Returns: Type Description ee.Number value of maximum inter-class intensity variance based on histogram Source code in hydrafloods/thresholding.py def otsu ( histogram ): \"\"\"Otsu's method threhsolding algorithm. Computes single intensity threshold that separate histogram into two classes, foreground and background args: histogram (ee.Dictionary): computed object from ee.Reducer.histogram with keys \"histogram\" and \"bucketMeans\" returns: ee.Number: value of maximum inter-class intensity variance based on histogram \"\"\" counts = ee . Array ( ee . Dictionary ( histogram ) . get ( \"histogram\" )) means = ee . Array ( ee . Dictionary ( histogram ) . get ( \"bucketMeans\" )) size = means . length () . get ([ 0 ]) total = counts . reduce ( ee . Reducer . sum (), [ 0 ]) . get ([ 0 ]) sums = means . multiply ( counts ) . reduce ( ee . Reducer . sum (), [ 0 ]) . get ([ 0 ]) mean = sums . divide ( total ) indices = ee . List . sequence ( 1 , size ) # Compute between sum of squares, where each mean partitions the data. def bss_function ( i ): aCounts = counts . slice ( 0 , 0 , i ) aCount = aCounts . reduce ( ee . Reducer . sum (), [ 0 ]) . get ([ 0 ]) aMeans = means . slice ( 0 , 0 , i ) aMean = ( aMeans . multiply ( aCounts ) . reduce ( ee . Reducer . sum (), [ 0 ]) . get ([ 0 ]) . divide ( aCount ) ) bCount = total . subtract ( aCount ) bMean = sums . subtract ( aCount . multiply ( aMean )) . divide ( bCount ) return aCount . multiply ( aMean . subtract ( mean ) . pow ( 2 )) . add ( bCount . multiply ( bMean . subtract ( mean ) . pow ( 2 )) ) bss = indices . map ( bss_function ) output = means . sort ( bss ) . get ([ - 1 ]) return ee . Number ( output )","title":"otsu()"},{"location":"timeseries/","text":"hydrafloods.timeseries add_harmonic_coefs ( image , n_cycles = 2 ) Function to add harmonic coefficients as bands to images Harmonic coefficients are calculated as sin and cos of frequency within year Parameters: Name Type Description Default image ee.Image image object to add harmonic coefficiencts to. Expects that image has time band required n_cycles int number of interannual cycles to include. default = 2 2 Returns: Type Description ee.Image image with harmonic coefficient bands added Source code in hydrafloods/timeseries.py def add_harmonic_coefs ( image , n_cycles = 2 ): \"\"\"Function to add harmonic coefficients as bands to images Harmonic coefficients are calculated as sin and cos of frequency within year args: image (ee.Image): image object to add harmonic coefficiencts to. Expects that image has time band n_cycles (int, optional): number of interannual cycles to include. default = 2 returns: ee.Image: image with harmonic coefficient bands added \"\"\" cosNames = _get_names ( \"cos\" , n_cycles ) sinNames = _get_names ( \"sin\" , n_cycles ) frequencyImg = ee . Image . constant ( ee . List . sequence ( 1 , n_cycles )) timeRadians = image . select ( \"time\" ) . multiply ( 2 * math . pi ) cosines = timeRadians . multiply ( frequencyImg ) . cos () . rename ( cosNames ) sines = timeRadians . multiply ( frequencyImg ) . sin () . rename ( sinNames ) return image . addBands ( cosines ) . addBands ( sines ) add_time_band ( img , offset = 'year' , apply_mask = False ) Function to add time band to image. Expects image has system:time_start property. Added band will have name \"time\" Parameters: Name Type Description Default img ee.Image image with system:time_start to add time band too required offset str units to calculate from 1970-01-01. default = \"year\" 'year' apply_mask bool boolean switch to apply image mask to time band. if False, then time band will have full coverage False Returns: Type Description ee.Image image object with time band added Source code in hydrafloods/timeseries.py def add_time_band ( img , offset = \"year\" , apply_mask = False ): \"\"\"Function to add time band to image. Expects image has `system:time_start` property. Added band will have name \"time\" args: img (ee.Image): image with `system:time_start` to add time band too offset (str, optional): units to calculate from 1970-01-01. default = \"year\" apply_mask (bool, optional): boolean switch to apply image mask to time band. if False, then time band will have full coverage returns: ee.Image: image object with time band added \"\"\" t = img . date () tDiff = t . difference ( ee . Date ( \"1970-01-01\" ), offset ) time = ee . Image ( tDiff ) . float () . rename ( \"time\" ) if apply_mask : time = time . updateMask ( img . select ([ 0 ]) . mask ()) return img . addBands ( time ) fit_harmonic_trend ( collection , n_cycles = 2 , independents = [ 'constant' , 'time' ], dependent = None , output_err = False ) Function to fit a harmonic trend on image collection along the time dimension. Uses ee.Reducer.linearRegression to solve for coefficients Parameters: Name Type Description Default collection ee.ImageCollection | hydrafloods.Dataset image collection to fit trend line for required n_cycles int number of interannual cycles to model. default = 2 2 independents list[str] list of band names to use for fitting regression. default = [\"constant\", \"time\"] ['constant', 'time'] dependent str | None band name of values to fit, if None then uses the first band. default = None None output_err bool switch to output regression x and y errors, if true output will have \"mean_x\", \"residual_x\" and \"residual_y\" bands. Useful for estimating confidence intervals. default = False False Returns: Type Description ee.Image output image with regression coeffients as bands named \"constant\", \"time\", \"cos_n\", and \"sin_n\" where n is a sequnces of cycles. Will have \"mean_x\", \"residual_x\" and \"residual_y\" if ouput_err == True Exceptions: Type Description ValueError if collection is not of type ee.ImageCollection or hydrafloods.Dataset Source code in hydrafloods/timeseries.py def fit_harmonic_trend ( collection , n_cycles = 2 , independents = [ \"constant\" , \"time\" ], dependent = None , output_err = False , ): \"\"\"Function to fit a harmonic trend on image collection along the time dimension. Uses ee.Reducer.linearRegression to solve for coefficients args: collection (ee.ImageCollection | hydrafloods.Dataset): image collection to fit trend line for n_cycles (int, optional): number of interannual cycles to model. default = 2 independents (list[str], optional): list of band names to use for fitting regression. default = [\"constant\", \"time\"] dependent (str | None, optional): band name of values to fit, if None then uses the first band. default = None output_err (bool, optional): switch to output regression x and y errors, if true output will have \"mean_x\", \"residual_x\" and \"residual_y\" bands. Useful for estimating confidence intervals. default = False returns: ee.Image: output image with regression coeffients as bands named \"constant\", \"time\", \"cos_n\", and \"sin_n\" where n is a sequnces of cycles. Will have \"mean_x\", \"residual_x\" and \"residual_y\" if ouput_err == True raises: ValueError: if collection is not of type ee.ImageCollection or hydrafloods.Dataset \"\"\" if not isinstance ( collection , ee . ImageCollection ): try : collection = collection . collection except AttributeError : raise ValueError ( \"collection argument expected type ee.ImageCollection or hydrafloods.Dataset,\" + f \"got { type ( collection ) } \" ) if dependent is None : dependent = ee . String ( ee . Image ( collection . first ()) . bandNames () . get ( 0 )) else : dependent = ee . String ( dependent ) independents = ( ee . List ( independents ) . cat ( _get_names ( \"cos\" , n_cycles )) . cat ( _get_names ( \"sin\" , n_cycles )) ) _add_coefs = partial ( add_harmonic_coefs , n_cycles = n_cycles ) harmonic_collection = prep_inputs ( collection , keep_bands = [ dependent ], apply_mask = True ) . map ( _add_coefs ) harmonic_trend = harmonic_collection . select ( independents . add ( dependent )) . reduce ( ee . Reducer . linearRegression ( numX = independents . length (), numY = 1 ), 16 ) n = harmonic_collection . select ( dependent ) . reduce ( ee . Reducer . count (), 16 ) . rename ( \"n\" ) # Turn the array image into a multi-band image of coefficients harmonic_coefficients = ( harmonic_trend . select ( \"coefficients\" ) . arrayProject ([ 0 ]) . arrayFlatten ([ independents ]) ) . addBands ( n ) if output_err : harmonic_mse = ( harmonic_trend . select ( \"residuals\" ) . arrayProject ([ 0 ]) . arrayFlatten ([[ \"residual_y\" ]]) ) t_mean = harmonic_collection . select ( \"time\" ) . reduce ( ee . Reducer . mean (), 16 ) . rename ( \"mean_x\" ) x_err = ( harmonic_collection . select ( \"time\" ) . map ( lambda x : x . subtract ( t_mean ) . pow ( 2 )) . reduce ( ee . Reducer . sum (), 16 ) . rename ( \"residual_x\" ) ) harmonic_coefficients = ee . Image . cat ( [ harmonic_coefficients , harmonic_mse , t_mean , x_err ] ) return harmonic_coefficients fit_linear_trend ( collection , independents = [ 'constant' , 'time' ], dependent = None , regression_method = 'ols' , output_err = False ) Function to fit a linear reducer on image collection along the time dimension. Parameters: Name Type Description Default collection ee.ImageCollection image collection to fit trend line for required independents list[str] list of band names to use for fitting regression. default = [\"constant\", \"time\"] ['constant', 'time'] dependent str | None band name of values to fit, if None then uses the first band. default = None None regression_method str name of regression reducer to use. options are \"simple\", \"ols\", \"robust\", \"ridge\", \"sen\". default = \"ols\" 'ols' output_err bool switch to output regression x and y errors, if true output will have \"mean_x\", \"residual_x\" and \"residual_y\" bands. Useful for estimating confidence intervals. default = False False Returns: Type Description ee.Image output image with regression coeffients as bands named \"offset\" and \"slope\". Will have \"mean_x\", \"residual_x\" and \"residual_y\" if ouput_err == True Source code in hydrafloods/timeseries.py def fit_linear_trend ( collection , independents = [ \"constant\" , \"time\" ], dependent = None , regression_method = \"ols\" , output_err = False , ): \"\"\"Function to fit a linear reducer on image collection along the time dimension. args: collection (ee.ImageCollection): image collection to fit trend line for independents (list[str], optional): list of band names to use for fitting regression. default = [\"constant\", \"time\"] dependent (str | None, optional): band name of values to fit, if None then uses the first band. default = None regression_method (str, optional): name of regression reducer to use. options are \"simple\", \"ols\", \"robust\", \"ridge\", \"sen\". default = \"ols\" output_err (bool, optional): switch to output regression x and y errors, if true output will have \"mean_x\", \"residual_x\" and \"residual_y\" bands. Useful for estimating confidence intervals. default = False returns: ee.Image: output image with regression coeffients as bands named \"offset\" and \"slope\". Will have \"mean_x\", \"residual_x\" and \"residual_y\" if ouput_err == True \"\"\" independents = ee . List ( independents ) if dependent is None : dependent = ee . String ( ee . Image ( collection . first ()) . bandNames () . get ( 0 )) else : dependent = ee . String ( dependent ) methods = [ \"simple\" , \"ols\" , \"robust\" , \"ridge\" , \"sen\" ] reducers = [ ee . Reducer . linearFit (), ee . Reducer . linearRegression ( independents . length (), 1 ), ee . Reducer . robustLinearRegression ( independents . length (), 1 ), ee . Reducer . ridgeRegression ( independents . length (), 1 ), ee . Reducer . sensSlope (), ] method_lookup = { v : reducers [ i ] for i , v in enumerate ( methods )} if regression_method not in methods : raise ValueError () else : lin_reducer = method_lookup [ regression_method ] if not isinstance ( collection , ee . ImageCollection ): collection = collection . collection reduction_coll = prep_inputs ( collection , keep_bands = [ dependent ], apply_mask = True ) . select ( independents . add ( dependent )) n = reduction_coll . select ( dependent ) . reduce ( \"count\" ) . rename ( \"n\" ) if regression_method in [ \"sen\" , \"ridge\" ]: independents = ee . List ([ \"constant\" ]) . cat ( independents ) if regression_method == \"sen\" : lr = reduction_coll . reduce ( lin_reducer , 16 ) . select ( [ \"offset\" , \"slope\" ], independents ) else : lr_arr = reduction_coll . reduce ( lin_reducer , 16 ) lr = ( lr_arr . select ([ \"coefficients\" ]) . arrayProject ([ 0 ]) . arrayFlatten ([ independents ]) ) if output_err and regression_method is not \"sen\" : linear_mse = ( lr_arr . select ( \"residuals\" ) . arrayProject ([ 0 ]) . arrayFlatten ([[ \"residual_y\" ]]) ) t_mean = reduction_coll . select ( \"time\" ) . mean () . rename ( \"mean_x\" ) x_err = ( reduction_coll . select ( \"time\" ) . map ( lambda x : x . subtract ( t_mean ) . pow ( 2 )) . reduce ( ee . Reducer . sum (), 16 ) . rename ( \"residual_x\" ) ) lr = ee . Image . cat ([ lr , linear_mse , t_mean , x_err ]) return lr . addBands ( n ) get_dummy_collection ( start_time , end_time ) Helper function to create image collection of images to apply time series prediction on Creates daily imagery between start_time and end_time Parameters: Name Type Description Default start_time str | ee.Date string or ee.Date string to start creating images on (inclusive) required end_time str | ee.Date string or ee.Date string to end creating images on (exclusive) required Returns: Type Description ee.ImageCollection image collection with image containing time and constant bands Source code in hydrafloods/timeseries.py def get_dummy_collection ( start_time , end_time ): \"\"\"Helper function to create image collection of images to apply time series prediction on Creates daily imagery between start_time and end_time args: start_time (str | ee.Date): string or ee.Date string to start creating images on (inclusive) end_time (str | ee.Date): string or ee.Date string to end creating images on (exclusive) returns: ee.ImageCollection: image collection with image containing time and constant bands \"\"\" def _gen_image ( i ): t = start_time . advance ( ee . Number ( i ), \"day\" ) return ee . Image () . rename ( \"blank\" ) . set ( \"system:time_start\" , t . millis ()) if not isinstance ( start_time , ee . Date ): start_time = ee . Date ( start_time ) if not isinstance ( end_time , ee . Date ): end_time = ee . Date ( end_time ) n = end_time . difference ( start_time , \"day\" ) coll = ee . ImageCollection ( ee . List . sequence ( 0 , n ) . map ( _gen_image )) return prep_inputs ( coll ) get_dummy_img ( t ) Helper function to get an image readily available to use for predictions Resulting image will include time based on year and constant band of 1 Parameters: Name Type Description Default t str | ee.Date string or ee.Date string to create dummy image for required Returns: Type Description ee.Image image object with time and constant bands Source code in hydrafloods/timeseries.py def get_dummy_img ( t ): \"\"\"Helper function to get an image readily available to use for predictions Resulting image will include time based on year and constant band of 1 args: t (str | ee.Date): string or ee.Date string to create dummy image for returns: ee.Image: image object with time and constant bands \"\"\" if not isinstance ( t , ee . Date ): t = ee . Date ( t ) img = ee . Image . constant ( 1 ) . set ( \"system:time_start\" , t . millis ()) time_band = ( ee . Image ( t . difference ( ee . Date ( \"1970-01-01\" ), \"year\" )) . float () . rename ( \"time\" ) ) return img . addBands ( time_band ) predict_harmonics ( collection , harmonics , n_cycles = 2 , independents = [ 'constant' , 'time' ]) Helper function to apply harmonic trend prediction Parameters: Name Type Description Default collection ee.ImageCollection image collection to apply prediction on required harmonics ee.Image harmonic coefficient image with coeffiecient bands required n_cycles int number of interannual cycles to model, note n_cycles must equal the number of cycle coefficients in harmonics . default = 2 2 independents list[str] list of independent band names to use in model. These are other than the harmonic coefficient names. default = [\"constant\", \"time\"] ['constant', 'time'] returns ee.ImageCollection: image collection with predicted values Source code in hydrafloods/timeseries.py def predict_harmonics ( collection , harmonics , n_cycles = 2 , independents = [ \"constant\" , \"time\" ] ): \"\"\"Helper function to apply harmonic trend prediction args: collection (ee.ImageCollection): image collection to apply prediction on harmonics (ee.Image): harmonic coefficient image with coeffiecient bands n_cycles (int, optional): number of interannual cycles to model, note n_cycles must equal the number of cycle coefficients in `harmonics`. default = 2 independents (list[str], optional): list of independent band names to use in model. These are other than the harmonic coefficient names. default = [\"constant\", \"time\"] returns ee.ImageCollection: image collection with predicted values \"\"\" @decorators . carry_metadata def _apply_prediction ( image ): \"\"\"Closure function to apply prediction \"\"\" return ( image . select ( independents ) . multiply ( harmonics ) . reduce ( \"sum\" ) . rename ( \"predicted\" ) ) independents = ( ee . List ( independents ) . cat ( _get_names ( \"cos\" , n_cycles )) . cat ( _get_names ( \"sin\" , n_cycles )) ) _add_coefs = partial ( add_harmonic_coefs , n_cycles = n_cycles ) harmonic_collection = prep_inputs ( collection ) . map ( _add_coefs ) # Compute fitted values. predicted = harmonic_collection . map ( _apply_prediction ) return predicted prep_inputs ( collection , keep_bands = None , apply_mask = False ) Helper function to prepare inputs into time series algorithms. Will check if each image in collection has a time and constant band, if not it will add to collection Wraps add_time_band() for adding the time band Parameters: Name Type Description Default collection ee.ImageCollection image collection to check and add time/constant band too required keep_bands list[str] | None regex name or list of band names to drop during prep and include in the result Will check if \"time\" or \"constant\" in list, if not then add to collection. default = None None apply_mask bool boolean switch to apply image mask to time band. if False, then time band will have full coverage False Returns: Type Description ee.ImageCollection collection with time and constant bands included Source code in hydrafloods/timeseries.py def prep_inputs ( collection , keep_bands = None , apply_mask = False ): \"\"\"Helper function to prepare inputs into time series algorithms. Will check if each image in collection has a time and constant band, if not it will add to collection Wraps `add_time_band()` for adding the time band args: collection (ee.ImageCollection): image collection to check and add time/constant band too keep_bands (list[str] | None, optional): regex name or list of band names to drop during prep and include in the result Will check if \"time\" or \"constant\" in list, if not then add to collection. default = None apply_mask (bool, optional): boolean switch to apply image mask to time band. if False, then time band will have full coverage returns: ee.ImageCollection: collection with time and constant bands included \"\"\" if not isinstance ( collection , ee . ImageCollection ): collection = collection . collection first = ee . Image ( collection . first ()) outCollection = copy . deepcopy ( collection ) if keep_bands is None : keep_bands = [] tband = partial ( add_time_band , apply_mask = apply_mask ) if \"time\" not in keep_bands : outCollection = outCollection . map ( tband ) if \"constant\" not in keep_bands : outCollection = outCollection . map ( lambda x : x . addBands ( ee . Image ( 1 ))) out_band_order = ee . List ([ \"constant\" , \"time\" ]) . cat ( keep_bands ) return outCollection . select ( out_band_order ) temporal_smoothing ( collection , reducer , days = 10 ) Function to apply moving window reducer in time on image collection Parameters: Name Type Description Default collection ee.ImageCollection image collection to apply moving window reducer in time on required reducer ee.Reducer earth engine reducer object to apply required days int,optional size of moving time window in days to apply reducer. default = 10 10 Returns: Type Description ee.ImageCollection image collection with reducer applied in time Source code in hydrafloods/timeseries.py def temporal_smoothing ( collection , reducer , days = 10 ): \"\"\"Function to apply moving window reducer in time on image collection args: collection (ee.ImageCollection): image collection to apply moving window reducer in time on reducer (ee.Reducer): earth engine reducer object to apply days (int,optional): size of moving time window in days to apply reducer. default = 10 returns: ee.ImageCollection: image collection with reducer applied in time \"\"\" @decorators . carry_metadata def _smooth ( img ): \"\"\"Closure function to apply smoothing in between window \"\"\" t = img . date () band_names = img . bandNames () t_start = t . advance ( - days // 2 , \"day\" ) t_stop = t . advance ( days // 2 , \"day\" ) return collection . filterDate ( t_start , t_stop ) . reduce ( reducer , 8 ) . rename ( band_names ) return collection . map ( _smooth )","title":"timeseries module"},{"location":"timeseries/#hydrafloods.timeseries","text":"","title":"timeseries"},{"location":"timeseries/#hydrafloods.timeseries.add_harmonic_coefs","text":"Function to add harmonic coefficients as bands to images Harmonic coefficients are calculated as sin and cos of frequency within year Parameters: Name Type Description Default image ee.Image image object to add harmonic coefficiencts to. Expects that image has time band required n_cycles int number of interannual cycles to include. default = 2 2 Returns: Type Description ee.Image image with harmonic coefficient bands added Source code in hydrafloods/timeseries.py def add_harmonic_coefs ( image , n_cycles = 2 ): \"\"\"Function to add harmonic coefficients as bands to images Harmonic coefficients are calculated as sin and cos of frequency within year args: image (ee.Image): image object to add harmonic coefficiencts to. Expects that image has time band n_cycles (int, optional): number of interannual cycles to include. default = 2 returns: ee.Image: image with harmonic coefficient bands added \"\"\" cosNames = _get_names ( \"cos\" , n_cycles ) sinNames = _get_names ( \"sin\" , n_cycles ) frequencyImg = ee . Image . constant ( ee . List . sequence ( 1 , n_cycles )) timeRadians = image . select ( \"time\" ) . multiply ( 2 * math . pi ) cosines = timeRadians . multiply ( frequencyImg ) . cos () . rename ( cosNames ) sines = timeRadians . multiply ( frequencyImg ) . sin () . rename ( sinNames ) return image . addBands ( cosines ) . addBands ( sines )","title":"add_harmonic_coefs()"},{"location":"timeseries/#hydrafloods.timeseries.add_time_band","text":"Function to add time band to image. Expects image has system:time_start property. Added band will have name \"time\" Parameters: Name Type Description Default img ee.Image image with system:time_start to add time band too required offset str units to calculate from 1970-01-01. default = \"year\" 'year' apply_mask bool boolean switch to apply image mask to time band. if False, then time band will have full coverage False Returns: Type Description ee.Image image object with time band added Source code in hydrafloods/timeseries.py def add_time_band ( img , offset = \"year\" , apply_mask = False ): \"\"\"Function to add time band to image. Expects image has `system:time_start` property. Added band will have name \"time\" args: img (ee.Image): image with `system:time_start` to add time band too offset (str, optional): units to calculate from 1970-01-01. default = \"year\" apply_mask (bool, optional): boolean switch to apply image mask to time band. if False, then time band will have full coverage returns: ee.Image: image object with time band added \"\"\" t = img . date () tDiff = t . difference ( ee . Date ( \"1970-01-01\" ), offset ) time = ee . Image ( tDiff ) . float () . rename ( \"time\" ) if apply_mask : time = time . updateMask ( img . select ([ 0 ]) . mask ()) return img . addBands ( time )","title":"add_time_band()"},{"location":"timeseries/#hydrafloods.timeseries.fit_harmonic_trend","text":"Function to fit a harmonic trend on image collection along the time dimension. Uses ee.Reducer.linearRegression to solve for coefficients Parameters: Name Type Description Default collection ee.ImageCollection | hydrafloods.Dataset image collection to fit trend line for required n_cycles int number of interannual cycles to model. default = 2 2 independents list[str] list of band names to use for fitting regression. default = [\"constant\", \"time\"] ['constant', 'time'] dependent str | None band name of values to fit, if None then uses the first band. default = None None output_err bool switch to output regression x and y errors, if true output will have \"mean_x\", \"residual_x\" and \"residual_y\" bands. Useful for estimating confidence intervals. default = False False Returns: Type Description ee.Image output image with regression coeffients as bands named \"constant\", \"time\", \"cos_n\", and \"sin_n\" where n is a sequnces of cycles. Will have \"mean_x\", \"residual_x\" and \"residual_y\" if ouput_err == True Exceptions: Type Description ValueError if collection is not of type ee.ImageCollection or hydrafloods.Dataset Source code in hydrafloods/timeseries.py def fit_harmonic_trend ( collection , n_cycles = 2 , independents = [ \"constant\" , \"time\" ], dependent = None , output_err = False , ): \"\"\"Function to fit a harmonic trend on image collection along the time dimension. Uses ee.Reducer.linearRegression to solve for coefficients args: collection (ee.ImageCollection | hydrafloods.Dataset): image collection to fit trend line for n_cycles (int, optional): number of interannual cycles to model. default = 2 independents (list[str], optional): list of band names to use for fitting regression. default = [\"constant\", \"time\"] dependent (str | None, optional): band name of values to fit, if None then uses the first band. default = None output_err (bool, optional): switch to output regression x and y errors, if true output will have \"mean_x\", \"residual_x\" and \"residual_y\" bands. Useful for estimating confidence intervals. default = False returns: ee.Image: output image with regression coeffients as bands named \"constant\", \"time\", \"cos_n\", and \"sin_n\" where n is a sequnces of cycles. Will have \"mean_x\", \"residual_x\" and \"residual_y\" if ouput_err == True raises: ValueError: if collection is not of type ee.ImageCollection or hydrafloods.Dataset \"\"\" if not isinstance ( collection , ee . ImageCollection ): try : collection = collection . collection except AttributeError : raise ValueError ( \"collection argument expected type ee.ImageCollection or hydrafloods.Dataset,\" + f \"got { type ( collection ) } \" ) if dependent is None : dependent = ee . String ( ee . Image ( collection . first ()) . bandNames () . get ( 0 )) else : dependent = ee . String ( dependent ) independents = ( ee . List ( independents ) . cat ( _get_names ( \"cos\" , n_cycles )) . cat ( _get_names ( \"sin\" , n_cycles )) ) _add_coefs = partial ( add_harmonic_coefs , n_cycles = n_cycles ) harmonic_collection = prep_inputs ( collection , keep_bands = [ dependent ], apply_mask = True ) . map ( _add_coefs ) harmonic_trend = harmonic_collection . select ( independents . add ( dependent )) . reduce ( ee . Reducer . linearRegression ( numX = independents . length (), numY = 1 ), 16 ) n = harmonic_collection . select ( dependent ) . reduce ( ee . Reducer . count (), 16 ) . rename ( \"n\" ) # Turn the array image into a multi-band image of coefficients harmonic_coefficients = ( harmonic_trend . select ( \"coefficients\" ) . arrayProject ([ 0 ]) . arrayFlatten ([ independents ]) ) . addBands ( n ) if output_err : harmonic_mse = ( harmonic_trend . select ( \"residuals\" ) . arrayProject ([ 0 ]) . arrayFlatten ([[ \"residual_y\" ]]) ) t_mean = harmonic_collection . select ( \"time\" ) . reduce ( ee . Reducer . mean (), 16 ) . rename ( \"mean_x\" ) x_err = ( harmonic_collection . select ( \"time\" ) . map ( lambda x : x . subtract ( t_mean ) . pow ( 2 )) . reduce ( ee . Reducer . sum (), 16 ) . rename ( \"residual_x\" ) ) harmonic_coefficients = ee . Image . cat ( [ harmonic_coefficients , harmonic_mse , t_mean , x_err ] ) return harmonic_coefficients","title":"fit_harmonic_trend()"},{"location":"timeseries/#hydrafloods.timeseries.fit_linear_trend","text":"Function to fit a linear reducer on image collection along the time dimension. Parameters: Name Type Description Default collection ee.ImageCollection image collection to fit trend line for required independents list[str] list of band names to use for fitting regression. default = [\"constant\", \"time\"] ['constant', 'time'] dependent str | None band name of values to fit, if None then uses the first band. default = None None regression_method str name of regression reducer to use. options are \"simple\", \"ols\", \"robust\", \"ridge\", \"sen\". default = \"ols\" 'ols' output_err bool switch to output regression x and y errors, if true output will have \"mean_x\", \"residual_x\" and \"residual_y\" bands. Useful for estimating confidence intervals. default = False False Returns: Type Description ee.Image output image with regression coeffients as bands named \"offset\" and \"slope\". Will have \"mean_x\", \"residual_x\" and \"residual_y\" if ouput_err == True Source code in hydrafloods/timeseries.py def fit_linear_trend ( collection , independents = [ \"constant\" , \"time\" ], dependent = None , regression_method = \"ols\" , output_err = False , ): \"\"\"Function to fit a linear reducer on image collection along the time dimension. args: collection (ee.ImageCollection): image collection to fit trend line for independents (list[str], optional): list of band names to use for fitting regression. default = [\"constant\", \"time\"] dependent (str | None, optional): band name of values to fit, if None then uses the first band. default = None regression_method (str, optional): name of regression reducer to use. options are \"simple\", \"ols\", \"robust\", \"ridge\", \"sen\". default = \"ols\" output_err (bool, optional): switch to output regression x and y errors, if true output will have \"mean_x\", \"residual_x\" and \"residual_y\" bands. Useful for estimating confidence intervals. default = False returns: ee.Image: output image with regression coeffients as bands named \"offset\" and \"slope\". Will have \"mean_x\", \"residual_x\" and \"residual_y\" if ouput_err == True \"\"\" independents = ee . List ( independents ) if dependent is None : dependent = ee . String ( ee . Image ( collection . first ()) . bandNames () . get ( 0 )) else : dependent = ee . String ( dependent ) methods = [ \"simple\" , \"ols\" , \"robust\" , \"ridge\" , \"sen\" ] reducers = [ ee . Reducer . linearFit (), ee . Reducer . linearRegression ( independents . length (), 1 ), ee . Reducer . robustLinearRegression ( independents . length (), 1 ), ee . Reducer . ridgeRegression ( independents . length (), 1 ), ee . Reducer . sensSlope (), ] method_lookup = { v : reducers [ i ] for i , v in enumerate ( methods )} if regression_method not in methods : raise ValueError () else : lin_reducer = method_lookup [ regression_method ] if not isinstance ( collection , ee . ImageCollection ): collection = collection . collection reduction_coll = prep_inputs ( collection , keep_bands = [ dependent ], apply_mask = True ) . select ( independents . add ( dependent )) n = reduction_coll . select ( dependent ) . reduce ( \"count\" ) . rename ( \"n\" ) if regression_method in [ \"sen\" , \"ridge\" ]: independents = ee . List ([ \"constant\" ]) . cat ( independents ) if regression_method == \"sen\" : lr = reduction_coll . reduce ( lin_reducer , 16 ) . select ( [ \"offset\" , \"slope\" ], independents ) else : lr_arr = reduction_coll . reduce ( lin_reducer , 16 ) lr = ( lr_arr . select ([ \"coefficients\" ]) . arrayProject ([ 0 ]) . arrayFlatten ([ independents ]) ) if output_err and regression_method is not \"sen\" : linear_mse = ( lr_arr . select ( \"residuals\" ) . arrayProject ([ 0 ]) . arrayFlatten ([[ \"residual_y\" ]]) ) t_mean = reduction_coll . select ( \"time\" ) . mean () . rename ( \"mean_x\" ) x_err = ( reduction_coll . select ( \"time\" ) . map ( lambda x : x . subtract ( t_mean ) . pow ( 2 )) . reduce ( ee . Reducer . sum (), 16 ) . rename ( \"residual_x\" ) ) lr = ee . Image . cat ([ lr , linear_mse , t_mean , x_err ]) return lr . addBands ( n )","title":"fit_linear_trend()"},{"location":"timeseries/#hydrafloods.timeseries.get_dummy_collection","text":"Helper function to create image collection of images to apply time series prediction on Creates daily imagery between start_time and end_time Parameters: Name Type Description Default start_time str | ee.Date string or ee.Date string to start creating images on (inclusive) required end_time str | ee.Date string or ee.Date string to end creating images on (exclusive) required Returns: Type Description ee.ImageCollection image collection with image containing time and constant bands Source code in hydrafloods/timeseries.py def get_dummy_collection ( start_time , end_time ): \"\"\"Helper function to create image collection of images to apply time series prediction on Creates daily imagery between start_time and end_time args: start_time (str | ee.Date): string or ee.Date string to start creating images on (inclusive) end_time (str | ee.Date): string or ee.Date string to end creating images on (exclusive) returns: ee.ImageCollection: image collection with image containing time and constant bands \"\"\" def _gen_image ( i ): t = start_time . advance ( ee . Number ( i ), \"day\" ) return ee . Image () . rename ( \"blank\" ) . set ( \"system:time_start\" , t . millis ()) if not isinstance ( start_time , ee . Date ): start_time = ee . Date ( start_time ) if not isinstance ( end_time , ee . Date ): end_time = ee . Date ( end_time ) n = end_time . difference ( start_time , \"day\" ) coll = ee . ImageCollection ( ee . List . sequence ( 0 , n ) . map ( _gen_image )) return prep_inputs ( coll )","title":"get_dummy_collection()"},{"location":"timeseries/#hydrafloods.timeseries.get_dummy_img","text":"Helper function to get an image readily available to use for predictions Resulting image will include time based on year and constant band of 1 Parameters: Name Type Description Default t str | ee.Date string or ee.Date string to create dummy image for required Returns: Type Description ee.Image image object with time and constant bands Source code in hydrafloods/timeseries.py def get_dummy_img ( t ): \"\"\"Helper function to get an image readily available to use for predictions Resulting image will include time based on year and constant band of 1 args: t (str | ee.Date): string or ee.Date string to create dummy image for returns: ee.Image: image object with time and constant bands \"\"\" if not isinstance ( t , ee . Date ): t = ee . Date ( t ) img = ee . Image . constant ( 1 ) . set ( \"system:time_start\" , t . millis ()) time_band = ( ee . Image ( t . difference ( ee . Date ( \"1970-01-01\" ), \"year\" )) . float () . rename ( \"time\" ) ) return img . addBands ( time_band )","title":"get_dummy_img()"},{"location":"timeseries/#hydrafloods.timeseries.predict_harmonics","text":"Helper function to apply harmonic trend prediction Parameters: Name Type Description Default collection ee.ImageCollection image collection to apply prediction on required harmonics ee.Image harmonic coefficient image with coeffiecient bands required n_cycles int number of interannual cycles to model, note n_cycles must equal the number of cycle coefficients in harmonics . default = 2 2 independents list[str] list of independent band names to use in model. These are other than the harmonic coefficient names. default = [\"constant\", \"time\"] ['constant', 'time'] returns ee.ImageCollection: image collection with predicted values Source code in hydrafloods/timeseries.py def predict_harmonics ( collection , harmonics , n_cycles = 2 , independents = [ \"constant\" , \"time\" ] ): \"\"\"Helper function to apply harmonic trend prediction args: collection (ee.ImageCollection): image collection to apply prediction on harmonics (ee.Image): harmonic coefficient image with coeffiecient bands n_cycles (int, optional): number of interannual cycles to model, note n_cycles must equal the number of cycle coefficients in `harmonics`. default = 2 independents (list[str], optional): list of independent band names to use in model. These are other than the harmonic coefficient names. default = [\"constant\", \"time\"] returns ee.ImageCollection: image collection with predicted values \"\"\" @decorators . carry_metadata def _apply_prediction ( image ): \"\"\"Closure function to apply prediction \"\"\" return ( image . select ( independents ) . multiply ( harmonics ) . reduce ( \"sum\" ) . rename ( \"predicted\" ) ) independents = ( ee . List ( independents ) . cat ( _get_names ( \"cos\" , n_cycles )) . cat ( _get_names ( \"sin\" , n_cycles )) ) _add_coefs = partial ( add_harmonic_coefs , n_cycles = n_cycles ) harmonic_collection = prep_inputs ( collection ) . map ( _add_coefs ) # Compute fitted values. predicted = harmonic_collection . map ( _apply_prediction ) return predicted","title":"predict_harmonics()"},{"location":"timeseries/#hydrafloods.timeseries.prep_inputs","text":"Helper function to prepare inputs into time series algorithms. Will check if each image in collection has a time and constant band, if not it will add to collection Wraps add_time_band() for adding the time band Parameters: Name Type Description Default collection ee.ImageCollection image collection to check and add time/constant band too required keep_bands list[str] | None regex name or list of band names to drop during prep and include in the result Will check if \"time\" or \"constant\" in list, if not then add to collection. default = None None apply_mask bool boolean switch to apply image mask to time band. if False, then time band will have full coverage False Returns: Type Description ee.ImageCollection collection with time and constant bands included Source code in hydrafloods/timeseries.py def prep_inputs ( collection , keep_bands = None , apply_mask = False ): \"\"\"Helper function to prepare inputs into time series algorithms. Will check if each image in collection has a time and constant band, if not it will add to collection Wraps `add_time_band()` for adding the time band args: collection (ee.ImageCollection): image collection to check and add time/constant band too keep_bands (list[str] | None, optional): regex name or list of band names to drop during prep and include in the result Will check if \"time\" or \"constant\" in list, if not then add to collection. default = None apply_mask (bool, optional): boolean switch to apply image mask to time band. if False, then time band will have full coverage returns: ee.ImageCollection: collection with time and constant bands included \"\"\" if not isinstance ( collection , ee . ImageCollection ): collection = collection . collection first = ee . Image ( collection . first ()) outCollection = copy . deepcopy ( collection ) if keep_bands is None : keep_bands = [] tband = partial ( add_time_band , apply_mask = apply_mask ) if \"time\" not in keep_bands : outCollection = outCollection . map ( tband ) if \"constant\" not in keep_bands : outCollection = outCollection . map ( lambda x : x . addBands ( ee . Image ( 1 ))) out_band_order = ee . List ([ \"constant\" , \"time\" ]) . cat ( keep_bands ) return outCollection . select ( out_band_order )","title":"prep_inputs()"},{"location":"timeseries/#hydrafloods.timeseries.temporal_smoothing","text":"Function to apply moving window reducer in time on image collection Parameters: Name Type Description Default collection ee.ImageCollection image collection to apply moving window reducer in time on required reducer ee.Reducer earth engine reducer object to apply required days int,optional size of moving time window in days to apply reducer. default = 10 10 Returns: Type Description ee.ImageCollection image collection with reducer applied in time Source code in hydrafloods/timeseries.py def temporal_smoothing ( collection , reducer , days = 10 ): \"\"\"Function to apply moving window reducer in time on image collection args: collection (ee.ImageCollection): image collection to apply moving window reducer in time on reducer (ee.Reducer): earth engine reducer object to apply days (int,optional): size of moving time window in days to apply reducer. default = 10 returns: ee.ImageCollection: image collection with reducer applied in time \"\"\" @decorators . carry_metadata def _smooth ( img ): \"\"\"Closure function to apply smoothing in between window \"\"\" t = img . date () band_names = img . bandNames () t_start = t . advance ( - days // 2 , \"day\" ) t_stop = t . advance ( days // 2 , \"day\" ) return collection . filterDate ( t_start , t_stop ) . reduce ( reducer , 8 ) . rename ( band_names ) return collection . map ( _smooth )","title":"temporal_smoothing()"},{"location":"using-datasets/","text":"Here are a more in depth examples of using hydrafloods.Dataset classes for working with imagery. It is expected that the code is run in an interactive python session such as IPython or in a Jupyter Notebook as later code blocks will use variables from previous ones. import ee ee . Initialze () import hydrafloods as hf Dataset structure region = hf . country_bbox ( \"Cambodia\" ) start_time = \"2019-01-01\" end_time = \"2019-07-01\" # get a Landsat 8 collection lc8 = hf . Landsat8 ( region , start_time , end_time ) print ( lc8 ) # should look like # HYDRAFloods Dataset: # {'asset_id': 'LANDSAT/LC08/C01/T1_SR', # 'end_time': '2019-07-01', # 'name': 'Landsat8', # 'region': [[[...], [...], [...], [...], [...]]], # 'start_time': '2019-01-01'} A dataset object has a few properties that we can access to assist in processing or understanding the data contained in the dataset. Here is a list of properties and a description: Dataset.collection : Earth Engine image collection object that the dataset class wraps Dataset.n_images : client side number of images in collection Dataset.dates : client side list of datetime information of all images acquisition times Let's inspect some of these properties print ( lc8 . n_images ) # should equal 197 print ( lc8 . dates ) # should look something like # ['2019-01-12 03:06:42.950', # '2019-01-28 03:06:38.990', # ... , # '2019-06-01 03:32:06.850'] # since `Dataset.collection` is a server side object we will just # check that it is in fact a ee.ImageCollection object print ( isinstance ( lc8 . collection , ee . ImageCollection )) # should == True Specialized Datasets hydrafloods has specialized datasets classes that extend a hydrafloods.Dataset class and are common image collections used in surface water mapping. These specialized datasets include a custom qa() method that gets called on initialization to mask poor quality pixels and custom methods that make harmonization easy. Furthermore, the optical sensor bands are automatically renamed to a common scheme so that they can be used together easily. Here is a list of the specialized datasets with links to information on methods: Really, one can think of the custom qa() method as a preprocessing step that you would like to happen on all images in the dataset so it is not just restricted to specific sensors as seen in a later section. Sentinel 1: hydrafloods.Sentinel1 Sentinel 2: hydrafloods.Sentinel2 Landsat 8: hydrafloods.Landsat8 Landsat 7: hydrafloods.Landsat7 VIIRS: hydrafloods.Viirs MODIS: hydrafloods.Modis To provide an example of using the internal qa() method and not we can redefine the Landsat 8 collection from before but with setting use_qa to False lc8 = hf . Landsat8 ( region , start_time , end_time ) lc8_noqa = hf . Landsat8 ( region , start_time , end_time , use_qa = False ) thumb_params = { \"min\" : 50 , \"max\" : 5500 , \"bands\" : \"swir2,nir,green\" , \"gamma\" : 1.5 , \"dimensions\" : 1024 } # get thumbnail images qa_thumb = ( lc8 . collection . first () . getThumbURL ( thumb_params ) ) noqa_thumb = ( lc8_noqa . collection . first () . getThumbURL ( thumb_params ) ) # print urls to view thumbnails print ( qa_thumb ) print ( noqa_thumb ) use_qa = True use_qa = False We can clearly see the image on the left has clouds and cloud shadows masked and can therefore be used directly in analysis with minimal effort. More information on the internals of these specialized datasets and how you can write your own can be found at the Writing your own dataset class section. Applying a function Merging Datasets One of the simpilist ways to combine datasets is to merge. This takes the imagery in one collection and concatenates it with the original collection. We can use the merge() method to accomplish this. Additioanlly, the merge() method automatically sorts the image collections in time so we can start using dense time series right away. Here is an example of merging Landat8 and Sentinel2 datasets together: lc8 = hf . Landsat8 ( region , start_time , end_time ) # has 197 image s2 = hf . Sentinel2 ( region , start_time , end_time ) # has 2400 images merged = lc8 . merge ( s2 ) print ( merged . n_images ) # now has 2597 images! Joining Datasets Joining datasets is another way to bring together two datasets but by looking at coincident imagery and combines the bands into one image. Whereas merge combined the two collections irrespective of space time overlap, join() looks for overlapping data in space and time and will return only data that overlaps with the bands combined. Furthermore, the resulting images will be clipped to the overlapping region. This functionality is really helpful when looking for coincident data from multiple sensors. lc8 = hf . Landsat8 ( region , start_time , end_time ) # has 197 images s1 = hf . Sentinel1 ( region , start_time , end_time ) # has 628 images joined = lc8 . join ( s1 ) # has 131 coincident images # grab the first image in the collection # will have optical and sar bands first = joined . collection . first () print ( first . bandNames () . getInfo ()) # should equal the following: # ['blue', 'green', 'red', 'nir', 'swir1', 'swir2', 'VV', 'VH', 'angle'] # both optical and SAR bands are included in the image # visualize the different bands optical_thumb = first . getThumbURL ({ \"min\" : 50 , \"max\" : 5500 , \"bands\" : \"swir2,nir,green\" , \"gamma\" : 1.5 , \"dimensions\" : 1024 }) sar_thumb = first . getThumbURL ({ \"min\" :[ - 25 , - 30 , - 25 ], \"max\" :[ 0 , - 5 , 0 ], \"bands\" : \"VV,VH,VV\" , \"dimensions\" : 1024 }) # print urls to view thumbnails print ( optical_thumb ) print ( sar_thumb ) Landsat 8 2019-01-28 Sentinel 1 2019-01-28 Temporal aggregation A common workflow is merging data and make composites for individual dates that data is available. A good example of this is the MODIS sensor that is onboard the Terra and Aqua satellite. We can create daily composites of the imagery by merging the datasets then looping over each day to mosaic the data. hydrafloods has a method aggregate_time() to do the mosiacing sequentially in time. Here we create a combined MODIS Terra and Aqua dataset. # define new time range start_time = \"2018-11-03\" end_time = \"2018-11-15\" # get the terra MODIS dataset terra = hf . Modis ( region , start_time , end_time ) # get the aqua MODIS dataset # note calling the asset_id explicitly aqua = hf . Modis ( region , start_time , end_time , asset_id = \"MODIS/006/MYD09GA\" ) # merge the collections into one merged = terra . merge ( aqua ) # aggregate in time agg = merged . aggregate_time ( reducer = \"median\" ) MODIS Terra 2018-11-03 MODIS Aqua 2018-11-03 Aggregated By doing this we can fill in gaps where some data is missing with other sensors. We see in the above example that combining the MODIS data from Terra and Aqua we can get more coverage in the event of flooding. By default the method will take unique dates within the dataset and aggregate by one day as seen in the above example. We can also use this functionality to make monthly or yearly composites of data by specifying the dates that we want to start the aggregation with and a period after the start dates to do the aggregation. Here is an example creating yearly composites from 2015 through 2019: # define new time range start_time = \"2015-01-01\" end_time = \"2020-01-01\" # define the dates in which to start aggregation year_starts = [ \"2015-01-01\" , \"2016-01-01\" , \"2017-01-01\" , \"2018-01-01\" , \"2019-01-01\" ] # get the terra MODIS dataset terra = hf . Modis ( region , start_time , end_time ) # apply the aggregation yearly = terra . aggregate_time ( dates = year_starts , period = 365 ) print ( yearly . dates ) # should equal to: # ['2015-01-01 00:00:00.000', # '2016-01-01 00:00:00.000', # '2017-01-01 00:00:00.000', # '2018-01-01 00:00:00.000', # '2019-01-01 00:00:00.000'] As seen, this method allows for customization of when to start aggregations and how long/which dates to include in aggregation which can be helpful for unique timings like dekads. Writing your own dataset class The hydrafloods.Dataset class can be used to create custom dataset classes for sensors. This is helpful when there is a sensor that will be used often with other datasets using hydrafloods . Here is an example of writing a custom hydrafloods.Dataset class for the GOES16 collection. We will predefine the asset_id argument and define a qa() method to scale data to reflectance and mask poor quality pixels. class Goes16 ( hf . Dataset ): def __init__ ( self , * args , asset_id = \"NOAA/GOES/16/MCMIPF\" , use_qa = True , ** kwargs ): # initialize the parent class super ( Goes16 , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) # list of band names to return with new names old_band_names = [ \"CMI_C01\" , \"green\" , \"CMI_C02\" , \"CMI_C03\" , \"CMI_C05\" , \"CMI_C06\" ] new_band_names = [ \"blue\" , \"green\" , \"red\" , \"nir\" , \"swir1\" , \"swir2\" ] # change the band names to something self . collection = self . collection . select ( old_band_names , new_band_names ) return # define a qa method and wrap in the carry_metadata decorator # retains metadata for each image # qa() will get called on super() if use_qa==True @hf . decorators . carry_metadata def qa ( self , img ): \"\"\"Custom QA masking method for Goes17 data Scales data to reflectance and finds poor quality images add a psuedo-green band using methods from https://doi.org/10.1029/2018EA000379 \"\"\" band_names = img . bandNames () # get scale and offset values scale_properties = band_names . map ( lambda x : ee . String ( x ) . cat ( \"_scale\" )) offset_properties = band_names . map ( lambda x : ee . String ( x ) . cat ( \"_offset\" )) # convert scale/offset values to image scale_img = img . toDictionary ( scale_properties ) . toImage () offset_img = img . toDictionary ( offset_properties ) . toImage () # get qa bands and set 0 to 1 and everything else to 0 qa_img = img . select ( \"^(DQF).*\" ) . Not () # get the actual image data and apply qa mask img = img . select ( \"^(CMI).*\" ) . updateMask ( qa_img ) # scale imagery to reflectance img = img . multiply ( scale_img ) . add ( offset_img ) . multiply ( qa_img ) # compute psuedo green band green_weights = ee . Image . constant ([ 0.45 , 0.45 , 0.1 ]) green_band = ( img . select ([ \"CMI_C01\" , \"CMI_C02\" , \"CMI_C03\" ]) . multiply ( green_weights ) . reduce ( \"sum\" ) . rename ( \"green\" ) ) return img . addBands ( green_band ) # get a GOES collection over the United States us = hf . country_bbox ( \"United States\" ) goes = Goes16 ( us , \"2020-07-28T18:40:18\" , \"2020-07-29T00:00:00\" ) # view the results from the GOES16 collection first_img = goes . collection . first () viz_params = { \"min\" : 0.05 , \"max\" : 0.55 , \"bands\" : \"swir1,nir,green\" , \"gamma\" : 1.5 , \"region\" : us , \"dimensions\" : 1024 , \"crs\" : \"epsg:5070\" } print ( first_img . getThumbURL ( viz_params )) In this example of a custom dataset class for GOES16 imagery, the qa() method definition is more for preprocessing to scale the imagery. A custom cloud/shadow masking workflow can easily be included and applied on the imagery. Now we are ready to use our custom GOES16 imagery with the rest of the hydrafloods functions! More detailed information on the hydrafloods.Dataset class along with it's method fucntionality and arguments can be found in the datasets module API reference.","title":"Using the Dataset class"},{"location":"using-datasets/#dataset-structure","text":"region = hf . country_bbox ( \"Cambodia\" ) start_time = \"2019-01-01\" end_time = \"2019-07-01\" # get a Landsat 8 collection lc8 = hf . Landsat8 ( region , start_time , end_time ) print ( lc8 ) # should look like # HYDRAFloods Dataset: # {'asset_id': 'LANDSAT/LC08/C01/T1_SR', # 'end_time': '2019-07-01', # 'name': 'Landsat8', # 'region': [[[...], [...], [...], [...], [...]]], # 'start_time': '2019-01-01'} A dataset object has a few properties that we can access to assist in processing or understanding the data contained in the dataset. Here is a list of properties and a description: Dataset.collection : Earth Engine image collection object that the dataset class wraps Dataset.n_images : client side number of images in collection Dataset.dates : client side list of datetime information of all images acquisition times Let's inspect some of these properties print ( lc8 . n_images ) # should equal 197 print ( lc8 . dates ) # should look something like # ['2019-01-12 03:06:42.950', # '2019-01-28 03:06:38.990', # ... , # '2019-06-01 03:32:06.850'] # since `Dataset.collection` is a server side object we will just # check that it is in fact a ee.ImageCollection object print ( isinstance ( lc8 . collection , ee . ImageCollection )) # should == True","title":"Dataset structure"},{"location":"using-datasets/#specialized-datasets","text":"hydrafloods has specialized datasets classes that extend a hydrafloods.Dataset class and are common image collections used in surface water mapping. These specialized datasets include a custom qa() method that gets called on initialization to mask poor quality pixels and custom methods that make harmonization easy. Furthermore, the optical sensor bands are automatically renamed to a common scheme so that they can be used together easily. Here is a list of the specialized datasets with links to information on methods: Really, one can think of the custom qa() method as a preprocessing step that you would like to happen on all images in the dataset so it is not just restricted to specific sensors as seen in a later section. Sentinel 1: hydrafloods.Sentinel1 Sentinel 2: hydrafloods.Sentinel2 Landsat 8: hydrafloods.Landsat8 Landsat 7: hydrafloods.Landsat7 VIIRS: hydrafloods.Viirs MODIS: hydrafloods.Modis To provide an example of using the internal qa() method and not we can redefine the Landsat 8 collection from before but with setting use_qa to False lc8 = hf . Landsat8 ( region , start_time , end_time ) lc8_noqa = hf . Landsat8 ( region , start_time , end_time , use_qa = False ) thumb_params = { \"min\" : 50 , \"max\" : 5500 , \"bands\" : \"swir2,nir,green\" , \"gamma\" : 1.5 , \"dimensions\" : 1024 } # get thumbnail images qa_thumb = ( lc8 . collection . first () . getThumbURL ( thumb_params ) ) noqa_thumb = ( lc8_noqa . collection . first () . getThumbURL ( thumb_params ) ) # print urls to view thumbnails print ( qa_thumb ) print ( noqa_thumb ) use_qa = True use_qa = False We can clearly see the image on the left has clouds and cloud shadows masked and can therefore be used directly in analysis with minimal effort. More information on the internals of these specialized datasets and how you can write your own can be found at the Writing your own dataset class section.","title":"Specialized Datasets"},{"location":"using-datasets/#applying-a-function","text":"","title":"Applying a function"},{"location":"using-datasets/#merging-datasets","text":"One of the simpilist ways to combine datasets is to merge. This takes the imagery in one collection and concatenates it with the original collection. We can use the merge() method to accomplish this. Additioanlly, the merge() method automatically sorts the image collections in time so we can start using dense time series right away. Here is an example of merging Landat8 and Sentinel2 datasets together: lc8 = hf . Landsat8 ( region , start_time , end_time ) # has 197 image s2 = hf . Sentinel2 ( region , start_time , end_time ) # has 2400 images merged = lc8 . merge ( s2 ) print ( merged . n_images ) # now has 2597 images!","title":"Merging Datasets"},{"location":"using-datasets/#joining-datasets","text":"Joining datasets is another way to bring together two datasets but by looking at coincident imagery and combines the bands into one image. Whereas merge combined the two collections irrespective of space time overlap, join() looks for overlapping data in space and time and will return only data that overlaps with the bands combined. Furthermore, the resulting images will be clipped to the overlapping region. This functionality is really helpful when looking for coincident data from multiple sensors. lc8 = hf . Landsat8 ( region , start_time , end_time ) # has 197 images s1 = hf . Sentinel1 ( region , start_time , end_time ) # has 628 images joined = lc8 . join ( s1 ) # has 131 coincident images # grab the first image in the collection # will have optical and sar bands first = joined . collection . first () print ( first . bandNames () . getInfo ()) # should equal the following: # ['blue', 'green', 'red', 'nir', 'swir1', 'swir2', 'VV', 'VH', 'angle'] # both optical and SAR bands are included in the image # visualize the different bands optical_thumb = first . getThumbURL ({ \"min\" : 50 , \"max\" : 5500 , \"bands\" : \"swir2,nir,green\" , \"gamma\" : 1.5 , \"dimensions\" : 1024 }) sar_thumb = first . getThumbURL ({ \"min\" :[ - 25 , - 30 , - 25 ], \"max\" :[ 0 , - 5 , 0 ], \"bands\" : \"VV,VH,VV\" , \"dimensions\" : 1024 }) # print urls to view thumbnails print ( optical_thumb ) print ( sar_thumb ) Landsat 8 2019-01-28 Sentinel 1 2019-01-28","title":"Joining Datasets"},{"location":"using-datasets/#temporal-aggregation","text":"A common workflow is merging data and make composites for individual dates that data is available. A good example of this is the MODIS sensor that is onboard the Terra and Aqua satellite. We can create daily composites of the imagery by merging the datasets then looping over each day to mosaic the data. hydrafloods has a method aggregate_time() to do the mosiacing sequentially in time. Here we create a combined MODIS Terra and Aqua dataset. # define new time range start_time = \"2018-11-03\" end_time = \"2018-11-15\" # get the terra MODIS dataset terra = hf . Modis ( region , start_time , end_time ) # get the aqua MODIS dataset # note calling the asset_id explicitly aqua = hf . Modis ( region , start_time , end_time , asset_id = \"MODIS/006/MYD09GA\" ) # merge the collections into one merged = terra . merge ( aqua ) # aggregate in time agg = merged . aggregate_time ( reducer = \"median\" ) MODIS Terra 2018-11-03 MODIS Aqua 2018-11-03 Aggregated By doing this we can fill in gaps where some data is missing with other sensors. We see in the above example that combining the MODIS data from Terra and Aqua we can get more coverage in the event of flooding. By default the method will take unique dates within the dataset and aggregate by one day as seen in the above example. We can also use this functionality to make monthly or yearly composites of data by specifying the dates that we want to start the aggregation with and a period after the start dates to do the aggregation. Here is an example creating yearly composites from 2015 through 2019: # define new time range start_time = \"2015-01-01\" end_time = \"2020-01-01\" # define the dates in which to start aggregation year_starts = [ \"2015-01-01\" , \"2016-01-01\" , \"2017-01-01\" , \"2018-01-01\" , \"2019-01-01\" ] # get the terra MODIS dataset terra = hf . Modis ( region , start_time , end_time ) # apply the aggregation yearly = terra . aggregate_time ( dates = year_starts , period = 365 ) print ( yearly . dates ) # should equal to: # ['2015-01-01 00:00:00.000', # '2016-01-01 00:00:00.000', # '2017-01-01 00:00:00.000', # '2018-01-01 00:00:00.000', # '2019-01-01 00:00:00.000'] As seen, this method allows for customization of when to start aggregations and how long/which dates to include in aggregation which can be helpful for unique timings like dekads.","title":"Temporal aggregation"},{"location":"using-datasets/#writing-your-own-dataset-class","text":"The hydrafloods.Dataset class can be used to create custom dataset classes for sensors. This is helpful when there is a sensor that will be used often with other datasets using hydrafloods . Here is an example of writing a custom hydrafloods.Dataset class for the GOES16 collection. We will predefine the asset_id argument and define a qa() method to scale data to reflectance and mask poor quality pixels. class Goes16 ( hf . Dataset ): def __init__ ( self , * args , asset_id = \"NOAA/GOES/16/MCMIPF\" , use_qa = True , ** kwargs ): # initialize the parent class super ( Goes16 , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) # list of band names to return with new names old_band_names = [ \"CMI_C01\" , \"green\" , \"CMI_C02\" , \"CMI_C03\" , \"CMI_C05\" , \"CMI_C06\" ] new_band_names = [ \"blue\" , \"green\" , \"red\" , \"nir\" , \"swir1\" , \"swir2\" ] # change the band names to something self . collection = self . collection . select ( old_band_names , new_band_names ) return # define a qa method and wrap in the carry_metadata decorator # retains metadata for each image # qa() will get called on super() if use_qa==True @hf . decorators . carry_metadata def qa ( self , img ): \"\"\"Custom QA masking method for Goes17 data Scales data to reflectance and finds poor quality images add a psuedo-green band using methods from https://doi.org/10.1029/2018EA000379 \"\"\" band_names = img . bandNames () # get scale and offset values scale_properties = band_names . map ( lambda x : ee . String ( x ) . cat ( \"_scale\" )) offset_properties = band_names . map ( lambda x : ee . String ( x ) . cat ( \"_offset\" )) # convert scale/offset values to image scale_img = img . toDictionary ( scale_properties ) . toImage () offset_img = img . toDictionary ( offset_properties ) . toImage () # get qa bands and set 0 to 1 and everything else to 0 qa_img = img . select ( \"^(DQF).*\" ) . Not () # get the actual image data and apply qa mask img = img . select ( \"^(CMI).*\" ) . updateMask ( qa_img ) # scale imagery to reflectance img = img . multiply ( scale_img ) . add ( offset_img ) . multiply ( qa_img ) # compute psuedo green band green_weights = ee . Image . constant ([ 0.45 , 0.45 , 0.1 ]) green_band = ( img . select ([ \"CMI_C01\" , \"CMI_C02\" , \"CMI_C03\" ]) . multiply ( green_weights ) . reduce ( \"sum\" ) . rename ( \"green\" ) ) return img . addBands ( green_band ) # get a GOES collection over the United States us = hf . country_bbox ( \"United States\" ) goes = Goes16 ( us , \"2020-07-28T18:40:18\" , \"2020-07-29T00:00:00\" ) # view the results from the GOES16 collection first_img = goes . collection . first () viz_params = { \"min\" : 0.05 , \"max\" : 0.55 , \"bands\" : \"swir1,nir,green\" , \"gamma\" : 1.5 , \"region\" : us , \"dimensions\" : 1024 , \"crs\" : \"epsg:5070\" } print ( first_img . getThumbURL ( viz_params )) In this example of a custom dataset class for GOES16 imagery, the qa() method definition is more for preprocessing to scale the imagery. A custom cloud/shadow masking workflow can easily be included and applied on the imagery. Now we are ready to use our custom GOES16 imagery with the rest of the hydrafloods functions! More detailed information on the hydrafloods.Dataset class along with it's method fucntionality and arguments can be found in the datasets module API reference.","title":"Writing your own dataset class"},{"location":"utils/","text":"hydrafloods.utils decode_date ( date ) Decodes a date from a command line argument, returning msec since epoch\". Parameters: Name Type Description Default date str date value in a format that can be parsed into datetime object required Returns: Type Description datetime.datetime decoded datetime value Exceptions: Type Description TypeError if string does not conform to a legal date format. Source code in hydrafloods/utils.py def decode_date ( date ): \"\"\"Decodes a date from a command line argument, returning msec since epoch\". args: date (str): date value in a format that can be parsed into datetime object returns: datetime.datetime: decoded datetime value raises: TypeError: if string does not conform to a legal date format. \"\"\" date_formats = [ \"%Y%m %d \" , \"%Y-%m- %d \" , \"%Y-%m- %d T%H:%M:%S\" , \"%Y-%m- %d T%H:%M:%S. %f \" , ] for date_format in date_formats : try : dt = datetime . datetime . strptime ( date , date_format ) return dt except ValueError : continue raise TypeError ( f \"Invalid value for property of type 'date': ' { date } '.\" ) list_gcs_objs ( bucket_path , pattern = None , output_url = False , project = None ) Function to list objects in Google Cloud Storage Bucket Parameters: Name Type Description Default bucket_path str Google Cloud Storage bucket name required pattern str | None regex pattern to search in bucket. Can seach folders by adding folder names (i.e. pattern = 'subfolder/*.txt). If None then will not use search pattern. default = None None output_url bool boolean switch to output google cloud storage http url or google cloud storage object uri. If false will output gcs uri. default = False False project str | None Cloud project name to use when initiation file spec. If None then use default gcloud config. default = None None Returns: Type Description list[str] List of objects in bucket that match pattern Source code in hydrafloods/utils.py def list_gcs_objs ( bucket_path , pattern = None , output_url = False , project = None ): \"\"\"Function to list objects in Google Cloud Storage Bucket args: bucket_path (str): Google Cloud Storage bucket name pattern (str | None, optional): regex pattern to search in bucket. Can seach folders by adding folder names (i.e. pattern = 'subfolder/*.txt). If None then will not use search pattern. default = None output_url (bool, optional): boolean switch to output google cloud storage http url or google cloud storage object uri. If false will output gcs uri. default = False project (str | None): Cloud project name to use when initiation file spec. If None then use default gcloud config. default = None returns: list[str]: List of objects in bucket that match pattern \"\"\" fs = gcsfs . GCSFileSystem ( project = project ) if pattern is not None : bucket_path = ( bucket_path + \"/\" if not bucket_path . endswith ( \"/\" ) else bucket_path ) blobs = fs . glob ( f \" { bucket_path }{ pattern } \" ) else : blobs = fs . ls ( bucket_path ) base = \"https://storage.cloud.google.com/ {0} \" if output_url else \"gs:// {0} \" return [ base . format ( blob ) for blob in blobs ] push_to_ee ( bucket_obj , asset_collection , properties = None , delete_bucket_obj = False ) Helper function to begin ingest process for imagery on GCS to GEE Thinly wraps earthengine upload image Parameters: Name Type Description Default bucket_obj str GCS bucket object to ingest into GEE. Expects that object has mime type of image/tiff required asset_collection str Earth Engine asset collection to push object to required properties list[str] list of properties to set when ingesting files. If None then no properties will be set. default = None None delete_bucket_obj bool boolean switch to delete GCS object once ingested into EE. If set to False then file will remain on GCS. default = False False Source code in hydrafloods/utils.py def push_to_ee ( bucket_obj , asset_collection , properties = None , delete_bucket_obj = False ): \"\"\"Helper function to begin ingest process for imagery on GCS to GEE Thinly wraps `earthengine upload image` args: bucket_obj (str): GCS bucket object to ingest into GEE. Expects that object has mime type of image/tiff asset_collection (str): Earth Engine asset collection to push object to properties (list[str], optional): list of properties to set when ingesting files. If None then no properties will be set. default = None delete_bucket_obj (bool, optional): boolean switch to delete GCS object once ingested into EE. If set to False then file will remain on GCS. default = False \"\"\" name = os . path . basename ( bucket_obj ) . replace ( \".\" , \"_\" ) asset = asset_collection + name pStr = \"\" for i in properties : pStr += \"-- {0} {1} \" . format ( i , properties [ i ]) binPath = os . path . dirname ( sys . executable ) cmd = \" {0} /earthengine upload image --asset_id= {1} {2} {3} \" . format ( binPath , asset , pStr , bucket_obj ) proc = subprocess . Popen ( cmd , shell = True , stdout = subprocess . PIPE , stderr = subprocess . STDOUT ) out , err = proc . communicate () if properties : pStr = \"\" running = True while running == True : tasks = ee . batch . Task . list () if \"COMPLETED\" in str ( tasks [ 0 ]): running = False elif \"FAILED\" in str ( tasks [ 0 ]): print ( \"EE upload process failed for image {} , check Earth Engine for error\" . format ( bucket_obj ) ) sys . exit ( 1 ) if delete_bucket_obj : cmd = \"gsutil rm {0} \" . format ( bucket_obj ) proc = subprocess . Popen ( cmd , shell = True , stdout = subprocess . PIPE , stderr = subprocess . STDOUT ) out , err = proc . communicate () return push_to_gcs ( file , bucket_path ) Helper function to copy local files to Google Cloud Storage Thinly wraps gsutil cp command line Parameters: Name Type Description Default file str file path to push to GCS required bucket_path str path on GCS to copy file to required Source code in hydrafloods/utils.py def push_to_gcs ( file , bucket_path ): \"\"\"Helper function to copy local files to Google Cloud Storage Thinly wraps `gsutil cp` command line args: file (str): file path to push to GCS bucket_path (str): path on GCS to copy file to \"\"\" if os . path . exists ( file ): cmd = \"gsutil cp {0} {1} \" . format ( file , bucketPath ) proc = subprocess . Popen ( cmd , shell = True , stdout = subprocess . PIPE , stderr = subprocess . STDOUT ) out , err = proc . communicate () else : raise ValueError ( 'file \" {0} does not exist' . format ( file )) return","title":"utils module"},{"location":"utils/#hydrafloods.utils","text":"","title":"utils"},{"location":"utils/#hydrafloods.utils.decode_date","text":"Decodes a date from a command line argument, returning msec since epoch\". Parameters: Name Type Description Default date str date value in a format that can be parsed into datetime object required Returns: Type Description datetime.datetime decoded datetime value Exceptions: Type Description TypeError if string does not conform to a legal date format. Source code in hydrafloods/utils.py def decode_date ( date ): \"\"\"Decodes a date from a command line argument, returning msec since epoch\". args: date (str): date value in a format that can be parsed into datetime object returns: datetime.datetime: decoded datetime value raises: TypeError: if string does not conform to a legal date format. \"\"\" date_formats = [ \"%Y%m %d \" , \"%Y-%m- %d \" , \"%Y-%m- %d T%H:%M:%S\" , \"%Y-%m- %d T%H:%M:%S. %f \" , ] for date_format in date_formats : try : dt = datetime . datetime . strptime ( date , date_format ) return dt except ValueError : continue raise TypeError ( f \"Invalid value for property of type 'date': ' { date } '.\" )","title":"decode_date()"},{"location":"utils/#hydrafloods.utils.list_gcs_objs","text":"Function to list objects in Google Cloud Storage Bucket Parameters: Name Type Description Default bucket_path str Google Cloud Storage bucket name required pattern str | None regex pattern to search in bucket. Can seach folders by adding folder names (i.e. pattern = 'subfolder/*.txt). If None then will not use search pattern. default = None None output_url bool boolean switch to output google cloud storage http url or google cloud storage object uri. If false will output gcs uri. default = False False project str | None Cloud project name to use when initiation file spec. If None then use default gcloud config. default = None None Returns: Type Description list[str] List of objects in bucket that match pattern Source code in hydrafloods/utils.py def list_gcs_objs ( bucket_path , pattern = None , output_url = False , project = None ): \"\"\"Function to list objects in Google Cloud Storage Bucket args: bucket_path (str): Google Cloud Storage bucket name pattern (str | None, optional): regex pattern to search in bucket. Can seach folders by adding folder names (i.e. pattern = 'subfolder/*.txt). If None then will not use search pattern. default = None output_url (bool, optional): boolean switch to output google cloud storage http url or google cloud storage object uri. If false will output gcs uri. default = False project (str | None): Cloud project name to use when initiation file spec. If None then use default gcloud config. default = None returns: list[str]: List of objects in bucket that match pattern \"\"\" fs = gcsfs . GCSFileSystem ( project = project ) if pattern is not None : bucket_path = ( bucket_path + \"/\" if not bucket_path . endswith ( \"/\" ) else bucket_path ) blobs = fs . glob ( f \" { bucket_path }{ pattern } \" ) else : blobs = fs . ls ( bucket_path ) base = \"https://storage.cloud.google.com/ {0} \" if output_url else \"gs:// {0} \" return [ base . format ( blob ) for blob in blobs ]","title":"list_gcs_objs()"},{"location":"utils/#hydrafloods.utils.push_to_ee","text":"Helper function to begin ingest process for imagery on GCS to GEE Thinly wraps earthengine upload image Parameters: Name Type Description Default bucket_obj str GCS bucket object to ingest into GEE. Expects that object has mime type of image/tiff required asset_collection str Earth Engine asset collection to push object to required properties list[str] list of properties to set when ingesting files. If None then no properties will be set. default = None None delete_bucket_obj bool boolean switch to delete GCS object once ingested into EE. If set to False then file will remain on GCS. default = False False Source code in hydrafloods/utils.py def push_to_ee ( bucket_obj , asset_collection , properties = None , delete_bucket_obj = False ): \"\"\"Helper function to begin ingest process for imagery on GCS to GEE Thinly wraps `earthengine upload image` args: bucket_obj (str): GCS bucket object to ingest into GEE. Expects that object has mime type of image/tiff asset_collection (str): Earth Engine asset collection to push object to properties (list[str], optional): list of properties to set when ingesting files. If None then no properties will be set. default = None delete_bucket_obj (bool, optional): boolean switch to delete GCS object once ingested into EE. If set to False then file will remain on GCS. default = False \"\"\" name = os . path . basename ( bucket_obj ) . replace ( \".\" , \"_\" ) asset = asset_collection + name pStr = \"\" for i in properties : pStr += \"-- {0} {1} \" . format ( i , properties [ i ]) binPath = os . path . dirname ( sys . executable ) cmd = \" {0} /earthengine upload image --asset_id= {1} {2} {3} \" . format ( binPath , asset , pStr , bucket_obj ) proc = subprocess . Popen ( cmd , shell = True , stdout = subprocess . PIPE , stderr = subprocess . STDOUT ) out , err = proc . communicate () if properties : pStr = \"\" running = True while running == True : tasks = ee . batch . Task . list () if \"COMPLETED\" in str ( tasks [ 0 ]): running = False elif \"FAILED\" in str ( tasks [ 0 ]): print ( \"EE upload process failed for image {} , check Earth Engine for error\" . format ( bucket_obj ) ) sys . exit ( 1 ) if delete_bucket_obj : cmd = \"gsutil rm {0} \" . format ( bucket_obj ) proc = subprocess . Popen ( cmd , shell = True , stdout = subprocess . PIPE , stderr = subprocess . STDOUT ) out , err = proc . communicate () return","title":"push_to_ee()"},{"location":"utils/#hydrafloods.utils.push_to_gcs","text":"Helper function to copy local files to Google Cloud Storage Thinly wraps gsutil cp command line Parameters: Name Type Description Default file str file path to push to GCS required bucket_path str path on GCS to copy file to required Source code in hydrafloods/utils.py def push_to_gcs ( file , bucket_path ): \"\"\"Helper function to copy local files to Google Cloud Storage Thinly wraps `gsutil cp` command line args: file (str): file path to push to GCS bucket_path (str): path on GCS to copy file to \"\"\" if os . path . exists ( file ): cmd = \"gsutil cp {0} {1} \" . format ( file , bucketPath ) proc = subprocess . Popen ( cmd , shell = True , stdout = subprocess . PIPE , stderr = subprocess . STDOUT ) out , err = proc . communicate () else : raise ValueError ( 'file \" {0} does not exist' . format ( file )) return","title":"push_to_gcs()"},{"location":"workflow-example/","text":"Workflows in the HYDRAFloods sense are related to high-level processes that chain together the lower-level functionality of the package. A defining feature of the workflows are that they are organized in a set of procedures (functions that return None ) that kick off a steps, when chained together result in surface water maps. For example, a workflow can be creating daily surface water maps using a data fusion process. Currently, only one workflow is implemented but it is possible to build more. Daily Surface Water Fusion Process (DSWFP) The DSWFP is based on a few concepts: data fusion, predicting long-term trends in surface water, and refining surface water estimate with short-term trends. The whole process is split into three broad functions to achieve this goal: Export samples of coincident SAR-Optical acquisitions for data fusion Export long-term surface water dynamics using harmonic analysis Predict daily surface water by applying long-term harmonic prediction and correcting for short-term trends hydrafloods has implemented this workflow as a module that users can call functions for each step detailed above. First we need to import the neccesary packages: import ee ee . Initialize () import hydrafloods as hf # import the DSWFP module from hydrafloods.workflows import dswfp 1. Export SAR-Optical fusion samples First step is to sample coincident SAR-Optical data so we can build a machine learning model to fuse the data. This process will kick off a Earth Engine export and result will be a feature collection with information. Keep in mind that this process will take a little while to run (over 30 min) so go grab a cup of coffee while you wait \u2615. # define a geographic region and time period region = hf . country_bbox ( \"Cambodia\" ) start_time = \"2019-01-01\" end_time = \"2019-07-01\" # define the asset name of the output output_asset = ( \"users/<your_username>/fusion_sampling_\" + f \" { start_time . replace ( '-' , '' ) } _ { end_time . replace ( '-' , '' ) } \" ) # run the sampling process dswfp . export_fusion_samples ( region , start_time , end_time , stratify_samples = True , output_asset_path = output_asset , ) 2. Export surface water harmonic coefficients After we have exported our samples to fuse optical and SAR data we can run the process to export the surface water harmonic coefficients. This process takes the fusion samples creates a model to convert SAR data to a water index and then calculates changes in interannual surface water (based on the index). Again, this process can take a while depending on how large of an area and time period being processed, sometimes even days \u23f3. region = hf . country_bbox ( \"Cambodia\" ) start_time = \"2015-01-01\" end_time = \"2020-01-01\" input_features = [ \"VV\" , \"VH\" , \"ratio\" , \"ndpi\" ] # SAR features to predict water index target_label = \"mndwi\" # water index to predict fusion_fc = output_asset # the ouput asset name from the earlier block ouput_asset = \"users/<your_username>/surface_water_harmonic_coefficients dswfp . export_surface_water_harmonics ( region , start_time , end_time , feature_names = input_features , label = target_label , fusion_samples = fusion_fc , output_asset_path = None , tile = False ) 3. Export daily water map Now that we have our data exported and ready to use, we can begin predicting daily surface water maps. Here we provide a date that will want to estimate water for and this algorithm will estimate a water index based on the long-term harmonic trend while correcting that with recent observations. This kicks off two exports, one for the fused water index and another for the water map. The final water index is segmented using on of the thresholding algorithms. target_date = \"2020-10-31\" dswfp . export_daily_surface_water ( region , target_date , harmonic_coefs = None , harmonic_collection = None , feature_names = None , label = None , look_back = 30 , output_confidence = True , fusion_samples = None , output_asset_path = None , initial_threshold = 0.1 , tile = False ) Example outputs from the DSWFP workflow highlighting the fusion product and estimated water as compared to and observed Sentinel 1 image. Sentinel 1 2019-12-04 Fused product 2019-12-04 Estimated Water 2019-12-04","title":"Workflow Example"},{"location":"workflow-example/#daily-surface-water-fusion-process-dswfp","text":"The DSWFP is based on a few concepts: data fusion, predicting long-term trends in surface water, and refining surface water estimate with short-term trends. The whole process is split into three broad functions to achieve this goal: Export samples of coincident SAR-Optical acquisitions for data fusion Export long-term surface water dynamics using harmonic analysis Predict daily surface water by applying long-term harmonic prediction and correcting for short-term trends hydrafloods has implemented this workflow as a module that users can call functions for each step detailed above. First we need to import the neccesary packages: import ee ee . Initialize () import hydrafloods as hf # import the DSWFP module from hydrafloods.workflows import dswfp","title":"Daily Surface Water Fusion Process (DSWFP)"},{"location":"workflow-example/#1-export-sar-optical-fusion-samples","text":"First step is to sample coincident SAR-Optical data so we can build a machine learning model to fuse the data. This process will kick off a Earth Engine export and result will be a feature collection with information. Keep in mind that this process will take a little while to run (over 30 min) so go grab a cup of coffee while you wait \u2615. # define a geographic region and time period region = hf . country_bbox ( \"Cambodia\" ) start_time = \"2019-01-01\" end_time = \"2019-07-01\" # define the asset name of the output output_asset = ( \"users/<your_username>/fusion_sampling_\" + f \" { start_time . replace ( '-' , '' ) } _ { end_time . replace ( '-' , '' ) } \" ) # run the sampling process dswfp . export_fusion_samples ( region , start_time , end_time , stratify_samples = True , output_asset_path = output_asset , )","title":"1. Export SAR-Optical fusion samples"},{"location":"workflow-example/#2-export-surface-water-harmonic-coefficients","text":"After we have exported our samples to fuse optical and SAR data we can run the process to export the surface water harmonic coefficients. This process takes the fusion samples creates a model to convert SAR data to a water index and then calculates changes in interannual surface water (based on the index). Again, this process can take a while depending on how large of an area and time period being processed, sometimes even days \u23f3. region = hf . country_bbox ( \"Cambodia\" ) start_time = \"2015-01-01\" end_time = \"2020-01-01\" input_features = [ \"VV\" , \"VH\" , \"ratio\" , \"ndpi\" ] # SAR features to predict water index target_label = \"mndwi\" # water index to predict fusion_fc = output_asset # the ouput asset name from the earlier block ouput_asset = \"users/<your_username>/surface_water_harmonic_coefficients dswfp . export_surface_water_harmonics ( region , start_time , end_time , feature_names = input_features , label = target_label , fusion_samples = fusion_fc , output_asset_path = None , tile = False )","title":"2. Export surface water harmonic coefficients"},{"location":"workflow-example/#3-export-daily-water-map","text":"Now that we have our data exported and ready to use, we can begin predicting daily surface water maps. Here we provide a date that will want to estimate water for and this algorithm will estimate a water index based on the long-term harmonic trend while correcting that with recent observations. This kicks off two exports, one for the fused water index and another for the water map. The final water index is segmented using on of the thresholding algorithms. target_date = \"2020-10-31\" dswfp . export_daily_surface_water ( region , target_date , harmonic_coefs = None , harmonic_collection = None , feature_names = None , label = None , look_back = 30 , output_confidence = True , fusion_samples = None , output_asset_path = None , initial_threshold = 0.1 , tile = False ) Example outputs from the DSWFP workflow highlighting the fusion product and estimated water as compared to and observed Sentinel 1 image. Sentinel 1 2019-12-04 Fused product 2019-12-04 Estimated Water 2019-12-04","title":"3. Export daily water map"}]}